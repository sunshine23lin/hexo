<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>JAVA</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://jameslin23.gitee.io/"/>
  <updated>2020-12-23T02:42:59.327Z</updated>
  <id>https://jameslin23.gitee.io/</id>
  
  <author>
    <name>LeBron Tao</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>docker基础篇</title>
    <link href="https://jameslin23.gitee.io/2020/12/22/docker%E5%9F%BA%E7%A1%80%E7%AF%87/"/>
    <id>https://jameslin23.gitee.io/2020/12/22/docker基础篇/</id>
    <published>2020-12-22T01:13:29.000Z</published>
    <updated>2020-12-23T02:42:59.327Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Docker简介"><a href="#Docker简介" class="headerlink" title="Docker简介"></a>Docker简介</h2><h3 id="什么是Docker？"><a href="#什么是Docker？" class="headerlink" title="什么是Docker？"></a>什么是Docker？</h3><p>Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的<a href="https://baike.baidu.com/item/镜像/1574" target="_blank" rel="noopener">镜像</a>中，然后发布到任何流行的 <a href="https://baike.baidu.com/item/Linux" target="_blank" rel="noopener">Linux</a>或<a href="https://baike.baidu.com/item/Windows/165458" target="_blank" rel="noopener">Windows</a> 机器上，也可以实现<a href="https://baike.baidu.com/item/虚拟化/547949" target="_blank" rel="noopener">虚拟化</a>。容器是完全使用<a href="https://baike.baidu.com/item/沙箱/393318" target="_blank" rel="noopener">沙箱</a>机制，相互之间不会有任何接口。</p><h3 id="为什么用Docker"><a href="#为什么用Docker" class="headerlink" title="为什么用Docker?"></a>为什么用Docker?</h3><p>作为一种新兴的虚拟化方法，Docker跟传统的虚拟化方式相比具有众多的优势。</p><ul><li><p><strong>更高效的利用系统资源</strong></p><p>由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。</p></li><li><p><strong>更快速的启动时间</strong></p><p>传统的虚拟机技术启动应用服务往往需要数分钟，而 Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。</p></li><li><p><strong>一致的运行环境</strong></p><p>开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。</p></li><li><p><strong>持续交付和部署</strong></p><p>对于开发和运维(DevOps)人员来说,最希望的就是一次创建或者配置，可以在任意地方正常运行。使用Docker可以通过定制应用镜像来实现持续继承、持续交付、部署。开发人员可以通过Dockerfile进行镜像构建，并结合持续集成系统进行集成测试。而运维人员可以直接在生产中快速部署该镜像，甚至结合持续部署系统进行自动部署。而使用<code>而使用Dockerfile</code>使镜像构建透明化，不仅仅开发团队可以理解应用运行环境，也方便运维团队理解应用运行所需条件，帮助更好的生产环境中部署该镜像。</p></li><li><p><strong>更轻松的迁移</strong></p><p>由于Docker确保了执行环境的一致性，使得应用的迁移更加容易。Docker可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结构是一致的。</p></li><li><p><strong>更轻松的维护和扩展</strong></p><p>Docker 使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，Docker 团队同各个开源项目团队一起维护了一大批高质量的 官方镜像，既可以直接在生产环境使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。</p><p><img src="https://jameslin23.gitee.io/2020/12/22/docker%E5%9F%BA%E7%A1%80%E7%AF%87/image-20201222093759205.png" alt="image-20201222093759205"></p></li></ul><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>docker包括三个基本概念</p><ul><li><strong>镜像（Image）</strong></li><li><strong>容器（Container）</strong></li><li><strong>仓库（Repository）</strong></li></ul><h3 id="Docker-镜像"><a href="#Docker-镜像" class="headerlink" title="Docker 镜像"></a>Docker 镜像</h3><p>我们都知道,操作系统分为内核和用户空间。对于Linux而言,内核启动后，会挂在<code>root</code>文件系统为其提供用户空间支持。而Docker镜像，就相当于一个<code>root</code>文件系统。比如官方镜像ubuntu:16.04就包含了完整的一套ubuntu16.04最小系统的<code>root</code>文件系统。Docker镜像是一个特殊文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外、还包含了一些为运行时准备的一些参数(如匿名卷、环境变量、用户等)。<strong>镜像不包含任何动态数据。其内容在构建之后也不会被改变。</strong></p><p><strong>分层存储</strong></p><p>因为镜像包含操作系统完整的  root  文件系统，其体积往往是庞大的，因此在 Docker 设计时，就充分利用 Union FS 的技术，将其设计为分层存储的架构。所以严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是<strong>由一组文件系统组成</strong>，或者说，<strong>由多层文件系统联合组成。镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层</strong>。比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，<strong>在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉</strong>。分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。</p><h3 id="Docker-容器"><a href="#Docker-容器" class="headerlink" title="Docker 容器"></a>Docker 容器</h3><p>镜像和容器的关系，就像是面向对象程序设计中类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、删除、暂停等。</p><p>容器实质是进程，但与直接在宿主执行的进程不同，容器进程运行属于自己的独立的命名空间。因此容器可以拥有自己<code>root</code>文件系统、自己的网络配置、自己进程空间，甚至自己的用户ID空间。容器内的进程是在运行一个隔离的环境中，使用起来好像是在一个独立于宿主的系统下的操作系统一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。</p><p>前面讲过镜像使用的是分层存储，容器也是如此。每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为容器存储层。<strong>容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。</strong></p><p>按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 <strong>数据卷（Volume）</strong>、<strong>或者绑定宿主目录</strong>，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。</p><p>数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。</p><h3 id="Docker-仓库"><a href="#Docker-仓库" class="headerlink" title="Docker 仓库"></a>Docker 仓库</h3><p>镜像构建完成后，可以很容易的在当前宿主机上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry 就是这样的服务。一个 Docker Registry 中可以包含多个仓库（ Repository  ）；每个仓库可以包含多个标签（ Tag  ）；每个标签对应一个镜像。</p><p>通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过  &lt;仓库名&gt;:&lt;标签&gt;  的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以  latest  作为默认标签。</p><p>最常使用的 Registry 公开服务是官方的 <strong>Docker Hub</strong>，这也是默认的 Registry，并拥有大量的<br>高质量的官方镜像。国内也有一些云服务商提供类似于 Docker Hub 的公开服务。比如 时速云镜像仓库、网易云<br>镜像服务、DaoCloud 镜像市场、阿里云镜像库 等。</p><h2 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h2><p>操作系统选择CentOS 7.0以上</p><p>安装之前如果需要卸载的话，执行以下指令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">yum remove docker \</span><br><span class="line">                  docker-client \</span><br><span class="line">                  docker-client-latest \</span><br><span class="line">                  docker-common \</span><br><span class="line">                  docker-latest \</span><br><span class="line">                  docker-latest-logrotate \</span><br><span class="line">                  docker-logrotate \</span><br><span class="line">                  docker-engine</span><br></pre></td></tr></table></figure><ol><li><p>按照Docker所需要的依赖</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y yum-utils \ device-mapper-persistent-data \ lvm2</span><br></pre></td></tr></table></figure></li></ol><ol start="2"><li><p>设置阿里云镜像库</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum-config-manager  --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure></li><li><p>安装Docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install docker-ce <span class="comment"># ce 为社区版本免费，docker-ee 企业版本</span></span><br></pre></td></tr></table></figure></li><li><p>设置镜像库加速</p><p><img src="https://jameslin23.gitee.io/2020/12/22/docker%E5%9F%BA%E7%A1%80%E7%AF%87/image-20201222105019871.png" alt="image-20201222105019871"></p><p><img src="/2020/12/22/docker基础篇/C:%5CUsers%5CAdministrator.USER-20190627HM%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201222105056444.png" alt="image-20201222105056444"></p><p>安装步骤设置即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /etc/docker</span><br><span class="line">sudo tee /etc/docker/daemon.json &lt;&lt;-<span class="string">'EOF'</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"registry-mirrors"</span>: [<span class="string">"https://qhyb8ixp.mirror.aliyuncs.com"</span>]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure></li></ol><ol start="5"><li><p>开启Docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service docker start</span><br></pre></td></tr></table></figure></li><li><p>测试</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run hello-world</span><br></pre></td></tr></table></figure><p><img src="https://jameslin23.gitee.io/2020/12/22/docker%E5%9F%BA%E7%A1%80%E7%AF%87/image-20201222105550892.png" alt="image-20201222105550892"></p></li></ol><h2 id="使用镜像"><a href="#使用镜像" class="headerlink" title="使用镜像"></a>使用镜像</h2><p>Docker运行容器前需要本地存在对应的镜像，如果本地不在该镜像,Docker会从镜像仓库下载该镜像。</p><ul><li>从仓库获取镜像</li><li>管理本地主机上的镜像</li><li>镜像实现的基本原理</li></ul><h3 id="获取镜像"><a href="#获取镜像" class="headerlink" title="获取镜像"></a>获取镜像</h3><p>从 Docker 镜像仓库获取镜像的命令是  <code>docker pull</code>  。其命令格式为：</p><blockquote><p>docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签]</p></blockquote><p>具体的选项可以通过  docker pull –help  命令看到，这里我们说一下镜像名称的格式。</p><ul><li>Docker 镜像仓库地址：地址的格式一般是  &lt;域名/IP&gt;[:端口号]  。默认地址是 Docker<br>Hub。</li><li>仓库名：如之前所说，这里的仓库名是两段式名称，即  &lt;用户名&gt;/&lt;软件名&gt;  。对于 Docker<br>Hub，如果不给出用户名，则默认为  library  ，也就是官方镜像。</li></ul><p><code>docker pull centos</code></p><p><img src="https://jameslin23.gitee.io/2020/12/22/docker%E5%9F%BA%E7%A1%80%E7%AF%87/image-20201222111042648.png" alt="image-20201222111042648"></p><h3 id="列出容器"><a href="#列出容器" class="headerlink" title="列出容器"></a>列出容器</h3><p><code>docker image ls</code></p><blockquote><p>REPOSITORY            TAG                    IMAGE ID                CREATED              SIZE<br>centos                      latest              300e315adb2f          2 weeks ago        209MB<br>hello-world            latest               bf756fb1ae65           11 months ago    13.3kB</p></blockquote><p>列表包含了  仓库名  、 标签  、 镜像 ID  、 创建时间  以及  所占用的空间  。</p><p>可以通过<code>docker system df</code>来便捷的查看镜像、容器、数据卷所占用的空间</p><blockquote><p>TYPE                   TOTAL     ACTIVE    SIZE      RECLAIMABLE<br>Images                 2               1         209.4MB    209.3MB (99%)<br>Containers          2               0               0B             0B<br>Local Volumes   0                0               0B             0B<br>Build Cache        0                0               0B             0B</p></blockquote><h3 id="删除镜像"><a href="#删除镜像" class="headerlink" title="删除镜像"></a>删除镜像</h3><p>如果要删除本地的镜像，可以使用  <code>docker image rm</code>  命令，其格式为：</p><blockquote><p>docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; …]</p></blockquote><h3 id="Commit命令"><a href="#Commit命令" class="headerlink" title="Commit命令"></a>Commit命令</h3><p>docker commit命令除了学习外，还有一些特殊的应用场景，比如被入侵后保存现场等，但不要使用该命令指定镜像，指定镜像应该使用<strong>Dockerfile</strong> 完成</p><blockquote><p>使用  docker commit  意味着所有对镜像的操作都是黑箱操作，生成的镜像也被称为黑箱镜像，换句话说，就是除了制作镜像的人知道执行过什么命令、怎么生成的镜像，别人根本无从得知。而且，即使是这个制作镜像的人，过一段时间后也无法记清具体在操作的。虽然  docker diff  或许可以告诉得到一些线索，但是远远不到可以确保生成一致镜像的地步。这种黑箱镜像的维护工作是非常痛苦的。而且，回顾之前提及的镜像所使用的分层存储的概念，除当前层外，之前的每一层都是不会发生改变的，换句话说，任何修改的结果仅仅是在当前层进行标记、添加、修改，而不会改动上一层。如果使用  docker commit  制作镜像，以及后期修改的话，每一次修改都会让镜像更加臃肿一次，所删除的上一层的东西并不会丢失，会一直如影随形的跟着这个镜像，即使根本无法访问到。这会让镜像更加臃肿。</p></blockquote><h3 id="DockerFile定制镜像"><a href="#DockerFile定制镜像" class="headerlink" title="DockerFile定制镜像"></a>DockerFile定制镜像</h3><p>DcokerFile是一个文本文件，其中包含了一条条的指令，每一条指令构建一层，因此每一条指令的你内容，就是描述该层应当如何构建。</p><p>DockerFile构建指令</p><blockquote><p>FROM                         # 基础镜像，一切从这里开始构建</p><p>MAINTAINER             # 镜像是谁写的， 姓名+邮箱</p><p>RUN                           # 镜像构建的时候需要运行的命令</p><p>ADD                           # 步骤，tomcat镜像，这个tomcat压缩包！添加内容 添加同目录</p><p>WORKDIR                  # 镜像的工作目录</p><p>VOLUME                   # 挂载的目录</p><p>EXPOSE                     # 保留端口配置</p><p>CMD                          # 指定这个容器启动的时候要运行的命令，只有最后一个会生效，可被替代</p><p>ENTRYPOINT            # 指定这个容器启动的时候要运行的命令，可以追加命令</p><p>COPY                        # 类似ADD，将我们文件拷贝到镜像中</p><p>ENV                          # 构建的时候设置环境变量！</p></blockquote><h4 id="定制centos镜像"><a href="#定制centos镜像" class="headerlink" title="定制centos镜像"></a>定制centos镜像</h4><ol><li><p>编写Dockerfile(文件名不是Dockerfile，构建是需要-f指定文件名)</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos</span><br><span class="line"><span class="keyword">MAINTAINER</span> MT&lt;<span class="number">1172952007</span>@qq.com&gt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> MYPATH /usr/local</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> <span class="variable">$MYPATH</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum -y install vim</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">80</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> /bin/bash</span></span><br></pre></td></tr></table></figure></li><li><p>构建mycentos镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -f mycentos -t mycentosdemodo:1.0  .</span><br></pre></td></tr></table></figure></li><li><p>查看镜像历史</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">history</span> 镜像ID</span><br></pre></td></tr></table></figure></li></ol><h4 id="定制tomcat镜像"><a href="#定制tomcat镜像" class="headerlink" title="定制tomcat镜像"></a>定制tomcat镜像</h4><ol><li><p>编写Dockerfile(文件名不是Dockerfile，构建是需要-f指定文件名)</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos</span><br><span class="line"><span class="keyword">MAINTAINER</span> fortuneteller&lt;<span class="number">1172952007</span>@qq.com&gt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> README.txt /usr/<span class="built_in">local</span>/README.txt</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> jdk-8u271-linux-x64.tar.gz /usr/<span class="built_in">local</span></span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> apache-tomcat-9.0.41.tar.gz /usr/<span class="built_in">local</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum -y install vim</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> MYPATH /usr/local</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> <span class="variable">$MYPATH</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> JAVA_HOME /usr/local/jdk1.<span class="number">8.0</span>_271</span><br><span class="line"><span class="keyword">ENV</span> CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"><span class="keyword">ENV</span> CATALINA_HOME /usr/local/apache-tomcat-<span class="number">9.0</span>.<span class="number">41</span></span><br><span class="line"><span class="keyword">ENV</span> CATALINA_BASH /usr/local/apache-toacat-<span class="number">9.0</span>.<span class="number">41</span></span><br><span class="line"><span class="keyword">ENV</span> PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin</span><br><span class="line"></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">8080</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"/usr/local/apache-tomcat-9.0.41/bin/catalina.sh"</span>, <span class="string">"run"</span>]</span></span><br></pre></td></tr></table></figure></li><li><p>构建mytomcat镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build  -f Dockerfile-tomcat -t mytomcat .</span><br></pre></td></tr></table></figure></li><li><p>启动tomcat</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 3344:8080 --name mttomcat -v /data/docker-test/tomcat/<span class="built_in">test</span>:/usr/<span class="built_in">local</span>/apache-tomcat-9.0.41/webapps/<span class="built_in">test</span> -v /data/docker-test/tomcat/<span class="built_in">test</span>/logs:/usr/<span class="built_in">local</span>/apache-tomcat-9.0.41/logs mytomcat</span><br></pre></td></tr></table></figure><p><img src="https://jameslin23.gitee.io/2020/12/22/docker%E5%9F%BA%E7%A1%80%E7%AF%87/image-20201222175017542.png" alt="image-20201222175017542"></p></li><li><p>进入容器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看容器id</span></span><br><span class="line">docker container ls</span><br><span class="line"><span class="comment"># 进入容器</span></span><br><span class="line">docker <span class="built_in">exec</span> -it 容器ID /bin/bash</span><br></pre></td></tr></table></figure></li></ol><h2 id="Docker-容器-1"><a href="#Docker-容器-1" class="headerlink" title="Docker 容器"></a>Docker 容器</h2><h3 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h3><p>启动容器有两种方式，一种是基于镜像新建一个容器并启动,另外一个是将在终止状态（stopped）的容器重启启动</p><p>因为docker的容器实在太轻量级了，很多时候用户都是随时删除和新创建容器</p><ul><li><p>新建容器并启动  <code>docker run</code></p><blockquote><p> docker run -t -i mycentos:1.0 /bin/bash</p></blockquote></li><li><p>存在容器启动 <code>docker container start</code></p></li></ul><p><strong>参数说明</strong></p><ul><li>-t让docker分配一个伪终端并绑定到容器的标准输入上</li><li>-i 则让容器的标志输入保持打开</li></ul><p>当利用<code>docker run</code> 来创建容器时，Docker在后台运行标准操作包括：</p><ul><li>检查本地是否存在指定的镜像，不存在就从公有仓库下载</li><li>利用镜像创建并启动一个容器</li><li>分配一个文件系统，并在只读的镜像层外面挂载一层可读写层</li><li>从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中</li><li>从地址池配置一个ip地址给容器</li><li>执行用户指定的应用程序</li><li>执行完毕后容器被终止</li></ul><h3 id="终止容器"><a href="#终止容器" class="headerlink" title="终止容器"></a>终止容器</h3><p><code>docker container stop</code></p><p>查看容器状态</p><p><code>docker container ls -a</code></p><h3 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h3><p>在使用  -d  参数时，容器启动后会进入后台。<br>某些时候需要进入容器进行操作，包括使用  <code>docker attach</code>  命令或  <code>docker exec</code>  命令，推荐大家使用  <code>docker exec</code>  命令</p><p>更多参数说明请使用  docker exec –help  查看。</p><h3 id="删除容器"><a href="#删除容器" class="headerlink" title="删除容器"></a>删除容器</h3><p>可以使用  <code>docker container rm</code>  来删除一个处于终止状态的容器。例如</p><p><code>docker container prune</code>可以清理掉所有处于终止状态的容器。</p><h2 id="Docker仓库"><a href="#Docker仓库" class="headerlink" title="Docker仓库"></a>Docker仓库</h2><p>目前 Docker 官方维护了一个公共仓库 Docker Hub，其中已经包括了数量超过 15,000 的镜<br>像。大部分需求都可以通过在 Docker Hub 中直接下载镜像来实现。</p><h3 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h3><p>你可以在 <a href="https://cloud.docker.com" target="_blank" rel="noopener">https://cloud.docker.com</a> 免费注册一个 Docker 账号。</p><h3 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h3><p>可以通过执行  <code>docker login</code>  命令交互式的输入用户名及密码来完成在命令行界面登录<br>Docker Hub。<br>你可以通过  <code>docker logout</code>  退出登录。</p><h3 id="拉取镜像"><a href="#拉取镜像" class="headerlink" title="拉取镜像"></a>拉取镜像</h3><p>你可以通过  <code>docker search</code>  命令来查找官方仓库中的镜像，并利用  <strong>docker pull</strong>  命令来将它<br>下载到本地。</p><h3 id="推送镜像"><a href="#推送镜像" class="headerlink" title="推送镜像"></a>推送镜像</h3><p>用户也可以在登录后通过  <strong>docker push</strong>  命令来将自己的镜像推送到 Docker Hub。</p><blockquote><p>docker push username/ubuntu:17.10</p></blockquote><h2 id="Docker数据管理"><a href="#Docker数据管理" class="headerlink" title="Docker数据管理"></a>Docker数据管理</h2><p>Docker 内部以及容器之间管理数据，在容器中管理数据主要有两种方式</p><ul><li><strong>数据卷(Volumes)</strong></li><li><strong>挂载主机目录（Bind mounts）</strong></li></ul><p>容器之间可以有一个数据共享的技术！Docker容器中产生的数据，同步到本地！</p><p>这就是卷技术！目录的挂载，将我们容器内的目录，挂载到Linux上面！</p><h3 id="使用命令"><a href="#使用命令" class="headerlink" title="使用命令"></a>使用命令</h3><blockquote><p>docker run -it -v 主机目录:容器内目录 /bin/bash</p></blockquote><h3 id="挂载方式"><a href="#挂载方式" class="headerlink" title="挂载方式"></a>挂载方式</h3><blockquote><p>-v 容器内路径                      # 匿名挂载</p><p>-v 卷名:容器内路径             # 具名挂载 </p><p>-v 宿主机路径:容器内路径  # 指定路径挂载</p></blockquote><p>Docker容器内的卷、在没有指定目录情况下都在<code>/var/lib/docker/volumes/xxx/_data</code>下</p><h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><blockquote><p># 通过 -v 容器内路径：ro rw 改变读写权限</p><p>ro # readonly 只读</p><p>rw # readwrite 可读可写</p><p>docker run -d nginx01 -v nginxdemo:/etc/nginx:ro nginx</p></blockquote><h2 id="网络配置"><a href="#网络配置" class="headerlink" title="网络配置"></a>网络配置</h2><h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><p>Docker使用linux桥接，在宿主机虚拟一个Docker容器网桥(docker0),Docker启动一个容器时会根据Docker网桥的网段分配给容器一个IP地址，称为Container-IP,同时<strong>Docker网桥是每个容器默认网关</strong>。因为在同一个宿主机的容器都接入同一个网桥，<strong>这样容器之间就能够通过容器的Container直接通讯。</strong></p><p>Docker网桥是宿主机虚拟出来的，并不是真实存在的网络设备，外部网络是无法寻址到的，这意味着外部网络无法通过直接Container-IP访问到容器，可以通过映射容器到宿主机(端口映射)，即docker run创建容器时候通过 -p 或 -P 参数来启用，访问容器的时候就通过<code>[宿主机IP]:[容器端口]</code>访问容器。</p><h3 id="网络模式"><a href="#网络模式" class="headerlink" title="网络模式"></a>网络模式</h3><p><img src="https://jameslin23.gitee.io/2020/12/22/docker%E5%9F%BA%E7%A1%80%E7%AF%87/image-20201223092909412.png" alt="image-20201223092909412"></p><h4 id="bridge模式-默认"><a href="#bridge模式-默认" class="headerlink" title="bridge模式(默认)"></a>bridge模式(默认)</h4><p>当Docker进程启动时，会在主机上创建一个名为docker0的虚拟网桥，此主机上启动的docker容器会连接到这个虚拟网桥上。从docker0子网络中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关,在主机上创建一对虚拟网卡veth pair设备,docker将veth pair设备的一端放入新的创建的容器中，并命名eth0(容器的网卡)，另一端放在主机中。以vethxxx这样类似的名字命名,并将这个网络设备加入到doker0网桥中，可以通过brctl show命令查看</p><p>birdge模式是docker的默认网络模式，不写–net参数，就是bridge模式。使用docker run -p 时,docker实际就是做iptables做了DNAT规则，实现端口转发功能。可以使用iptables -t nat -vnl查看</p><p><img src="https://jameslin23.gitee.io/2020/12/22/docker%E5%9F%BA%E7%A1%80%E7%AF%87/image-20201223093913511.png" alt="image-20201223093913511"></p><h4 id="host模式"><a href="#host模式" class="headerlink" title="host模式"></a>host模式</h4><p>如果启动容器 的时候使用host模式，那么这个容器将不会获得一个独立的Network Namespace,而是和宿主机共用一个Network Namespace 。容器将不会虚拟出自己的网卡，配置自己的ip等，而是使用宿主机ip和端口。但是容器的其他方面，如文件系统，进程列表等还是个宿主机隔离。</p><p>使用host模式的容器可以直接使用宿主机的ip地址与外界通信,容器内部的服务端口也可以使用宿主机的端口，不需要进行nat,host最大优势是网络性能比较好，但是docker host上已经使用的端口就不能再用了网络隔离性不好。</p><p><img src="https://jameslin23.gitee.io/2020/12/22/docker%E5%9F%BA%E7%A1%80%E7%AF%87/image-20201223094523624.png" alt="image-20201223094523624"></p><h4 id="container-模式"><a href="#container-模式" class="headerlink" title="container 模式"></a>container 模式</h4><p>这个模式指定新创建的容器和已经存在一个容器共享一个Network Namespace,而不是和宿主机共享。新创建的容器不会创建自己的网卡，配自己IP。而是和一个指定的容器共享IP、端口等。同样2个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。2个容器进程可以通过lo网卡设备通信。</p><p><img src="https://jameslin23.gitee.io/2020/12/22/docker%E5%9F%BA%E7%A1%80%E7%AF%87/image-20201223095659128.png" alt="image-20201223095659128"></p><h4 id="none模式"><a href="#none模式" class="headerlink" title="none模式"></a>none模式</h4><p>使用none模式，docker容器拥有自己的Network Namespace,但是，并不为Docker容器进行任何网络配置，也就是说，这个容器没有网卡、IP、路由等信息。所以需要我们自己为docker容器添加网卡、配置IP等。</p><p>这种网络模式下容器只有lo回环网络，没有其他网卡。node模式可以在容器创建时通过–network=none来指定。这类型网络没有办法联网，封闭的网络能很好保证容器安全性。</p><p><img src="https://jameslin23.gitee.io/2020/12/22/docker%E5%9F%BA%E7%A1%80%E7%AF%87/image-20201223103642080.png" alt="image-20201223103642080"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Docker简介&quot;&gt;&lt;a href=&quot;#Docker简介&quot; class=&quot;headerlink&quot; title=&quot;Docker简介&quot;&gt;&lt;/a&gt;Docker简介&lt;/h2&gt;&lt;h3 id=&quot;什么是Docker？&quot;&gt;&lt;a href=&quot;#什么是Docker？&quot; class=&quot;
      
    
    </summary>
    
      <category term="docker" scheme="https://jameslin23.gitee.io/categories/docker/"/>
    
    
      <category term="运维与虚拟化技术" scheme="https://jameslin23.gitee.io/tags/%E8%BF%90%E7%BB%B4%E4%B8%8E%E8%99%9A%E6%8B%9F%E5%8C%96%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>tcp可靠机制</title>
    <link href="https://jameslin23.gitee.io/2020/12/16/tcp%E5%8F%AF%E9%9D%A0%E6%9C%BA%E5%88%B6/"/>
    <id>https://jameslin23.gitee.io/2020/12/16/tcp可靠机制/</id>
    <published>2020-12-16T01:56:00.000Z</published>
    <updated>2020-12-16T02:41:22.671Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>为了实现可靠性传输，需要考虑很多事情，例如数据的破坏、丢包、重复以及分片顺序混乱等问题。如不能解决这些问题，也就无从谈起可靠传输。</p><p>那么，TCP 是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的</p><p>今天，将重点介绍 TCP 的<strong>重传机制、滑动窗口、流量控制、拥塞控制。</strong></p><p><img src="/2020/12/16/tcp可靠机制/C:%5CUsers%5CAdministrator.USER-20190627HM%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201216100004410.png" alt="image-20201216100004410"></p><pre><code>##  重传机制</code></pre><h3 id="超时重传"><a href="#超时重传" class="headerlink" title="超时重传"></a>超时重传</h3><p>指在设置时间内未收到对方ACK确认应答报文，就会重发数据。</p><p>如果超时重发的数据，再次超时的时候，又需要重传时候，TCP的策略是超时间隔加倍。</p><p><strong>每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。</strong></p><p><strong>存在问题:</strong></p><p>超时周期可能相对较长</p><p><img src="/2020/12/16/tcp可靠机制/C:%5CUsers%5CAdministrator.USER-20190627HM%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201216102028045.png" alt="image-20201216102028045"></p><h3 id="快速重传"><a href="#快速重传" class="headerlink" title="快速重传"></a>快速重传</h3><p>快速重传的工作方法是当收到三个相同ACK报文时，会在定时器过期之前，重传丢失报文。</p><p><strong>存在问题：</strong></p><p>重传的时候，是重传之前的一个，还是所有？</p><p><img src="/2020/12/16/tcp可靠机制/C:%5CUsers%5CAdministrator.USER-20190627HM%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201216102158624.png" alt="image-20201216102158624"></p><h3 id="SACK"><a href="#SACK" class="headerlink" title="SACK"></a>SACK</h3><p>SACK选择性确认</p><p>在TCP头部选项字段加一个SACK的东西，缓存发送的序列化，然后发送给发送方，让发送方可以知道哪些数据收到，哪些数据没收到。</p><p>知道这些信息，就可以只重传丢失的数据。</p><p><img src="/2020/12/16/tcp可靠机制/C:%5CUsers%5CAdministrator.USER-20190627HM%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201216102638128.png" alt="image-20201216102638128"></p><p>如果要支持 <code>SACK</code>，必须双方都要支持。在 Linux 下，可以通过 <code>net.ipv4.tcp_sack</code> 参数打开这个功能（Linux 2.4 后默认打开）。</p><h3 id="D-SACK"><a href="#D-SACK" class="headerlink" title="D-SACK"></a>D-SACK</h3><p>使用SACK来告诉有哪些数据被重复接收了</p><p><strong>ACK丢包</strong></p><p><img src="/2020/12/16/tcp可靠机制/C:%5CUsers%5CAdministrator.USER-20190627HM%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201216102903448.png" alt="image-20201216102903448"></p><ul><li>「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）</li><li><strong>于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500</strong>，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 <code>D-SACK</code>。</li><li>这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。</li></ul><p><strong>网络延迟</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZeuicRMlA8rKvl5AVLibhibDhgGSKaMMbmPiaUQmCvR4cz2kQ5OV8SqaPIwdkZ7T19uEs5WxCc6h66x7w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><ul><li>数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。</li><li>而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；</li><li><strong>所以「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。</strong></li><li>这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。</li></ul><h2 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h2><h2 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h2><h2 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;为了实现可靠性传输，需要考虑很多事情，例如数据的破坏、丢包、重复以及分片顺序混乱等问题。如不能解决这些问题，也就无从谈起可靠传输。&lt;/p&gt;

      
    
    </summary>
    
      <category term="计算机网络" scheme="https://jameslin23.gitee.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="https://jameslin23.gitee.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>http核心技术</title>
    <link href="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/"/>
    <id>https://jameslin23.gitee.io/2020/12/15/http核心技术/</id>
    <published>2020-12-15T02:03:03.000Z</published>
    <updated>2020-12-16T00:57:42.861Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ul><li><strong>HTTP 基本概念</strong></li><li><strong>Get 与 Post</strong></li><li><strong>HTTP 特性</strong></li><li><strong>HTTP 与 HTTPS</strong></li><li><strong>HTTP/1.1、HTTP/2、HTTP/3 演练</strong></li></ul><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215140430600.png" alt="image-20201215140430600"></p><h2 id="HTTP基本概念"><a href="#HTTP基本概念" class="headerlink" title="HTTP基本概念"></a>HTTP基本概念</h2><h3 id="初入认识"><a href="#初入认识" class="headerlink" title="初入认识"></a>初入认识</h3><p><strong>http是超文本传输协议，是在一个计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范</strong>。</p><h3 id="状态码"><a href="#状态码" class="headerlink" title="状态码"></a>状态码</h3><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215141652119.png" alt="image-20201215141652119"></p><h3 id="常见字段"><a href="#常见字段" class="headerlink" title="常见字段"></a>常见字段</h3><ul><li><p><strong>Host</strong></p><p>客户端发送请求时，用来指定服务器的域名</p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215141938002.png" alt="image-20201215141938002"></p></li><li><p><strong>Content-Length</strong> </p><p>服务器在返回数据时，会有 <code>Content-Length</code> 字段，表明本次回应的数据长度。</p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215143529802.png" alt="image-20201215143529802"></p><p>如上面则是告诉浏览器，本次服务器回应的数据长度是 1000 个字节，后面的字节就属于下一个回应了。</p></li><li><p><strong>Connection</strong></p><p><code>Connection</code> 字段最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。</p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215143627738.png" alt="image-20201215143627738"></p><p>HTTP/1.1 版本的默认连接都是持久连接，但为了兼容老版本的 HTTP，需要指定 <code>Connection</code> 首部字段的值为 <code>Keep-Alive</code>。</p></li><li><p><strong>Content-Type</strong></p><p><code>Content-Type</code> 字段用于服务器回应时，告诉客户端，本次数据是什么格式。</p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215143719801.png" alt="image-20201215143719801"></p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">Content-Type</span>: text/html; charset=utf-8</span><br></pre></td></tr></table></figure><p>上面的类型表明，发送的是网页，而且编码是UTF-8。</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">Accept</span>: */*</span><br></pre></td></tr></table></figure><p>上面代码中，客户端声明自己可以接受任何格式的数据。</p></li><li><p><strong>Content-Encoding</strong></p><p><code>Content-Encoding</code> 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">Content-Encoding</span>: gzip</span><br></pre></td></tr></table></figure><p>上面表示服务器返回的数据采用了 gzip 方式压缩，告知客户端需要用此方式解压。</p><p>客户端在请求时，用 <code>Accept-Encoding</code> 字段说明自己可以接受哪些压缩方法。</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">Accept-Encoding</span>: gzip, deflate</span><br></pre></td></tr></table></figure></li></ul><h2 id="GET和POST"><a href="#GET和POST" class="headerlink" title="GET和POST"></a>GET和POST</h2><h3 id="GET"><a href="#GET" class="headerlink" title="GET"></a>GET</h3><p><code>Get</code> 方法的含义是请求<strong>从服务器获取资源</strong>，这个资源可以是静态的文本、页面、图片视频等</p><p>比如，你打开我的文章，浏览器就会发送 GET 请求给服务器，服务器就会返回文章的所有文字及资源。</p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215144359800.png" alt="image-20201215144359800"></p><h3 id="POST"><a href="#POST" class="headerlink" title="POST"></a>POST</h3><p>而<code>POST</code> 方法则是相反操作，它向 <code>URI</code> 指定的资源提交数据，数据就放在报文的 body 里。</p><p>比如，你在我文章底部，敲入了留言后点击「提交」，浏览器就会执行一次 POST 请求，把你的留言文字放进了报文 body 里，然后拼接好 POST 请求头，通过 TCP 协议发送给服务器。</p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215144458204.png" alt="image-20201215144458204"></p><h3 id="GET-和-POST-区别？"><a href="#GET-和-POST-区别？" class="headerlink" title="GET 和 POST 区别？"></a>GET 和 POST 区别？</h3><h4 id="安全幂等"><a href="#安全幂等" class="headerlink" title="安全幂等"></a>安全幂等</h4><p>先说明下安全和幂等的概念：</p><ul><li>在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源</li><li>所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。</li></ul><p>那么很明显 <strong>GET 方法就是安全且幂等的</strong>，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。</p><p><strong>POST</strong> 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是<strong>不安全</strong>的，且多次提交数据就会创建多个资源，所以<strong>不是幂等</strong>的。</p><h4 id="参数存放"><a href="#参数存放" class="headerlink" title="参数存放"></a>参数存放</h4><ul><li>GET请求参数是放在URL后面，从而容易导致被攻击者窃取，对你的信息超成破坏和伪造，<strong>对URL有长度限制</strong>；</li><li>POST请求参数是放在请求体BODY中。对数据长度没有要求。</li></ul><h4 id="TCP数量"><a href="#TCP数量" class="headerlink" title="TCP数量"></a>TCP数量</h4><ul><li>get 请求在发送过程中会产生一个 TCP 数据包，浏览器会把 http header 和 data 一并发送出去，服务器响应 200（返回数据）</li><li>post 在发送过程中会产生两个 TCP 数据包，浏览器先发送 header，服务器响应 100 continue，浏览器再发送 data，服务器响应 200 ok（返回数据）。</li></ul><h2 id="HTTP特性"><a href="#HTTP特性" class="headerlink" title="HTTP特性"></a>HTTP特性</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li>简单</li><li>灵活和易于扩展</li><li>应用广泛跨平台</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>HTTP 协议里有优缺点一体的<strong>双刃剑</strong>，分别是「无状态、明文传输」，同时还有一大缺点「不安全」。</p><ul><li><p><strong>无状态双刃剑</strong></p><p>无状态的<strong>好处</strong>，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。</p><p>无状态的<strong>坏处</strong>，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦</p><p><strong>解决方法：使用cookie技术</strong></p><p><code>Cookie</code> 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。</p><p>相当于，<strong>在客户端第一次请求后，服务器会下发一个装有客户信息的「小贴纸」，后续客户端请求服务器的时候，带上「小贴纸」，服务器就能认得了了</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215145522022.png" alt="image-20201215145522022"></p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215145537027.png" alt="image-20201215145537027"></p></li></ul><ul><li><p><strong>明文传输双刃剑</strong></p><p>明文意味着在传输过程中的信息，是可方便阅读的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。</p><p>但是这正是这样，HTTP 的所有信息都暴露在了光天化日下，相当于<strong>信息裸奔</strong>。在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能被窃取，如果里面有你的账号密码信息。</p></li><li><p><strong>不安全</strong></p><p>使用HTTPS解决。</p></li></ul><h2 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h2><p>HTTP 由于是明文传输，所以安全上存在以下三个风险：</p><ul><li><strong>窃听风险</strong>，比如通信链路上可以获取通信内容，用户号容易没。</li><li><strong>篡改风险</strong>，比如强制入垃圾广告，视觉污染，用户眼容易瞎。</li><li><strong>冒充风险</strong>，比如冒充淘宝网站，用户钱容易没。</li></ul><p>HTTPS 在HTTP与TCP层之间加入SSL/TLS协议</p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215150223967.png" alt="image-20201215150223967"></p><p>可以很好的解决了上述的风险：</p><ul><li><strong>信息加密</strong>：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。</li><li><strong>校验机制</strong>：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。</li><li><strong>身份证书</strong>：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。</li></ul><p><strong>HTTPS是如何解决上面的三个风险？</strong></p><ul><li><strong>混合加密</strong>的方式实现信息的<strong>机密性</strong>，解决了窃听的风险。</li><li><strong>摘要算法</strong>的方式来实现<strong>完整性</strong>，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。</li><li>将服务器公钥放入到<strong>数字证书</strong>中，解决了冒充的风险。</li></ul><ol><li><p>混合加密</p><p>通过<strong>混合加密</strong>的方式可以保证信息的<strong>机密性</strong>，解决了窃听的风险。</p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215150715241.png" alt="image-20201215150715241"></p><p>HTTPS 采用的是<strong>对称加密</strong>和<strong>非对称加密</strong>结合的「混合加密」方式：</p><ul><li>在通信建立前采用<strong>非对称加密</strong>的方式交换「会话秘钥」，后续就不再使用非对称加密。</li><li>在通信过程中全部使用<strong>对称加密</strong>的「会话秘钥」的方式加密明文数据。</li></ul><p>采用「混合加密」的方式的原因：</p><ul><li><strong>对称加密</strong>只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。</li><li><strong>非对称加密</strong>使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。</li></ul></li><li><p>摘要算法</p><p><strong>摘要算法</strong>用来实现<strong>完整性</strong>，能够为数据生成独一无二的「指纹」，用于校验数据的完整性，解决了篡改的风险。</p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215150813968.png" alt="image-20201215150813968"></p><p>客户端在发送明文之前会通过摘要算法算出明文的「指纹」，发送的时候把「指纹 + 明文」一同<br>加密成密文后，发送给服务器，服务器解密后，用相同的摘要算法算出发送过来的明文，通过比较客户端携带的「指纹」和当前算出的「指纹」做比较，若「指纹」相同，说明数据是完整的。</p></li><li><p>数字证书</p><p>客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。</p><p>这就存在些问题，如何保证公钥不被篡改和信任度？</p><p>所以这里就需要借助第三方权威机构 <code>CA</code> （数字证书认证机构），将<strong>服务器公钥放在数字证书</strong>（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。</p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215150946771.png" alt="image-20201215150946771"></p></li></ol><h2 id="HTTP-1-1、HTTP-2、HTTP-3-演变"><a href="#HTTP-1-1、HTTP-2、HTTP-3-演变" class="headerlink" title="HTTP/1.1、HTTP/2、HTTP/3 演变"></a>HTTP/1.1、HTTP/2、HTTP/3 演变</h2><h3 id="说说-HTTP-1-1-相比-HTTP-1-0-提高了什么性能？"><a href="#说说-HTTP-1-1-相比-HTTP-1-0-提高了什么性能？" class="headerlink" title="说说 HTTP/1.1 相比 HTTP/1.0 提高了什么性能？"></a>说说 HTTP/1.1 相比 HTTP/1.0 提高了什么性能？</h3><p>HTTP/1.1 相比 HTTP/1.0 性能上的改进：</p><ul><li>使用 <strong>TCP 长连接</strong>的方式改善了 HTTP/1.0 短连接造成的性能开销。</li><li>支持 管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。</li></ul><p>HTTP/1.1 还是有性能瓶颈：</p><ul><li>请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 <code>Body</code> 的部分；</li><li>发送冗长的首部。每次互相发送相同的首部造成的浪费较多；</li><li>服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；</li><li>没有请求优先级控制；</li><li>请求只能从客户端开始，服务器只能被动响应。</li></ul><p>那上面的 HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？</p><p>HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。</p><h3 id="HTTP-2-相比-HTTP-1-1-性能上的改进"><a href="#HTTP-2-相比-HTTP-1-1-性能上的改进" class="headerlink" title="HTTP/2 相比 HTTP/1.1 性能上的改进"></a>HTTP/2 相比 HTTP/1.1 性能上的改进</h3><ol><li><p><strong>头部压缩</strong></p><p>HTTP/2 会<strong>压缩头</strong>（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你<strong>消除重复的分</strong>。</p><p>这就是所谓的 <code>HPACK</code> 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就<strong>提高速度</strong>了。</p></li><li><p><strong>二进制格式</strong></p><p>HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了<strong>二进制格式。</strong></p><p>头信息和数据体都是二进制，并且统称为帧（frame）：<strong>头信息帧和数据帧</strong>。</p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215152141511.png" alt="image-20201215152141511"></p><p>这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这<strong>增加了数据传输的效率</strong>。</p></li><li><p><strong>数据流</strong></p><p>HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。</p><p>每个请求或回应的所有数据包，称为一个数据流（<code>Stream</code>）。</p><p>每个数据流都标记着一个独一无二的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数</p><p>客户端还可以<strong>指定数据流的优先级</strong>。优先级高的请求，服务器就先响应该请求。</p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215152242276.png" alt="image-20201215152242276"></p></li><li><p><strong>多路复用</strong></p><p>HTTP/2 是可以在<strong>一个连接中并发多个请求或回应，而不用按照顺序一一对应</strong>。</p><p>移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，<strong>降低了延迟，大幅度提高了连接的利用率</strong>。</p><p>举例来说，在一个 TCP 连接里，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程非常耗时，于是就回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分。</p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215152403683.png" alt="image-20201215152403683"></p></li><li><p><strong>服务器推送</strong></p><p>HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以<strong>主动</strong>向客户端发送消息。</p><p>举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会用到的 JS、CSS 文件等静态资源主动发给客户端，<strong>减少延时的等待</strong>，也就是服务器推送（Server Push，也叫 Cache Push）。</p></li></ol><h3 id="HTTP-2-有哪些缺陷？HTTP-3-做了哪些优化？"><a href="#HTTP-2-有哪些缺陷？HTTP-3-做了哪些优化？" class="headerlink" title="HTTP/2 有哪些缺陷？HTTP/3 做了哪些优化？"></a>HTTP/2 有哪些缺陷？HTTP/3 做了哪些优化？</h3><p>HTTP/2 主要的问题在于：多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。</p><p>所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的<strong>所有的 HTTP 请求都必须等待这个丢了的包被重传回来</strong>。</p><ul><li>HTTP/1.1 中的管道（ pipeline）传输中如果有一个请求阻塞了，那么队列后请求也统统被阻塞住了</li><li>HTTP/2 多请求复用一个TCP连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。</li></ul><p>这都是基于 TCP 传输层的问题，所以 <strong>HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215152550236.png" alt="image-20201215152550236"></p><p>UDP 发生是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的一个丢包全部重传问题。</p><p>大家都知道 UDP 是不可靠传输的，但基于 UDP 的 <strong>QUIC 协议</strong> 可以实现类似 TCP 的可靠性传输。</p><ul><li>QUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，<strong>其他流不会受到影响</strong>。</li><li>TL3 升级成了最新的 <code>1.3</code> 版本，头部压缩算法也升级成了 <code>QPack</code>。</li><li>HTTPS 要建立一个连接，要花费 6 次交互，先是建立三次握手，然后是 <code>TLS/1.3</code> 的三次握手。QUIC 直接把以往的 TCP 和 <code>TLS/1.3</code> 的 6 次交互<strong>合并成了 3 次，减少了交互次数</strong></li></ul><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215152614617.png" alt="image-20201215152614617"></p><p>所以， QUIC 是一个在 UDP 之上的<strong>伪</strong> TCP + TLS + HTTP/2 的多路复用的协议。</p><p>QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题。所以 HTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。</p><h2 id="无状态协议"><a href="#无状态协议" class="headerlink" title="无状态协议"></a>无状态协议</h2><p>无状态协议就是指浏览器对于事务的处理没有记忆能力。例如比如客户请求获得网页之后关闭浏览器，然后再次启动浏览器，登陆该网站，但是服务器并不知道客户关闭了一次浏览器。</p><p>HTTP 就是一种无状态的协议，他对用户的操作没有记忆能力。可能大多数用户不相信，他可能觉得每次输入用户名和密码登陆一个网站后，下次登陆就不再重新输入用户名和密码了。这其实不是 HTTP 做的事情，起作用的是一个叫做 <code>小甜饼(Cookie)</code> 的机制。它能够让浏览器具有<code>记忆</code>能力。</p><p>如果你的浏览器允许 cookie 的话，查看方式 <strong>chrome://settings/content/cookies</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215172321303.png" alt="image-20201215172321303"></p><p>当你向服务端发送请求时，服务端会给你发送一个认证信息，服务器第一次接收请求时，开辟了一块Session空间（创建了Session对象）</p><p>同时生成一个sessionID,并通过响应头的Set-Cookie: JSESSIONID=XXXXXXX 命令，向客户端发送要求设置Cookie的响应；客户端接收响应后，在本机客户端设置一个JSESSIONID=XXXXXXX 的 Cookie 信息，该 Cookie 的过期时间为浏览器会话结束。</p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215173131296.png" alt="image-20201215173131296"></p><p>​    接下来客户端每次向同一个网站发送请求时，请求头都会带上该Cookie信息（包含sessionid）,然后，服务器通过读取请求头中cookie信息，获取名称为JSESSIONID 的值，得到每次请求SessionID，这样，你的浏览器才具有记忆能力。</p><p><img src="https://jameslin23.gitee.io/2020/12/15/http%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/image-20201215173524513.png" alt="image-20201215173524513"></p><p>​     还有一种方式是使用 JWT 机制，它也是能够让你的浏览器具有记忆能力的一种机制。与 Cookie 不同，JWT 是保存在客户端的信息，它广泛的应用于单点登录的情况。JWT 具有两个特点</p><ul><li>JWT 的 Cookie 信息存储在<code>客户端</code>，而不是服务端内存中。也就是说，JWT 直接本地进行验证就可以，验证完毕后，这个 Token 就会在 Session 中随请求一起发送到服务器，通过这种方式，可以节省服务器资源，并且 token 可以进行多次验证。</li><li>JWT 支持跨域认证，Cookies 只能用在<code>单个节点的域</code>或者它的<code>子域</code>中有效。如果它们尝试通过第三个节点访问，就会被禁止。使用 JWT 可以解决这个问题，使用 JWT 能够通过<code>多个节点</code>进行用户认证，也就是我们常说的<code>跨域认证</code>。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;HTTP 基本概念&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Get 与 Post&lt;/strong&gt;&lt;
      
    
    </summary>
    
      <category term="计算机网络" scheme="https://jameslin23.gitee.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="https://jameslin23.gitee.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>TCP-IP</title>
    <link href="https://jameslin23.gitee.io/2020/12/14/TCP-IP/"/>
    <id>https://jameslin23.gitee.io/2020/12/14/TCP-IP/</id>
    <published>2020-12-14T01:47:40.000Z</published>
    <updated>2020-12-15T02:15:48.462Z</updated>
    
    <content type="html"><![CDATA[<h2 id="OSI标准模型"><a href="#OSI标准模型" class="headerlink" title="OSI标准模型"></a>OSI标准模型</h2><p>OSI标准模型是7层架构</p><p><img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201214100223229.png" alt="image-20201214100223229"></p><p>​    <img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201214100620029.png" alt="image-20201214100620029"></p><ul><li><strong>应用层</strong>: 应用层是OSI标准模型的最顶层,是直接为应用进程提供服务。其作用在实现多个系统应用进程相互通信的同时，完成一系列业务处理所需要的服务。包括文件传输、电子邮件远程登录和远程接口调用等协议。</li><li><strong>表示层</strong>: 表示层向上对应用服务，向下接收会话层提供的服务，表示层位于OSI标准模型的第六层，表示层的主要作用就是将设备的固有数据格式转换为网络标准传输格式。</li><li><strong>会话层</strong>: 会话层位于OSI标准模型的第五层，它是建立在传输层之上，利用传输层提供的服务建立和维持会话。</li><li><strong>传输层</strong>: 传输层为上面的应用层提供通讯服务,负责将上层数据分段并提供端到端的,可靠（TCP）或者不可靠（UDP）的传输，以及端到端的差错控制和流量控制</li><li><strong>网络层</strong>: 实现两个端系统之间的数据透明传送，具体功能包括寻址和路由选择、连接的建立、保持和终止等。它提供的服务使传输层不需要了解网络中的数据传输和交换技术。（协议：IP、ICMP协议、ARR、RAPP协议，设备: 路由器）</li><li><strong>链路层</strong>: 最基本服务是将来自网络层的数据可靠传输到相临节点的目标机（协议：以太网协议，设备：网桥和交换机）</li><li><strong>物理层</strong>: 为上层提供了一个传输数据可靠的物理媒介</li></ul><h2 id="TCP-IP体系"><a href="#TCP-IP体系" class="headerlink" title="TCP/IP体系"></a>TCP/IP体系</h2><p>TCP/IP协议说的不仅仅只是TCP/IP这两种协议、TCP/IP指的协议簇，简单来说就是一系列协议的综合</p><p><img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201214110541195.png" alt="image-20201214110541195"></p><p>  TCP/IP 协议是我们程序员接触最多的协议，OSI 模型共有七层，从下到上分别是物理层、数据链路层、网络层、运输层、会话层、表示层和应用层。但是这显然是有些复杂的，所以在 TCP/IP 协议中，它们被简化为了四个层次</p><p><img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201214110803250.png" alt="image-20201214110803250"></p><h3 id="各层定义"><a href="#各层定义" class="headerlink" title="各层定义"></a>各层定义</h3><h4 id="通信链路层"><a href="#通信链路层" class="headerlink" title="通信链路层"></a>通信链路层</h4><p>通信链路层包括物理层和链路层</p><h4 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h4><p><strong>实现两个端系统之间的数据传送，具体功能包括寻址和路由选择、连接的建立、保持和终止等。它提供的服务使传输层不需要了解网络中的数据传输和交换技术。</strong></p><p><strong>提供两种服务</strong></p><ul><li><p><strong>虚电路服务</strong></p><p>虚电路表示只是一条逻辑上的链接，分组都沿着这条逻辑链接按照存储转发的方式发送，而不是真正建立了一个物理连接。</p><p><img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201214111803331.png" alt="image-20201214111803331"></p></li><li><p><strong>数据报服务</strong></p><p>提供简单灵活、无连接、尽最大努力交付的数据报服务</p><p><img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201214112827717.png" alt="image-20201214112827717"></p></li></ul><p><strong>包括协议</strong></p><ul><li><p><strong>IP协议(Internet Protocol,因特网协议)</strong></p><p>IP地址由四段组成，每个字段是一个字节，8位，最大值是255</p><p>IP地址由两部分组成，即网络地址和主机地址。网络地址表示其属于互联网的哪一个网络，主机地址表示其属于该网络中的哪一台主机。二者是主从关系。</p><p>IP地址的四大类型标识的是网络中的某台主机。IPv4的地址长度为32位，共4个字节，但实际中我们用<a href="http://baike.baidu.com/view/828066.htm" target="_blank" rel="noopener">点分十进制</a>记法。</p><p><img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201215101315110.png" alt="image-20201215101315110"></p><p>IP地址根据网络号和主机号来分,分为A、B、C、三类及特殊地址D、E。全0和全1都不保留不用。</p><p>A类：1.0.0.0 ~ 127.255.255.255        私有：10.0.0.0~10.255.255.255</p><p>B类：128.0.0.0 ~ 191.255.255.255    私有：172.16.0.0～172.31.255.255 </p><p>C类：192.0.0.0~ 223.255.255.255     私有：192.168.0.0~192.168.255.255</p><p>D类：224.0.0.0 ~ 239.255.255.255</p><p>E类：240.0.0.0~247.255.255.255</p><p>回环地址：127.0.0.0/8被用作回环地址，回环地址表示本机的地址，常用于对本机的测试，用的最多的是127.0.0.1。</p><p><img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201214115539456.png" alt="image-20201214115539456"></p></li><li><p><strong>ICMP协议(Internet Control Message Protocol，因特网控制报文协议)</strong></p></li><li><p><strong>ARP协议（Address Resolution Protocol，地址解析协议）</strong></p><p>从网络层使用IP地址，解析出数据链路层使用的硬件地址（由IP地址解析出硬件地址）</p><p>当主机A预向本局域网上的某个主机B发送IP数据报时，就先其ARP高速缓存中查看有无主机B的IP地址。</p><ul><li>有，就可查出其对应的硬件地址，再将此硬件地址写入MAC帧，然后通过局域网将该MAC帧发往此硬件地址。</li><li>没有，ARP进程在本局域网上广播发送一个ARP请求分组。收到ARP响应分组后，将得到IP地址到硬件地址的映射写入ARP高速缓存。</li></ul></li><li><p><strong>RARP协议（Reverse Address Resolution Protocol，逆地址解析协议）</strong></p></li></ul><h4 id="传输层"><a href="#传输层" class="headerlink" title="传输层"></a>传输层</h4><p><strong>TCP/IP协议是Internet最基本的协议、Internet国际互联网络的基础，由网络层的IP协议和传输层的TCP协议组成。通俗而言：TCP负责发现传输的问题，一有问题就发出信号，要求重新传输，直到所有数据安全正确地传输到目的地。而IP是给因特网的每一台联网设备规定一个地址。</strong></p><h5 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h5><p>TCP 是一种可靠的协议，它能够保证数据包的可靠性交付，TCP 能够正确处理传输过程中的丢包、传输顺序错乱等异常情况。此外，TCP 还提供拥塞控制用于缓解网络拥堵。</p><p><strong>TCP报文首部格式：</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201214135505549.png" alt="image-20201214135505549"></p><p><strong>三次握手</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201214135909598.png" alt="image-20201214135909598"></p><ul><li>建立连接时，客户端发送syn包（syn=j）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。</li><li>服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；</li><li>客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。</li></ul><p><strong>总结:</strong> 因为TCP面向连接，可靠的，3次足以满足一个安全连接请求和应答。clinet发出第一个连接请求报文段并没有丢失，而是在某个网络节点长时间堵塞，以致于延误连接释放以后某个时间点才到达server端，server端以为是clinet发送新请求，像客户端发送确认报文，如果不建立3次连接，只要客户端发送确认报文就建立连接，并一直等待clinet发来的数据，这样server端资源就被占用浪费了。</p><p><strong>4次挥手</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201214141613712.png" alt="image-20201214141613712"></p><blockquote><p>1）客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。<br>2）服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。<br>3）客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。<br>4）服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。<br>5）客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。<br>6）服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。</p></blockquote><p><strong>总结：</strong> TCP面向连接，可靠的，断开连接需要双方都同意，才能断开连接。所以满足条件需要4次。</p><h5 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h5><p>UDP用户数据报协议,是面向无连接的通讯协议，UDP数据包括目的端口号和源端口号信息，由于通讯不需要连接，所以可以实现广播发送。</p><p><img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201214142941374.png" alt="image-20201214142941374"></p><p><strong>TCP</strong> <strong>与</strong> <strong>UDP</strong> <strong>的区别：TCP是面向连接的，可靠的字节流服务；UDP是面向无连接的，不可靠的数据报服务。</strong></p><h4 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h4><p>在TCP/IP协议簇中，将OSI标准模型中的会话层，表示层都归为了应用层。应用层的架构大多属于客户端/服务端，提供服务的程序叫做服务端，接受服务的程序就做客户端。在这种架构中，服务端通常会提前部署到服务器上，等待客户端连接，从而提供服务。</p><p><img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201214161849711.png" alt="image-20201214161849711"></p><h3 id="传输过程"><a href="#传输过程" class="headerlink" title="传输过程"></a>传输过程</h3><h4 id="数据包结构"><a href="#数据包结构" class="headerlink" title="数据包结构"></a>数据包结构</h4><p><img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201214162007978.png" alt="image-20201214162007978"></p><p>每一分层中，都会对所发送的数据增加一个首部，这个首部中包含该层必要的信息。每一层都会对数据进行处理并在数据包中附上这一层的必要信息。</p><h4 id="数据包发送历程"><a href="#数据包发送历程" class="headerlink" title="数据包发送历程"></a>数据包发送历程</h4><p>假设主机 A 和主机 B 进行通信，主机 A 想要向主机 B 发送一个数据包，都会经历哪些奇特的操作？</p><p><strong>1、应用层的处理</strong></p><p>主机 A 也就是用户点击了某个应用或者打开了一个聊天窗口输入了<code>cxuan</code>，然后点击了发送，那么这个 cxuan 就作为一个数据包遨游在了网络中，等下还没完呢，应用层还需要对这个数据包进行处理，包括字符编码、格式化等等，这一层其实是 OSI 中表现层做的工作，只不过在 TCP/IP 协议中都归为了应用层。</p><p>数据包在发送的那一刻建立 TCP 连接，这个连接相当于通道，在这之后其他数据包也会使用通道传输数据。</p><p><strong>2、传输层处理</strong></p><p>为了描述信息能准确的到达另一方，我们使用 TCP 协议来进行描述。TCP 会根据应用的指示，负责建立连接、发送数据和断开连接。</p><p>TCP 会在应用数据层的前端附加一个 TCP 首部字段，TCP 首部包含了<code>源端口号</code> 和 <code>目的端口号</code>，这两个端口号用于表明数据包是从哪里发出的，需要发送到哪个应用程序上；TCP 首部还包含<code>序号</code>，用以表示该包中数据是发送端整个数据中第几个字节的序列号；TCP 首部还包含 <code>校验和</code>，用于判断数据是否损坏，随后将 TCP 头部附加在数据包的首部发送给 IP。</p><p><strong>3、网络层处理</strong></p><p>网络层主要负责处理数据包的是 IP 协议，IP 协议将 TCP 传过来的 TCP 首部和数据结合当作自己的数据，并在 TCP 首部的前端加上自己的 IP 首部。因此，IP 数据包后面会紧跟着 TCP 数据包，后面才是数据本身。IP 首部包含目的和源地址，紧随在 IP 首部的还有用来判断后面是 TCP 还是 UDP 的信息。</p><p>IP 包生成后，会由路由控制表判断应该发送至哪个主机，IP 修饰后的数据包继续向下发送给路由器或者网络接口的驱动程序，从而实现真正的数据传输。</p><p><strong>4、通信链路层处理</strong></p><p>经由 IP 传过来的数据包，以太网会给数据附上以太网首部并进行发送处理。以太网首部包含接收端的 MAC 地址、发送端的 MAC 地址以及标志以太网类型的以太网数据协议等</p><h4 id="数据包接收历程"><a href="#数据包接收历程" class="headerlink" title="数据包接收历程"></a>数据包接收历程</h4><p><strong>1、通信链路的解析</strong></p><p>目标主机收到数据包后，首先会从以太网的首部找到MAC地址判断是否是发给自己的数据包，如果不是发给自己的数据包则会丢弃该数据包。</p><p>如果收到的数据包是发送给自己，就会查以太网类型判断是哪种协议，如果是IP协议就扔给IP协议进行处理，如果是ARR协议就扔给ARP协议进行处理。如果协议无法识别，就丢弃。</p><p><strong>2、网络层的解析</strong></p><p>经过以太网处理后的数据包扔给网络层处理，我们假设协议类型是IP协议，那么在IP收到数据包后就会解析IP首部，判断IP首部中IP地址是不是与自己匹配，如果匹配接收并判断上一层协议是TCP或者UDP,不匹配直接丢弃。</p><blockquote><p>注意：在路由转发的过程中，有的时候 IP 地址并不是自己的，这个时候需要借助路由表协助处理</p></blockquote><p><strong>3、传输层的处理</strong></p><p>在传输层中，我们默认使用TCP协议，在TCP处理过程中，首先会计算一下校验和，判断数据是否被损坏。然后检测是否按照序号接收数据，最后检查端口号，确定是哪个应用程序。数据被完整的识别，会传递给由端口号识别的应用程序进行处理。</p><p><strong>4、应用程序的处理</strong></p><p>接收端指定的应用程序会处理发送方传递过来的数据，通过解码等操作识别出数据的内容，然后把对应的数据存储在磁盘上，返回一个保存成功的消息给发送方，如果保存失败，则返回错误消息。</p><p><strong>下面是完整的处理过程和解析过程</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201214164505242.png" alt="image-20201214164505242"></p><p><strong>数据包经过每层后，该层协议都会在数据包附上包首部，一个完整的包首部图如下所示</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/14/TCP-IP/image-20201214164638295.png" alt="image-20201214164638295"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;OSI标准模型&quot;&gt;&lt;a href=&quot;#OSI标准模型&quot; class=&quot;headerlink&quot; title=&quot;OSI标准模型&quot;&gt;&lt;/a&gt;OSI标准模型&lt;/h2&gt;&lt;p&gt;OSI标准模型是7层架构&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://jameslin23.g
      
    
    </summary>
    
      <category term="计算机网络" scheme="https://jameslin23.gitee.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="计算机网络" scheme="https://jameslin23.gitee.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>平衡二叉搜索树</title>
    <link href="https://jameslin23.gitee.io/2020/12/12/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/"/>
    <id>https://jameslin23.gitee.io/2020/12/12/平衡二叉搜索树/</id>
    <published>2020-12-12T03:36:28.000Z</published>
    <updated>2020-12-15T02:08:31.855Z</updated>
    
    <content type="html"><![CDATA[<h2 id="平衡二叉搜索树"><a href="#平衡二叉搜索树" class="headerlink" title="平衡二叉搜索树"></a>平衡二叉搜索树</h2><p>平衡二叉搜索树简称:<strong>BBST</strong></p><p><strong>平衡二叉搜索树类型</strong></p><ul><li><p><strong>AVL树</strong></p><p>Windows NT 内核中广泛使用</p></li><li><p><strong>红黑树</strong></p><p>C++ STL(比如map、set)</p><p>java的TreeMap、TreeSet、HashMap、HashSet</p><p>Linux的进程调度</p><p>Ngix的timer管理</p></li></ul><h2 id="AVL树"><a href="#AVL树" class="headerlink" title="AVL树"></a>AVL树</h2><p><strong>平衡因子(Balance Factor): 某节点的左右子树的高度差</strong></p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul><li>每个节点的平衡因子只可能是1、0、-1(如果绝对值-1,如果超过1,称为失衡)</li><li>每个节点的左右子树高度差不超过1</li><li>搜索、添加、删除的时间复杂度是o(logn)</li></ul><p><img src="https://jameslin23.gitee.io/2020/12/12/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/image-20201212141626132.png" alt="image-20201212141626132"></p><h3 id="旋转"><a href="#旋转" class="headerlink" title="旋转"></a>旋转</h3><p>调整旋转有4种情况</p><h4 id="LL-右旋转-单旋"><a href="#LL-右旋转-单旋" class="headerlink" title="LL-右旋转(单旋)"></a>LL-右旋转(单旋)</h4><p>当左子树出现不平衡情况，也就是LL(左节点-左节点)，就需要右旋转</p><ul><li>g.left = p.right</li><li>p.right = g</li><li>让P成为这个棵子树的根节点</li><li>仍然是一颗二叉搜索树: T0&lt; n &lt; T1 &lt; p &lt; T2 &lt; g &lt; T3</li></ul><p>需要注意的维护内容</p><ul><li>T2、p、g的parent属性</li><li>先后更新g、p的高度</li></ul><p><img src="https://jameslin23.gitee.io/2020/12/12/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/image-20201212142308077.png" alt="image-20201212142308077"></p><h4 id="RR-左旋转-单旋"><a href="#RR-左旋转-单旋" class="headerlink" title="RR - 左旋转(单旋)"></a>RR - 左旋转(单旋)</h4><p>当右子树出现不平衡情况，也就是RR(右节点-右节点)，就需要左旋转</p><ul><li>g.right = p.leftt</li><li>p.left = g</li><li>让p成为这棵子树的根节点</li><li>仍然是一颗二叉搜索树: T0 &lt; g &lt; T1 &lt; p &lt; T2 &lt;  n &lt;T3</li></ul><p>需要维护内容</p><ul><li>T1、p、g的parent属性</li><li>先后更新g、p的高度</li></ul><p><img src="https://jameslin23.gitee.io/2020/12/12/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/image-20201212142837427.png" alt="image-20201212142837427"></p><h4 id="LR-左旋转，右旋转"><a href="#LR-左旋转，右旋转" class="headerlink" title="LR-左旋转，右旋转"></a>LR-左旋转，右旋转</h4><p>出现LR情况、需要2次旋转，才能达到平衡</p><p><img src="https://jameslin23.gitee.io/2020/12/12/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/image-20201212143323528.png" alt="image-20201212143323528"></p><h4 id="RL-右旋转-左旋转"><a href="#RL-右旋转-左旋转" class="headerlink" title="RL-右旋转,左旋转"></a>RL-右旋转,左旋转</h4><p><img src="https://jameslin23.gitee.io/2020/12/12/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/image-20201212143422067.png" alt="image-20201212143422067"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>添加</strong></p><ul><li>可能导致所有祖先节点都失衡</li><li>只要让高度最低的失衡节点恢复平衡,整棵树就恢复平衡[仅需o(1)次调整]</li></ul><p><strong>删除</strong></p><ul><li>只可能会导致父节点失衡</li><li>让父节点恢复平衡后,可能会导致更高层的祖先节点失衡[最多需要o(logn)次调整]</li></ul><p><strong>平均时间复杂度</strong></p><ul><li>搜索: o(logn)</li><li>添加:o(logn)，仅需o(1)次调整</li><li>删除:o(logn),最多需要o(logn)次旋转操作</li></ul><h2 id="红黑树"><a href="#红黑树" class="headerlink" title="红黑树"></a>红黑树</h2><h3 id="特点（5大特点）"><a href="#特点（5大特点）" class="headerlink" title="特点（5大特点）"></a>特点（5大特点）</h3><ul><li><strong>节点是RED或者BLACK</strong></li><li><strong>根节点是BLACK</strong></li><li><strong>叶子节点(外部节点,空节点) 都是BLACK</strong></li><li><strong>RED节点的子节点都是BLACK</strong><ul><li>RED节点的parent都是BLACK</li><li>从根节点到叶子节点的所有路径不能有2个连续的RED节点</li></ul></li><li><strong>从任一节点到叶子节点的所有路径都包含相同的BLACK节点</strong></li></ul><p><img src="https://jameslin23.gitee.io/2020/12/12/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/image-20201212144943468.png" alt="image-20201212144943468"></p><ul><li>红黑树和4阶B树(2-3-4树)具有等价性</li><li>BLACK节点与它的RED字节点融合在一起，形成1个B树节点</li><li>红黑树的BLACK节点个树与4阶B树的节点总个树相等</li></ul><h3 id="添加过程"><a href="#添加过程" class="headerlink" title="添加过程"></a>添加过程</h3><p>总共3大类，12种情况</p><ul><li><p>4种情况满足红黑情况的性质，不用修改。 <strong>父节点为黑色</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/12/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/image-20201212151113598.png" alt="image-20201212151113598"></p></li><li><p>有八种情况满足红黑树性质：父节点为红色（Double Red）</p><p><img src="https://jameslin23.gitee.io/2020/12/12/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/image-20201212151223612.png" alt="image-20201212151223612"></p></li></ul><ul><li><p>其中4种叔父(<strong>父节点的兄弟</strong>)节点是黑色</p><p>这4种情况分别是RR/LL/RL/LR</p><p><strong>RR/LL</strong></p><p>1、父亲节点染成黑色BLACK,祖父节点染成RED</p><p>2、祖父节点进行单旋</p><p>3、RR(左旋)、LL(右旋)</p><p><img src="https://jameslin23.gitee.io/2020/12/12/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/image-20201212152631233.png" alt="image-20201212152631233"></p><p><strong>RL/LR</strong></p><p>1、自己染成黑色BLACK,祖父节点染成红色</p><p>2、进行双旋操作</p><p>3、LR(父节点左旋，祖父节点右旋)</p><p>4、RL(父节点右旋，祖父节点左旋)</p><p><img src="https://jameslin23.gitee.io/2020/12/12/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/image-20201212153314487.png" alt="image-20201212153314487"></p></li><li><p>4种叔父(<strong>父节点的兄弟</strong>)节点是红色</p><p>这4种情况也分别是RR/LL/RL/LR</p><p><strong>RR</strong></p><p>1、父节点和叔父节点染成黑色</p><p>2、祖父节点(染成红色)向上合并，当做新添加节点进行处理</p><p>3、向上合并时候有可能继续发生上益</p><p><img src="https://jameslin23.gitee.io/2020/12/12/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/image-20201212153935525.png" alt="image-20201212153935525"></p></li></ul><p>​    </p><h3 id="删除过程"><a href="#删除过程" class="headerlink" title="删除过程"></a>删除过程</h3><ul><li>A—删除的是叶子节点且该叶子节点是红色的，无需修复。</li><li>B—删除的是叶子节点且叶子节点是黑色的，会破坏特征5，需要修复</li><li>C—删除的节点（P）有一个子节点(S)，通过置换的方式，然后进行删除。<ul><li>S为红，P为黑，对应A情况</li></ul></li></ul><p>待补充（看算法导论为准）</p><h2 id="AVL树-VS-红黑树"><a href="#AVL树-VS-红黑树" class="headerlink" title="AVL树 VS 红黑树"></a>AVL树 VS 红黑树</h2><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p><strong>AVL树</strong></p><ul><li>平衡标准严格:每个左右子树的高度差不超过1</li><li>最大高度是1.44*log2(n+1)-1.328(100w节点，AVL树最大树高28)</li><li>搜索、添加、删除都是o(logn)复杂度，其中添加仅仅需要o(1)次调整、删除最多需要o(logn)次旋转调整</li></ul><p><strong>红黑树</strong></p><ul><li>平衡标准比较宽松:没有一条路径会大于其他路径2倍</li><li>最大高度是2*log2(n+1)(100万个节点，红黑树最大树高40)</li><li>搜索、添加、删除都是o(logn)复杂度，其中添加、删除都仅仅o(1)次旋转调整</li></ul><p><strong>选择</strong></p><ul><li>搜索的次数远远大于插入和删除,选择AVL树；搜索、插入、删除几乎差不多，选择红黑树</li><li>相对AVL树来说，红黑树牺牲了部分平衡以换取插入/删除操作时少量旋转操作，整体来说性能要优于AVL树</li><li>红黑树的平均统计性能优于AVL树,实际应用中更多选择使用红黑树</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;平衡二叉搜索树&quot;&gt;&lt;a href=&quot;#平衡二叉搜索树&quot; class=&quot;headerlink&quot; title=&quot;平衡二叉搜索树&quot;&gt;&lt;/a&gt;平衡二叉搜索树&lt;/h2&gt;&lt;p&gt;平衡二叉搜索树简称:&lt;strong&gt;BBST&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;平衡二
      
    
    </summary>
    
      <category term="数据结构与算法" scheme="https://jameslin23.gitee.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="数据结构与算法" scheme="https://jameslin23.gitee.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>ZooKeeper的ZAB协议</title>
    <link href="https://jameslin23.gitee.io/2020/12/11/ZooKeeper%E7%9A%84ZAB%E5%8D%8F%E8%AE%AE/"/>
    <id>https://jameslin23.gitee.io/2020/12/11/ZooKeeper的ZAB协议/</id>
    <published>2020-12-11T07:07:32.000Z</published>
    <updated>2020-12-11T09:21:32.328Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Zab（Zookeeper Atomic Broadcast）是为ZooKeeper协设计的崩溃恢复原子广播协议，它保证zookeeper集群数据的<strong>一致性和命令的全局有序性。</strong></p><h2 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h2><p>在介绍zab协议之前首先要知道zookeeper相关的几个概念，才能更好的了解zab协议。</p><ul><li><p><strong>集群角色</strong></p><p><strong>Leader</strong>: 同一时间集群总有允许有一个Leader,提供对客户端的读写功能，负责将数据同步至各个节点。</p><p><strong>Follower</strong>: 提供对客户端读功能,写请求则转发给Leader处理,当Leader崩溃失联之后，参与Leader选举</p><p><strong>Observer</strong>:不参与Leader选举</p></li><li><p><strong>服务状态</strong></p><ol><li>LOOKING：当节点认为群集中没有Leader，服务器会进入LOOKING状态，目的是为了查找或者选举Leader；</li><li>FOLLOWING：follower角色；</li><li>LEADING：leader角色；</li><li>OBSERVING：observer角色；</li></ol><p>Zookeeper是通过自身的状态来区分自己所属的角色，来执行自己应该的任务。</p><p><strong>ZAB状态</strong>Zookeeper还给ZAB定义的4中状态，反应Zookeeper从选举到对外提供服务的过程中的四个步骤。状态枚举定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> ZabState &#123;</span><br><span class="line">    ELECTION, <span class="comment">// 集群进入选举状态，此过程会选出一个节点作为leader角色；</span></span><br><span class="line">    DISCOVERY,<span class="comment">// 连接上leader，响应leader心跳，并且检测leader的角色是否更改，通过此步骤之后选举出的leader才能执行真正职务；</span></span><br><span class="line">    SYNCHRONIZATION,<span class="comment">// 整个集群都确认leader之后，将会把leader的数据同步到各个节点，保证整个集群的数据一致性；</span></span><br><span class="line">    BROADCAST<span class="comment">// 过渡到广播状态，集群开始对外提供服务。</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>Zxid</strong></p><p>Zxid是Zab协议的一个事务编号,Zxid是一个64位数字,其中低32位是一个简单的单调递增计数器,针对客户每个一个事务请求,计数器+1；而高32位则代表Leader周期年代编号（epoch）。</p></li></ul><h2 id="选举"><a href="#选举" class="headerlink" title="选举"></a>选举</h2><h3 id="选举时机"><a href="#选举时机" class="headerlink" title="选举时机"></a>选举时机</h3><ul><li><strong>服务器初始化启动</strong></li><li><strong>服务器运行期间Leader故障</strong></li></ul><h3 id="启动时选举"><a href="#启动时选举" class="headerlink" title="启动时选举"></a>启动时选举</h3><p>假设一个 Zookeeper 集群中有5台服务器，id从1到5编号，并且它们都是最新启动的，没有历史数据</p><p><img src="https://jameslin23.gitee.io/2020/12/11/ZooKeeper%E7%9A%84ZAB%E5%8D%8F%E8%AE%AE/image-20201211154630630.png" alt="image-20201211154630630"></p><p>假设服务器依次启动，我们来分析一下选举过程：</p><p><strong>（1）服务器1启动</strong></p><p>发起一次选举，服务器1投自己一票，此时服务器1票数一票，不够半数以上（3票），选举无法完成。</p><p>投票结果：服务器1为1票。</p><p>服务器1状态保持为<code>LOOKING</code>。</p><p><strong>（2）服务器2启动</strong></p><p>发起一次选举，服务器1和2分别投自己一票，此时服务器1发现服务器2的id比自己大，更改选票投给服务器2。</p><p>投票结果：服务器1为0票，服务器2为2票。</p><p>服务器1，2状态保持<code>LOOKING</code></p><p><strong>（3）服务器3启动</strong></p><p>发起一次选举，服务器1、2、3先投自己一票，然后因为服务器3的id最大，两者更改选票投给为服务器3；</p><p>投票结果：服务器1为0票，服务器2为0票，服务器3为3票。此时服务器3的票数已经超过半数（3票），<strong>服务器3当选<code>Leader</code></strong>。</p><p>服务器1，2更改状态为<code>FOLLOWING</code>，服务器3更改状态为<code>LEADING</code>。</p><p><strong>（4）服务器4启动</strong></p><p>发起一次选举，此时服务器1，2，3已经不是LOOKING 状态，不会更改选票信息。交换选票信息结果：服务器3为3票，服务器4为1票。此时服务器4服从多数，更改选票信息为服务器3。</p><p>服务器4并更改状态为<code>FOLLOWING</code>。</p><p><strong>（5）服务器5启动</strong></p><p>与服务器4一样投票给3，此时服务器3一共5票，服务器5为0票。</p><p>服务器5并更改状态为<code>FOLLOWING</code>。</p><p><strong>最终的结果</strong>：</p><p>服务器3是 <code>Leader</code>，状态为 <code>LEADING</code>；其余服务器是 <code>Follower</code>，状态为 <code>FOLLOWING</code>。</p><h3 id="运行时期的Leader选举"><a href="#运行时期的Leader选举" class="headerlink" title="运行时期的Leader选举"></a>运行时期的Leader选举</h3><p>在Zookeeper运行期间 <code>Leader</code> 和 <code>非 Leader</code> 各司其职，当非Leader服务器宕机或者加入不会影响Leader，但是一旦Leader服务器挂了,那么整个Zookeeper集群将<strong>暂停对外服务</strong>,会触发新一轮的选举。</p><p>初始状态下服务器3当选为<code>Leader</code>，假设现在服务器3故障宕机了，此时每个服务器上zxid可能都不一样，server1为99，server2为102，server4为100，server5为101</p><p><img src="https://jameslin23.gitee.io/2020/12/11/ZooKeeper%E7%9A%84ZAB%E5%8D%8F%E8%AE%AE/image-20201211160106980.png" alt="image-20201211160106980"></p><p>（1）状态变更。Leader 故障后，余下的<code>非 Observer</code> 服务器都会将自己的服务器状态变更为<code>LOOKING</code>，然后开始进入<code>Leader选举过程</code>。</p><p>（2）每个Server会发出投票。</p><p>（3）接收来自各个服务器的投票，如果其他服务器的数据比自己的新会改投票。</p><p>（4）处理和统计投票，每一轮投票结束后都会统计投票，超过半数即可当选。</p><p>（5）改变服务器的状态，宣布当选。</p><p><img src="https://jameslin23.gitee.io/2020/12/11/ZooKeeper%E7%9A%84ZAB%E5%8D%8F%E8%AE%AE/image-20201211160848185.png" alt="image-20201211160848185"></p><h2 id="传递"><a href="#传递" class="headerlink" title="传递"></a>传递</h2><p>集群在经过leader选举之后还会有连接leader和同步两个步骤，这里就不具体分析这两个步骤的流程了，主要介绍集群对外提供服务如何保证各个节点数据的一致性。</p><p>zab在广播状态中保证以下特征</p><ul><li><strong>可靠传递:</strong> 如果消息m由一台服务器传递，那么它最终将由所有服务器传递。</li><li><strong>全局有序:</strong> 如果一个消息a在消息b之前被一台服务器交付，那么所有服务器都交付了a和b，并且a先于b。</li><li><strong>全局有序:</strong> 如果一个消息a在消息b之前被一台服务器交付，那么所有服务器都交付了a和b，并且a先于b。</li></ul><p><strong>有序性</strong>是zab协议必须要保证的一个很重要的属性，因为zookeeper是以类似目录结构的数据结构存储数据的，必须要求命名的有序性。</p><p>比如一个命名a创建路径为/test，然后命名b创建路径为/test/123，如果不能保证有序性b命名在a之前，b命令会因为父节点不存在而创建失败。</p><p><img src="https://jameslin23.gitee.io/2020/12/11/ZooKeeper%E7%9A%84ZAB%E5%8D%8F%E8%AE%AE/image-20201211161516253.png" alt="image-20201211161516253"></p><p>​              如上图所示，整个写请求类似一个<strong>二阶段</strong>的提交。</p><p>  当收到客户端的写请求的时候会经历以下几个步骤：</p><ol><li>Leader收到客户端的写请求，生成一个事务（Proposal），其中包含了zxid；</li><li>Leader开始广播该事务，需要注意的是所有节点的通讯都是由一个FIFO的队列维护的；</li><li>Follower接受到事务之后，将事务写入本地磁盘，写入成功之后返回Leader一个ACK；</li><li>Leader收到过半的ACK之后，开始提交本事务，并广播事务提交信息</li><li>从节点开始提交本事务。</li></ol><p>有以上流程可知，zookeeper通过二阶段提交来保证集群中数据的一致性，因为只需要收到过半的ACK就可以提交事务，所以zookeeper的数据<strong>并不是强一致性。</strong></p><p><strong>zab协议的有序性保证是通过几个方面来体现的，第一是，服务之前用TCP协议进行通讯，保证在网络传输中的有序性；第二，节点之前都维护了一个FIFO的队列，保证全局有序性；第三，通过全局递增的zxid保证因果有序性。</strong></p><h3 id="状态流转"><a href="#状态流转" class="headerlink" title="状态流转"></a>状态流转</h3><p>前面介绍了zookeeper服务状态有四种，ZAB状态也有四种。这里就简单介绍一个他们之间的状态流转，更能加深对zab协议在zookeeper工作流程中的作用。</p><p><img src="https://jameslin23.gitee.io/2020/12/11/ZooKeeper%E7%9A%84ZAB%E5%8D%8F%E8%AE%AE/image-20201211162550315.png" alt="image-20201211162550315"></p><ol><li>服务在启动或者和leader失联之后服务状态转为LOOKING</li><li>如果leader不存在选举leader，如果存在直接连接leader，此时zab协议状态为ELECTION</li><li>如果有超过半数的投票选择同一台server，则leader选举结束，被选举为leader的server服务状态为LEADING，其他server服务状态为FOLLOWING/OBSERVING</li><li>所有server连接上leader，此时zab协议状态为DISCOVERY</li><li>leader同步数据给learner，使各个从节点数据和leader保持一致，此时zab协议状态为SYNCHRONIZATION</li><li>同步超过一半的server之后，集群对外提供服务，此时zab状态为BROADCAST</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Zab（Zookeeper Atomic Broadcast）是为ZooKeeper协设计的崩溃恢复原子广播协议，它保证zookeeper集
      
    
    </summary>
    
      <category term="服务中心" scheme="https://jameslin23.gitee.io/categories/%E6%9C%8D%E5%8A%A1%E4%B8%AD%E5%BF%83/"/>
    
    
      <category term="分布式" scheme="https://jameslin23.gitee.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>ZooKeeper</title>
    <link href="https://jameslin23.gitee.io/2020/12/11/ZooKeeper/"/>
    <id>https://jameslin23.gitee.io/2020/12/11/ZooKeeper/</id>
    <published>2020-12-11T02:12:20.000Z</published>
    <updated>2020-12-17T10:55:08.915Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><ul><li>ZooKeeper是一个<strong>分布式服务框架</strong>，可以用ZooKeeper来做：<strong>统一配置管理、统一命名服务、分布式锁、集群管理</strong>。</li><li>使用分布式系统就无法避免对节点管理的问题(需要实时感知节点的状态、对节点进行统一管理等等)，而由于这些问题处理起来可能相对麻烦和提高了系统的复杂性，ZooKeeper作为一个能够<strong>通用</strong>解决这些问题的中间件就应运而生了</li></ul><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p>那为什么ZooKeeper可以干那么多事？来看看ZooKeeper究竟是何方神物，在Wiki中其实也有提到：</p><blockquote><p>ZooKeeper nodes store their data in a hierarchical name space, much like a file system or a tree data structure</p></blockquote><p>ZooKeeper的数据结构，跟Unix文件系统非常类似，可以看做是一颗<strong>树</strong>，每个节点叫做<strong>ZNode</strong>。每一个节点可以通过<strong>路径</strong>来标识，结构图如下：</p><p><img src="https://jameslin23.gitee.io/2020/12/11/ZooKeeper/image-20201211102242102.png" alt="image-20201211102242102"></p><p>那ZooKeeper这颗”树”有什么特点呢？？ZooKeeper的节点我们称之为<strong>Znode</strong>，Znode分为<strong>两种</strong>类型：</p><ul><li><strong>短暂/临时(Ephemeral)</strong>：当客户端和服务端断开连接后，所创建的Znode(节点)<strong>会自动删除</strong></li><li><strong>持久(Persistent)</strong>：当客户端和服务端断开连接后，所创建的Znode(节点)<strong>不会删除</strong></li></ul><blockquote><p>ZooKeeper和Redis一样，也是C/S结构(分成客户端和服务端)</p></blockquote><p><img src="https://jameslin23.gitee.io/2020/12/11/ZooKeeper/image-20201211102441109.png" alt="image-20201211102441109"></p><h3 id="监听器"><a href="#监听器" class="headerlink" title="监听器"></a>监听器</h3><p>在上面我们已经简单知道了ZooKeeper的数据结构了，ZooKeeper还配合了<strong>监听器</strong>才能够做那么多事的。</p><p><strong>常见</strong>的监听场景有以下两项：</p><ul><li>监听Znode节点的<strong>数据变化</strong></li><li>监听子节点的<strong>增减变化</strong></li></ul><p><img src="https://jameslin23.gitee.io/2020/12/11/ZooKeeper/image-20201211102813557.png" alt="image-20201211102813557"></p><p><img src="https://jameslin23.gitee.io/2020/12/11/ZooKeeper/image-20201211102839298.png" alt="image-20201211102839298"></p><p>​      没错，通过<strong>监听+Znode节点(持久/短暂[临时])</strong>，ZooKeeper就可以玩出这么多花样了。</p><h3 id="统一配置管理"><a href="#统一配置管理" class="headerlink" title="统一配置管理"></a>统一配置管理</h3><p>比如我们现在有3个系统A、B、C、他们有三份配置,分别是ASystem.yml、BSystem.yml、CSystem.yml,然后这分配又非常类似,很多的配置项几乎都一样</p><ul><li>此时，如果我们要改变其中一份配置项的信息，很可能其他两份都要改。并且，改变了配置项的信息<strong>很可能就要重启系统</strong></li></ul><p>于是，我们希望把<code>ASystem.yml、BSystem.yml、CSystem.yml</code>相同的配置项抽取出来成一份<strong>公用</strong>的配置<code>common.yml</code>，并且即便<code>common.yml</code>改了，也不需要系统A、B、C重启。</p><p><img src="https://jameslin23.gitee.io/2020/12/11/ZooKeeper/image-20201211104510206.png" alt="image-20201211104510206"></p><p>做法：我们可以将<code>common.yml</code>这份配置放在ZooKeeper的Znode节点中，系统A、B、C监听着这个Znode节点有无变更，如果变更了，<strong>及时</strong>响应。</p><p><img src="https://jameslin23.gitee.io/2020/12/11/ZooKeeper/image-20201211104559004.png" alt="image-20201211104559004"></p><h3 id="统一命名服务"><a href="#统一命名服务" class="headerlink" title="统一命名服务"></a>统一命名服务</h3><p>统一命名服务的理解其实跟<strong>域名</strong>一样，是我们为这某一部分的资源给它<strong>取一个名字</strong>，别人通过这个名字就可以拿到对应的资源。</p><p>比如说，现在我有一个域名<code>www.java3y.com</code>，但我这个域名下有多台机器：</p><ul><li>192.168.1.1</li><li>192.168.1.2</li><li>192.168.1.3</li><li>192.168.1.4</li></ul><p><img src="https://jameslin23.gitee.io/2020/12/11/ZooKeeper/image-20201211104837641.png" alt="image-20201211104837641"></p><h3 id="分布锁"><a href="#分布锁" class="headerlink" title="分布锁"></a>分布锁</h3><p>我们可以使用ZooKeeper来实现分布式锁，那是怎么做的呢？？下面来看看：</p><p>系统A、B、C都去访问<code>/locks</code>节点</p><p><img src="https://jameslin23.gitee.io/2020/12/11/ZooKeeper/image-20201211104953698.png" alt="image-20201211104953698"></p><p>访问的时候会创建<strong>带顺序号的临时/短暂</strong>(<code>EPHEMERAL_SEQUENTIAL</code>)节点，比如，系统A创建了<code>id_000000</code>节点，系统B创建了<code>id_000002</code>节点，系统C创建了<code>id_000001</code>节点。</p><p><img src="https://jameslin23.gitee.io/2020/12/11/ZooKeeper/image-20201211105020998.png" alt="image-20201211105020998"></p><p>接着，拿到<code>/locks</code>节点下的所有子节点(id_000000,id_000001,id_000002)，<strong>判断自己创建的是不是最小的那个节点</strong></p><ul><li>如果是，则拿到锁。</li><li>释放锁：执行完操作后，把创建的节点给删掉</li><li>如果不是，则监听比自己要小1的节点变化</li></ul><p>举个例子：</p><ul><li>系统A拿到<code>/locks</code>节点下的所有子节点，经过比较，发现自己(<code>id_000000</code>)，是所有子节点最小的。所以得到锁</li><li>系统B拿到<code>/locks</code>节点下的所有子节点，经过比较，发现自己(<code>id_000002</code>)，不是所有子节点最小的。所以监听比自己小1的节点<code>id_000001</code>的状态</li><li>系统C拿到<code>/locks</code>节点下的所有子节点，经过比较，发现自己(<code>id_000001</code>)，不是所有子节点最小的。所以监听比自己小1的节点<code>id_000000</code>的状态</li><li>……</li><li>等到系统A执行完操作以后，将自己创建的节点删除(<code>id_000000</code>)。通过监听，系统C发现<code>id_000000</code>节点已经删除了，发现自己已经是最小的节点了，于是顺利拿到锁</li><li>….系统B如上</li></ul><p><strong>总结:</strong></p><p><strong>其实如果有客户端C、客户端D等N个客户端争抢一个zk分布式锁，原理都是类似的。</strong></p><ul><li>大家都是上来直接创建一个锁节点下的一个接一个的临时顺序节点</li><li>如果自己不是第一个节点，就对自己上一个节点加监听器</li><li>只要上一个节点释放锁，自己就排到前面去了，相当于是一个排队机制。</li></ul><p>临时顺序节点的另外一个用意就是，如果某个客户端创建临时顺序节点之后，不小心自己宕机了也没关系，zk感知到那个客户端宕机，会自动删除对应的临时顺序节点，相当于自动释放锁，或者是自动取消自己的排队。</p><h3 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h3><p>经过上面几个例子，我相信大家也很容易想到ZooKeeper是怎么”<strong>感知</strong>“节点的动态新增或者删除的了</p><p>还是以我们三个系统A、B、C为例，在ZooKeeper中创建<strong>临时节点</strong>即可：</p><p><img src="https://jameslin23.gitee.io/2020/12/11/ZooKeeper/image-20201211105142359.png" alt="image-20201211105142359"></p><p>​      只要系统A挂了，那<code>/groupMember/A</code>这个节点就会删除，通过<strong>监听</strong><code>groupMember</code>下的子节点，系统B和C就能够感知到系统A已经挂了。(新增也是同理)</p><p>除了能够感知节点的上下线变化，ZooKeeper还可以实现<strong>动态选举Master</strong>的功能。(如果集群是主从架构模式下)</p><p>原理也很简单，如果想要实现动态选举Master的功能，Znode节点的类型是带<strong>顺序号的临时节点</strong>(<code>EPHEMERAL_SEQUENTIAL</code>)就好了。</p><ul><li>Zookeeper会每次选举最小编号的作为Master，如果Master挂了，自然对应的Znode节点就会删除。然后让<strong>新的最小编号作为Master</strong>，这样就可以实现动态选举的功能了</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Zookeeper&quot;&gt;&lt;a href=&quot;#Zookeeper&quot; class=&quot;headerlink&quot; title=&quot;Zookeeper&quot;&gt;&lt;/a&gt;Zookeeper&lt;/h2&gt;&lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="服务中心" scheme="https://jameslin23.gitee.io/categories/%E6%9C%8D%E5%8A%A1%E4%B8%AD%E5%BF%83/"/>
    
    
      <category term="分布式" scheme="https://jameslin23.gitee.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>mysql之count用法</title>
    <link href="https://jameslin23.gitee.io/2020/12/10/mysql%E4%B9%8Bcount%E7%94%A8%E6%B3%95/"/>
    <id>https://jameslin23.gitee.io/2020/12/10/mysql之count用法/</id>
    <published>2020-12-10T11:35:17.000Z</published>
    <updated>2020-12-11T02:12:41.323Z</updated>
    
    <content type="html"><![CDATA[<p>这个常用的<strong>COUNT</strong>函数，却暗藏着很多玄机，尤其是在面试的时候，一不小心就会被虐。不信的话请尝试回答下以下问题：</p><blockquote><p>1、COUNT有几种用法？</p><p>2、COUNT(字段名)和COUNT(*)的查询结果有什么不同？</p><p>3、COUNT(1)和COUNT(*)之间有什么不同？</p><p>4、COUNT(1)和COUNT(*)之间的效率哪个更高？</p><p>5、为什么《阿里巴巴Java开发手册》建议使用COUNT(*)</p><p>6、MySQL的MyISAM引擎对COUNT(*)做了哪些优化？</p><p>7、MySQL的InnoDB引擎对COUNT(*)做了哪些优化？</p><p>8、上面提到的MySQL对COUNT(*)做的优化，有一个关键的前提是什么？</p><p>9、SELECT COUNT(*) 的时候，加不加where条件有差别吗？</p><p>10、COUNT(*)、COUNT(1)和COUNT(字段名)的执行过程是怎样的？</p></blockquote><h3 id="COUNT-列名-、COUNT-常量-和COUNT-之间的区别"><a href="#COUNT-列名-、COUNT-常量-和COUNT-之间的区别" class="headerlink" title="COUNT(列名)、COUNT(常量)和COUNT(*)之间的区别"></a><strong>COUNT(列名)、COUNT(常量)和COUNT(*)之间的区别</strong></h3><p><strong><code>COUNT(常量)</code> 和 <code>COUNT(*)</code>表示的是直接查询符合条件的数据库表的行数。而<code>COUNT(列名)</code>表示的是查询符合条件的列的值不为NULL的行数。</strong></p><h3 id="COUNT-的优化"><a href="#COUNT-的优化" class="headerlink" title="COUNT(*)的优化"></a><strong>COUNT(*)的优化</strong></h3><p>前面提到了<code>COUNT(*)</code>是SQL92定义的标准统计行数的语法，所以MySQL数据库对他进行过很多优化。那么，具体都做过哪些事情呢？</p><p>这里的介绍要区分不同的执行引擎。MySQL中比较常用的执行引擎就是InnoDB和MyISAM。</p><p>MyISAM和InnoDB有很多区别，其中有一个关键的区别和我们接下来要介绍的<code>COUNT(*)</code>有关，那就是<strong>MyISAM不支持事务，MyISAM中的锁是表级锁；**</strong>而InnoDB支持事务，并且支持行级锁。**</p><p>因为MyISAM的锁是表级锁，所以同一张表上面的操作需要串行进行，所以，<strong>MyISAM做了一个简单的优化，那就是它可以把表的总行数单独记录下来，如果从一张表中使用COUNT(*)进行查询的时候，可以直接返回这个记录下来的数值就可以了，当然，前提是不能有where条件。</strong></p><p>MyISAM之所以可以把表中的总行数记录下来供COUNT(*)查询使用，那是因为MyISAM数据库是表级锁，不会有并发的数据库行数修改，所以查询得到的行数是准确的。</p><p>但是，对于InnoDB来说，就不能做这种缓存操作了，因为InnoDB支持事务，其中大部分操作都是行级锁，所以可能表的行数可能会被并发修改，那么缓存记录下来的总行数就不准确了。</p><p>但是，InnoDB还是针对COUNT(*)语句做了些优化的。</p><p>在InnoDB中，使用COUNT(*)查询行数的时候，不可避免的要进行扫表了，那么，就可以在扫表过程中下功夫来优化效率了。</p><p>从MySQL 8.0.13开始，针对InnoDB的<code>SELECT COUNT(*) FROM tbl_name</code>语句，确实在扫表的过程中做了一些优化。前提是查询语句中不包含WHERE或GROUP BY等条件。</p><p><strong>我们知道，COUNT(*)的目的只是为了统计总行数，所以，他根本不关心自己查到的具体值，所以，他如果能够在扫表的过程中，选择一个成本较低的索引进行的话，那就可以大大节省时间。</strong></p><p>我们知道，InnoDB中索引分为聚簇索引（主键索引）和非聚簇索引（非主键索引），聚簇索引的叶子节点中保存的是整行记录，而非聚簇索引的叶子节点中保存的是该行记录的主键的值。</p><p>所以，相比之下，非聚簇索引要比聚簇索引小很多，所以<strong>MySQL会优先选择最小的非聚簇索引来扫表。**</strong>所以，当我们建表的时候，除了主键索引以外，创建一个非主键索引还是有必要的。**</p><p>至此，我们介绍完了MySQL数据库对于COUNT(*)的优化，这些优化的前提都是查询语句中不包含WHERE以及GROUP BY条件。</p><h3 id="COUNT-和COUNT-1"><a href="#COUNT-和COUNT-1" class="headerlink" title="COUNT(*)和COUNT(1)"></a><strong>COUNT(*)和COUNT(1)</strong></h3><p>官方文档</p><blockquote><p>InnoDB handles SELECT COUNT(*) and SELECT COUNT(1) operations in the same way. There is no performance difference.</p></blockquote><p><strong>所以，对于COUNT(1)和COUNT(*)，MySQL的优化是完全一样的，根本不存在谁比谁快！</strong></p><p>那既然<code>COUNT(*)</code>和<code>COUNT(1)</code>一样，建议用哪个呢？</p><p>建议使用<code>COUNT(*)</code>！因为这个是SQL92定义的标准统计行数的语法</p><p>《阿里巴巴Java开发手册》中强制要求不让使用 <code>COUNT(列名)</code>或 <code>COUNT(常量)</code>来替代 <code>COUNT(*)</code></p><p><img src="/2020/12/10/mysql之count用法/C:%5CUsers%5CAdministrator.USER-20190627HM%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20201210194250149.png" alt="image-20201210194250149"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这个常用的&lt;strong&gt;COUNT&lt;/strong&gt;函数，却暗藏着很多玄机，尤其是在面试的时候，一不小心就会被虐。不信的话请尝试回答下以下问题：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1、COUNT有几种用法？&lt;/p&gt;
&lt;p&gt;2、COUNT(字段名)和COUNT(*)的
      
    
    </summary>
    
      <category term="数据库" scheme="https://jameslin23.gitee.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="面试经典" scheme="https://jameslin23.gitee.io/tags/%E9%9D%A2%E8%AF%95%E7%BB%8F%E5%85%B8/"/>
    
  </entry>
  
  <entry>
    <title>mysql事务</title>
    <link href="https://jameslin23.gitee.io/2020/12/10/mysql%E4%BA%8B%E5%8A%A1/"/>
    <id>https://jameslin23.gitee.io/2020/12/10/mysql事务/</id>
    <published>2020-12-10T05:44:50.000Z</published>
    <updated>2020-12-11T09:50:49.651Z</updated>
    
    <content type="html"><![CDATA[<h2 id="事务的四大特性"><a href="#事务的四大特性" class="headerlink" title="事务的四大特性"></a>事务的四大特性</h2><ul><li><strong>原子性</strong>:  事务最小工作单位，要么全部成功,要没全部失败。</li><li><strong>一致性</strong>:  事务开始和结束后，数据库完整性不会被破坏。</li><li><strong>隔离性</strong>:  不同事务之间互不影响，四种隔离级别为RU(读为提交)、RC(读已提交)、RR(可重复读)、SERIALIZABLE （串行化）。</li><li><strong>持久性</strong>:  事务提交后,对数据的修改是永久性的，即便系统故障也不会丢失。</li></ul><h3 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h3><h4 id="读未提交-Read-UnCommitted-RU"><a href="#读未提交-Read-UnCommitted-RU" class="headerlink" title="读未提交(Read UnCommitted/RU)"></a>读未提交(Read UnCommitted/RU)</h4><p>一个事务可以读取到另外一个事务未提交的数据。这种隔离级别是最不安全的，因为未提交的事务存在回滚。</p><h4 id="读已提交-Read-Committed-RC"><a href="#读已提交-Read-Committed-RC" class="headerlink" title="读已提交(Read Committed/RC)"></a>读已提交(Read Committed/RC)</h4><p>一个事务因为读取到另一个事务已提交的修改数据，导致在当前事务的不同时间读取同一条数据获取的结果不一致。</p><h4 id="可重复读-Repeatable-Read-RR"><a href="#可重复读-Repeatable-Read-RR" class="headerlink" title="可重复读(Repeatable Read/RR)"></a>可重复读(Repeatable Read/RR)</h4><p>当前读取此条数据只可读一次,在当前事务中,不论读取多少次，数据仍然是第一次读取的数据,不会因为在第一次读取之后，其它事务再修改提交此数据而产生改变。</p><h4 id="串行化"><a href="#串行化" class="headerlink" title="串行化"></a>串行化</h4><ul><li>事务A和事务B，事务A在操作数据库时，事务B只能排队等待</li><li>这种隔离级别很少使用，吞吐量太低，用户体验差</li><li>这种级别可以避免“幻像读”，每一次读取的都是数据库中真实存在数据，事务A与事务B串行，而不并发</li></ul><h4 id="出现问题"><a href="#出现问题" class="headerlink" title="出现问题"></a>出现问题</h4><p><strong>脏读</strong>：当前事务可以查看到别的事务未提交的数据（侧重点在于别的事务未提交）。</p><p><strong>幻读</strong>：幻读的表象与不可重读的表象都让人”懵逼”，很容易搞混，但是如果非要细分的话，幻读的侧重点在于新增和删除。表示在同一事务中，使用相同的查询语句，第二次查询时，莫名的多出了一些之前不存在数据，或者莫名的不见了一些数据。</p><p><strong>不可重读</strong>：不可重读的侧重点在于更新修改数据。表示在同一事务中，查询相同的数据范围时，同一个数据资源莫名的改变了。</p><h3 id="不同级别拥有问题"><a href="#不同级别拥有问题" class="headerlink" title="不同级别拥有问题"></a>不同级别拥有问题</h3><table><thead><tr><th align="center"></th><th align="center">脏读</th><th align="center">不可重读</th><th align="center">幻读</th></tr></thead><tbody><tr><td align="center"><strong>读未提交</strong></td><td align="center">√</td><td align="center">√</td><td align="center">√</td></tr><tr><td align="center"><strong>读提交</strong></td><td align="center">×</td><td align="center">√</td><td align="center">√</td></tr><tr><td align="center"><strong>可重读</strong></td><td align="center">×</td><td align="center">×</td><td align="center">√</td></tr><tr><td align="center"><strong>串行化</strong></td><td align="center">×</td><td align="center">×</td><td align="center">×</td></tr></tbody></table><h2 id="LBCC"><a href="#LBCC" class="headerlink" title="LBCC"></a>LBCC</h2><p><strong>LBCC，基于锁的并发控制，Lock Based Concurrency Control。</strong></p><p>使用锁的机制,在当前事务需要对数据修改时,将当前事务加上锁,同一个时间只允许一条事务修改当前数据,其他事务务必等待锁释放之后才可以操作。</p><h2 id="MCAA"><a href="#MCAA" class="headerlink" title="MCAA"></a>MCAA</h2><p><strong>MVCC，多版本的并发控制，Multi-Version Concurrency Control。</strong></p><p>使用版本来控制并发情况下的数据问题，在B事务开始修改账户且事务未提交时，当A事务需要读取账户余额时，此时会读取到B事务修改操作之前的账户余额的副本数据，但是如果A事务需要修改账户余额数据就必须要等待B事务提交事务。</p><p><strong>MVCC使得数据库读不会对数据加锁，普通的SELECT请求不会加锁，提高了数据库的并发处理能力</strong>。借助MVCC，数据库可以实现READ COMMITTED，REPEATABLE READ等隔离级别，用户可以查看当前数据的前一个或者前几个历史版本，保证了ACID中的I特性（隔离性)。</p><h5 id="InnoDB的MVCC实现逻辑"><a href="#InnoDB的MVCC实现逻辑" class="headerlink" title="InnoDB的MVCC实现逻辑"></a>InnoDB的MVCC实现逻辑</h5><p>InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列来实现的。一个保存了行的事务ID(DB_TRX_ID),一个保存了行的回滚指针(DB_ROLL_PT)。每开始一个新的事务,都会自动递增产生一个新ID,事务开始时刻的会把事务ID放到当前事务影响的行事务ID中,当查询时需要用当前事务id和每行记录的事务id做比较。</p><blockquote><p>MVCC只在REPEATABLE READ和READ COMMITIED两个隔离级别下工作。其他两个隔离级别都和 MVCC不兼容 ，因为READ UNCOMMITIED总是读取最新的数据行，而不是符合当前事务版本的数据行。而SERIALIZABLE则会对所有读取的行都加锁。</p></blockquote><p><strong>MVCC 在mysql 中的实现依赖的是 undo log(下面会介绍) 与 read view 。</strong></p><h5 id="ReadView"><a href="#ReadView" class="headerlink" title="ReadView"></a>ReadView</h5><p><strong>ReadView</strong>中主要包含当前系统中还有哪些活跃的读写事务，把它们的事务id放到一个列表中，我们把这个列表命名为为<strong>m_ids</strong>。</p><p>对于查询时的版本链数据是否看见的判断逻辑：</p><ul><li>如果被访问版本的 trx_id 属性值小于 m_ids 列表中最小的事务id，表明生成该版本的事务在生成 ReadView 前已经提交，所以该版本可以被当前事务访问。</li><li>如果被访问版本的 trx_id 属性值大于 m_ids 列表中最大的事务id，表明生成该版本的事务在生成 ReadView 后才生成，所以该版本不可以被当前事务访问。</li><li>如果被访问版本的 trx_id 属性值在 m_ids 列表中最大的事务id和最小事务id之间，那就需要判断一下 trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问。</li></ul><p><strong>举个例子：</strong></p><h6 id="READ-COMMITTED-隔离级别下的ReadView"><a href="#READ-COMMITTED-隔离级别下的ReadView" class="headerlink" title="READ COMMITTED 隔离级别下的ReadView"></a>READ COMMITTED 隔离级别下的ReadView</h6><p><strong>每次读取数据前都生成一个ReadView (m_ids列表)</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/10/mysql%E4%BA%8B%E5%8A%A1/image-20201210173409028.png" alt="image-20201210173409028"></p><p>​          这里分析下上面的情况下的ReadView</p><p>​         时间点 T5 情况下的 SELECT 语句：</p><p>​          当前时间点的版本链：</p><p>​       <img src="https://jameslin23.gitee.io/2020/12/10/mysql%E4%BA%8B%E5%8A%A1/image-20201210173458790.png" alt="image-20201210173458790"></p><p>此时 SELECT 语句执行，当前数据的版本链如上，因为当前的事务777，和事务888 都未提交，所以此时的活跃事务的ReadView的列表情况 <strong>m_ids：[777, 888]</strong> ，因此查询语句会根据当前版本链中小于 <strong>m_ids</strong> 中的最大的版本数据，即查询到的是 Mbappe</p><p>时间点 T8 情况下的 SELECT 语句：</p><p>当前时间的版本链情况：</p><p><img src="https://jameslin23.gitee.io/2020/12/10/mysql%E4%BA%8B%E5%8A%A1/image-20201210173533273.png" alt="image-20201210173533273"></p><p>此时 SELECT 语句执行，当前数据的版本链如上，因为当前的事务777已经提交，和事务888 未提交，所以此时的活跃事务的ReadView的列表情况 <strong>m_ids：[888]</strong> ，因此查询语句会根据当前版本链中小于 <strong>m_ids</strong> 中的最大的版本数据，即查询到的是 Messi。</p><p>时间点 T11 情况下的 SELECT 语句：</p><p>当前时间点的版本链信息：</p><p><img src="https://jameslin23.gitee.io/2020/12/10/mysql%E4%BA%8B%E5%8A%A1/image-20201210173604265.png" alt="image-20201210173604265"></p><p>​      此时 SELECT 语句执行，当前数据的版本链如上，因为当前的事务777和事务888 都已经提交，所以此时的活跃事务的ReadView的列表为空 ，因此查询语句会直接查询当前数据库最新数据，即查询到的是 Dybala。</p><p><strong>总结：</strong> <strong>使用READ COMMITTED隔离级别的事务在每次查询开始时都会生成一个独立的 ReadView。</strong></p><h6 id="REPEATABLE-READ-隔离级别下的ReadView"><a href="#REPEATABLE-READ-隔离级别下的ReadView" class="headerlink" title="REPEATABLE READ 隔离级别下的ReadView"></a>REPEATABLE READ 隔离级别下的ReadView</h6><p><strong>在事务开始后读取第一次读取数据时生成一个ReadView（m_ids列表）</strong></p><h4 id="MVCC总结："><a href="#MVCC总结：" class="headerlink" title="MVCC总结："></a>MVCC总结：</h4><p>所谓的MVCC（Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用 <strong>READ COMMITTD</strong> 、<strong>REPEATABLE READ</strong> 这两种隔离级别的事务在执行普通的 SEELCT 操作时访问记录的版本链的过程，这样子可以使不同事务的 <code>读-写</code> 、 <code>写-读</code> 操作并发执行，从而提升系统性能。</p><p>在 MySQL 中， READ COMMITTED 和 REPEATABLE READ 隔离级别的的一个非常大的区别就是它们生成 ReadView 的时机不同。在 READ COMMITTED 中每次查询都会生成一个实时的 ReadView，做到保证每次提交后的数据是处于当前的可见状态。而 REPEATABLE READ 中，在当前事务第一次查询时生成当前的 ReadView，并且当前的 ReadView 会一直沿用到当前事务提交，以此来保证可重复读（REPEATABLE READ）。</p><h2 id="事务日志"><a href="#事务日志" class="headerlink" title="事务日志"></a>事务日志</h2><h3 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h3><p>redo log叫做重做日志，是用来实现事务的持久性。该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log）,前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都会存到该日志中。假设有个表叫做tb1(id,username) 现在要插入数据（3，ceshi）</p><p><img src="https://jameslin23.gitee.io/2020/12/10/mysql%E4%BA%8B%E5%8A%A1/image-20201210174515027.png" alt="image-20201210174515027"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">start transaction;</span><br><span class="line">select balance from bank where name=&quot;zhangsan&quot;;</span><br><span class="line">// 生成 重做日志 balance=600</span><br><span class="line">update bank set balance = balance - 400; </span><br><span class="line">// 生成 重做日志 amount=400</span><br><span class="line">update finance set amount = amount + 400;</span><br></pre></td></tr></table></figure><p><img src="https://jameslin23.gitee.io/2020/12/10/mysql%E4%BA%8B%E5%8A%A1/image-20201210174624187.png" alt="image-20201210174624187"></p><p><strong>作用:</strong></p><p>mysql 为了提升性能不会把每次的修改都实时同步到磁盘，而是会先存到Boffer Pool(缓冲池)里头，把这个当作缓存来用。然后使用后台线程去做缓冲池和磁盘之间的同步。</p><p>那么问题来了，如果还没来的同步的时候宕机或断电了怎么办？还没来得及执行上面图中红色的操作。这样会导致丢部分已提交事务的修改信息！</p><p>所以引入了redo log来记录已成功提交事务的修改信息，并且会把redo log持久化到磁盘，系统重启之后在读取redo log恢复最新数据。</p><p><strong>总结：redo log是用来恢复数据的，用于保障，已提交事务的持久化特性（记录了已经提交的操作）</strong></p><h3 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log?"></a>undo log?</h3><p>undo log 叫做回滚日志，用于记录数据被修改前的信息。他正好跟前面所说的重做日志所记录的相反，重做日志记录数据被修改后的信息。undo log主要记录的是数据的逻辑变化，为了在发生错误时回滚之前的操作，需要将之前的操作都记录下来，然后在发生错误时才可以回滚。<br> 还用上面那两张表</p><p><img src="https://jameslin23.gitee.io/2020/12/10/mysql%E4%BA%8B%E5%8A%A1/image-20201210175554317.png" alt="image-20201210175554317"></p><p>每次写入数据或者修改数据之前都会把修改前的信息记录到 undo log。</p><p><strong>作用</strong>:</p><p>undo log 记录事务修改之前版本的数据信息，因此假如由于系统错误或者rollback操作而回滚的话可以根据undo log的信息来进行回滚到没被修改前的状态。</p><p><strong>总结:undo log是用来回滚数据的用于保障，未提交事务的原子性</strong>    </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;事务的四大特性&quot;&gt;&lt;a href=&quot;#事务的四大特性&quot; class=&quot;headerlink&quot; title=&quot;事务的四大特性&quot;&gt;&lt;/a&gt;事务的四大特性&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;原子性&lt;/strong&gt;:  事务最小工作单位，要么全部成功,要没全部失
      
    
    </summary>
    
      <category term="数据库" scheme="https://jameslin23.gitee.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="事务" scheme="https://jameslin23.gitee.io/tags/%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>Memcache</title>
    <link href="https://jameslin23.gitee.io/2020/12/09/Memcache/"/>
    <id>https://jameslin23.gitee.io/2020/12/09/Memcache/</id>
    <published>2020-12-09T12:50:10.000Z</published>
    <updated>2020-12-09T12:58:08.010Z</updated>
    
    <content type="html"><![CDATA[<h2 id="memchache特点"><a href="#memchache特点" class="headerlink" title="memchache特点"></a>memchache特点</h2><ul><li>MC处理请求时使用多线程异步IO方法，可以合理利用CPU多核的优势，性能非常优秀。</li><li>MC功能简单，使用内存存储数据</li><li>MC 对缓存的数据可以设置失效期，过期后的数据会被清除；</li><li>失效的策略采用延迟失效，就是当再次使用数据时检查是否失效；</li><li>当容量存满时，会对缓存中的数据进行剔除，剔除时除了会对过期 key 进行清理，还会按 LRU 策略对数据进行剔除。</li></ul><h3 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h3><ul><li>key不能超过250个字节</li><li>value不能超过1M字节</li><li>key的最大失效时间是30天</li><li>只支持K-V结构，不能供持久化和主从同步功能</li><li>没有原生的集群模式，需要依靠客户端来实现集群中分片写数据。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;memchache特点&quot;&gt;&lt;a href=&quot;#memchache特点&quot; class=&quot;headerlink&quot; title=&quot;memchache特点&quot;&gt;&lt;/a&gt;memchache特点&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;MC处理请求时使用多线程异步IO方法，可以合理利用CPU
      
    
    </summary>
    
      <category term="Nosql" scheme="https://jameslin23.gitee.io/categories/Nosql/"/>
    
    
      <category term="缓存" scheme="https://jameslin23.gitee.io/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>redis面试专题</title>
    <link href="https://jameslin23.gitee.io/2020/12/09/redis%E9%9D%A2%E8%AF%95%E4%B8%93%E9%A2%98/"/>
    <id>https://jameslin23.gitee.io/2020/12/09/redis面试专题/</id>
    <published>2020-12-09T00:55:02.000Z</published>
    <updated>2020-12-10T05:45:26.452Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、redis用了哪些数据结构？适用哪些场景"><a href="#一、redis用了哪些数据结构？适用哪些场景" class="headerlink" title="一、redis用了哪些数据结构？适用哪些场景"></a>一、redis用了哪些数据结构？适用哪些场景</h3><h3 id="二、redis是单线程，为什么不使用多线程？"><a href="#二、redis是单线程，为什么不使用多线程？" class="headerlink" title="二、redis是单线程，为什么不使用多线程？"></a>二、redis是单线程，为什么不使用多线程？</h3><h3 id="三、redis持久化机制？"><a href="#三、redis持久化机制？" class="headerlink" title="三、redis持久化机制？"></a>三、redis持久化机制？</h3><h3 id="四、redis哨兵模式如何实现故障转移？"><a href="#四、redis哨兵模式如何实现故障转移？" class="headerlink" title="四、redis哨兵模式如何实现故障转移？"></a>四、redis哨兵模式如何实现故障转移？</h3><h3 id="五、穿透，击穿，雪崩如何解决"><a href="#五、穿透，击穿，雪崩如何解决" class="headerlink" title="五、穿透，击穿，雪崩如何解决"></a>五、穿透，击穿，雪崩如何解决</h3><h3 id="六、谈一谈redis分布式锁"><a href="#六、谈一谈redis分布式锁" class="headerlink" title="六、谈一谈redis分布式锁?"></a>六、谈一谈redis分布式锁?</h3><h3 id="七、你了解最经典的KV、DB读写模式么？"><a href="#七、你了解最经典的KV、DB读写模式么？" class="headerlink" title="七、你了解最经典的KV、DB读写模式么？"></a>七、你了解最经典的KV、DB读写模式么？</h3><h3 id="八、为什么是删除缓存，而不是更新缓存？"><a href="#八、为什么是删除缓存，而不是更新缓存？" class="headerlink" title="八、为什么是删除缓存，而不是更新缓存？"></a>八、为什么是删除缓存，而不是更新缓存？</h3><h3 id="九、Redis-和-Memcached-有啥区别，为啥选择用Redis作为你们的缓存中间件？"><a href="#九、Redis-和-Memcached-有啥区别，为啥选择用Redis作为你们的缓存中间件？" class="headerlink" title="九、Redis 和 Memcached 有啥区别，为啥选择用Redis作为你们的缓存中间件？"></a>九、Redis 和 Memcached 有啥区别，为啥选择用Redis作为你们的缓存中间件？</h3><h3 id="十、假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？"><a href="#十、假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？" class="headerlink" title="十、假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？"></a>十、假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？</h3><blockquote><p>使用 <code>keys</code> 指令可以扫出指定模式的 key 列表。但是要注意 keys 指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 <code>scan</code> 指令，<code>scan</code> 指令可以无阻塞的提取出指定模式的 <code>key</code> 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 <code>keys</code> 指令长。</p></blockquote><h3 id="十一、跳跃表是如何实现的？原理？"><a href="#十一、跳跃表是如何实现的？原理？" class="headerlink" title="十一、跳跃表是如何实现的？原理？"></a>十一、跳跃表是如何实现的？原理？</h3><p><strong>本质是解决查找问题</strong></p><p>因为是有序链表，无法使用二分查找，我们需要从头开始遍历查找，导致时间复杂度(n)</p><p><strong>思想: 是一种特殊的数据结构，多层链表结构设计思想，不同节点有不同的高度，当查找的时候可以实现跳跃查找。</strong></p><p><strong>这样方便加快查询速度。</strong></p><h3 id="十二、Redis-的-SDS-和-C-中字符串相比有什么优势？"><a href="#十二、Redis-的-SDS-和-C-中字符串相比有什么优势？" class="headerlink" title="十二、Redis 的 SDS 和 C 中字符串相比有什么优势？"></a>十二、Redis 的 SDS 和 C 中字符串相比有什么优势？</h3><p><strong>SDS动态字符串</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sdshdr</span>&#123;</span></span><br><span class="line"> <span class="keyword">int</span> len;</span><br><span class="line"> <span class="keyword">int</span> <span class="built_in">free</span>;</span><br><span class="line"> <span class="keyword">char</span> buf[];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>计数方式不同</li><li>杜绝缓冲区溢出</li><li>减少修改字符串时带来的内存重分配次数</li><li>二进制安全</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;一、redis用了哪些数据结构？适用哪些场景&quot;&gt;&lt;a href=&quot;#一、redis用了哪些数据结构？适用哪些场景&quot; class=&quot;headerlink&quot; title=&quot;一、redis用了哪些数据结构？适用哪些场景&quot;&gt;&lt;/a&gt;一、redis用了哪些数据结构？适用哪些
      
    
    </summary>
    
      <category term="Nosql" scheme="https://jameslin23.gitee.io/categories/Nosql/"/>
    
    
      <category term="缓存" scheme="https://jameslin23.gitee.io/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>redis分布式锁</title>
    <link href="https://jameslin23.gitee.io/2020/12/07/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <id>https://jameslin23.gitee.io/2020/12/07/redis分布式锁/</id>
    <published>2020-12-07T12:01:38.000Z</published>
    <updated>2020-12-09T02:23:36.865Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><h2 id="什么是分布式锁"><a href="#什么是分布式锁" class="headerlink" title="什么是分布式锁?"></a>什么是分布式锁?</h2><p>分布式锁就是控制分布式系统或不同系统之间共同访问共享资源的一种锁实现,如果不同的系统或同一个系统的不同主机之间共享了某个资源时，往往需要互斥来防止彼此干扰来保证一致性。</p><h2 id="分布式锁需要具备哪些条件"><a href="#分布式锁需要具备哪些条件" class="headerlink" title="分布式锁需要具备哪些条件"></a>分布式锁需要具备哪些条件</h2><ol><li><strong>互斥性</strong>:在任意一个时刻,只有一个客户端持有锁</li><li><strong>无死锁</strong>:即便持有锁的客户端崩溃或者其他意外事件,锁仍然可以被获取。</li><li><strong>容错</strong>:只要大部分redis节点都活着,客户端就可以获取锁和释放锁</li></ol><h2 id="分布式锁实现有哪些？"><a href="#分布式锁实现有哪些？" class="headerlink" title="分布式锁实现有哪些？"></a>分布式锁实现有哪些？</h2><ul><li><strong>数据库</strong></li><li><strong>Memcached（add命令）</strong></li><li><strong>Redis（setnx命令）</strong></li><li><strong>Zookeeper（临时节点）</strong></li></ul><h1 id="分布式锁实现"><a href="#分布式锁实现" class="headerlink" title="分布式锁实现"></a>分布式锁实现</h1><h2 id="SET-key-value-NX"><a href="#SET-key-value-NX" class="headerlink" title="SET key value NX"></a>SET key value NX</h2><p>假设有两个客户端A和B，A获取到分布式的锁。A执行了一会，突然A所在的服务器断电了（或者其他什么的），也就是客户端A挂了。这时出现一个问题，这个锁一直存在，且不会被释放，其他客户端永远获取不到锁。如下示意图</p><p><img src="https://jameslin23.gitee.io/2020/12/07/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/image-20201207205319341.png" alt="image-20201207205319341"></p><h2 id="SET-lockKey-value-NX-EX-30"><a href="#SET-lockKey-value-NX-EX-30" class="headerlink" title="SET lockKey value NX EX 30"></a>SET lockKey value NX EX 30</h2><p><strong>注: 要保证设置过期时间和设置锁具有原子性</strong></p><p>此时又出现一个问题,过程如下</p><ol><li>客户端A获取锁成功,过期时间30秒</li><li>客户端A在某个程序上阻塞了50秒</li><li>30秒时间到了，锁自动释放了</li><li>客户端B获取对应同一资源的锁</li><li>客户端A从阻塞恢复过来,释放掉了客户端B持有的锁</li></ol><p><img src="https://jameslin23.gitee.io/2020/12/07/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/image-20201207210005131.png" alt="image-20201207210005131"></p><p>这时会有两个问题</p><ol><li>过期时间如何保证大于业务执行时间?</li><li>如何保证锁不会被误删除?</li></ol><p><strong>先来解决如何保证锁不会被误删除这个问题。 这个问题可以通过设置value为当前客户端生成的一个随机字符串，且保证在足够长的一段时间内在所有客户端的所有获取锁的请求中都是唯一的。</strong></p><h2 id="lua脚本释放锁具备原子性"><a href="#lua脚本释放锁具备原子性" class="headerlink" title="lua脚本释放锁具备原子性"></a>lua脚本释放锁具备原子性</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="comment">// 使用lua脚本进行原子删除操作</span></span><br><span class="line">      String checkAndDelScript = <span class="string">"if redis.call('get', KEYS[1]) == ARGV[1] then "</span> +</span><br><span class="line">                                  <span class="string">"return redis.call('del', KEYS[1]) "</span> +</span><br><span class="line">                                  <span class="string">"else "</span> +</span><br><span class="line">                                  <span class="string">"return 0 "</span> +</span><br><span class="line">                                  <span class="string">"end"</span>;</span><br><span class="line">      jedis.eval(checkAndDelScript, <span class="number">1</span>, lockKey, lockValue);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h1 id="Redisson实现分布式锁"><a href="#Redisson实现分布式锁" class="headerlink" title="Redisson实现分布式锁"></a>Redisson实现分布式锁</h1><h2 id="Redisson原理"><a href="#Redisson原理" class="headerlink" title="Redisson原理"></a>Redisson原理</h2><p><img src="https://jameslin23.gitee.io/2020/12/07/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/1090617-20190618183025891-1248337684.jpg" alt="img"></p><ol><li><p><strong>加锁机制</strong></p><p>线程去获取锁,获取成功:执行lua脚本,保存数据到redis数据库</p><p>线程去获取锁,获取失败:一直通过while循环尝试获取锁,获取成功后，执行lua脚本，保存数据到redis数据库</p></li><li><p><strong>watch dog自动延期机制</strong></p><p>它的作用就是 线程1 业务还没有执行完，锁时间就过了，线程1 还想持有锁的话，就会启动一个watch dog后台线程，不断的延长锁key的生存时间。</p></li><li><p><strong>LUA脚本</strong></p><p>主要是如果你的业务逻辑复杂的话，通过封装在lua脚本中发送给redis，而且redis是单线程的，这样就保证这段复杂业务逻辑执行的<strong>原子性</strong>。</p></li><li><p><strong>可重入锁</strong></p><p>Hash数据类型的key值包含了当前线程信息。</p><p>下面是redis存储的数据</p><p><img src="https://jameslin23.gitee.io/2020/12/07/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/1090617-20190618183037704-975536201.png" alt="img"></p><p>这里表面数据类型是Hash类型,Hash类型相当于我们java的 <code>&lt;key,&lt;key1,value&gt;&gt;</code> 类型,这里key是指 ‘redisson’</p><p>它的有效期还有9秒，我们再来看里们的key1值为<code>078e44a3-5f95-4e24-b6aa-80684655a15a:45</code>它的组成是:</p><p>guid + 当前线程的ID。后面的value是就和可重入加锁有关。</p><p><strong>举图说明</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/07/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/1090617-20190618183046827-1994396879.png" alt="img"></p><p>上面这图的意思就是可重入锁的机制，它最大的优点就是相同线程不需要在等待锁，而是可以直接进行相应操作。</p></li></ol><h2 id="Redis分布式锁缺陷"><a href="#Redis分布式锁缺陷" class="headerlink" title="Redis分布式锁缺陷"></a>Redis分布式锁缺陷</h2><p><strong>Redis分布式锁会有个缺陷，就是在Redis哨兵模式下:</strong></p><p><code>客户端1</code> 对某个<code>master节点</code>写入了redisson锁，此时会异步复制给对应的 slave节点。但是这个过程中一旦发生 master节点宕机，主备切换，slave节点从变为了 master节点。</p><p>这时<code>客户端2</code> 来尝试加锁的时候，在新的master节点上也能加锁，此时就会导致多个客户端对同一个分布式锁完成了加锁。</p><p>这时系统在业务语义上一定会出现问题，<strong>导致各种脏数据的产生</strong>。</p><p><code>缺陷</code>在哨兵模式或者主从模式下，如果 master实例宕机的时候，可能导致多个客户端同时完成加锁。</p><h2 id="RLock接口"><a href="#RLock接口" class="headerlink" title="RLock接口"></a>RLock接口</h2><p><strong>Redisson分布式锁是基于RLock接口,RedissonLock实现RLock接口</strong>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">RLock</span> <span class="keyword">extends</span> <span class="title">Lock</span>, <span class="title">RExpirable</span>, <span class="title">RLockAsync</span></span></span><br></pre></td></tr></table></figure><p>很明显RLock是继承Lock锁,所以他有Lock锁的所有特征,比如lock,unlock,trylock等特征，同时它很多新特性:强制锁释放,带有效期的锁。</p><h2 id="RLock锁API"><a href="#RLock锁API" class="headerlink" title="RLock锁API"></a>RLock锁API</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">RLock</span> </span>&#123;</span><br><span class="line">    <span class="comment">//----------------------Lock接口方法-----------------------</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 加锁 锁的有效期默认30秒</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">lock</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false .</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间，</span></span><br><span class="line"><span class="comment">     * 在时间期限之内如果还拿不到锁，就返回false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> time 等待时间</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> unit 时间单位 小时、分、秒、毫秒等</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">(<span class="keyword">long</span> time, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 解锁</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 中断锁 表示该锁可以被中断 假如A和B同时调这个方法，A获取锁，B为获取锁，那么B线程可以通过</span></span><br><span class="line"><span class="comment">     * Thread.currentThread().interrupt(); 方法真正中断该线程</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">lockInterruptibly</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//----------------------RLock接口方法-----------------------</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 加锁 上面是默认30秒这里可以手动设置锁的有效时间</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> leaseTime 锁有效时间</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> unit      时间单位 小时、分、秒、毫秒等</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">lock</span><span class="params">(<span class="keyword">long</span> leaseTime, TimeUnit unit)</span></span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 这里比上面多一个参数，多添加一个锁的有效时间</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> waitTime  等待时间</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> leaseTime 锁有效时间</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> unit      时间单位 小时、分、秒、毫秒等</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">(<span class="keyword">long</span> waitTime, <span class="keyword">long</span> leaseTime, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 检验该锁是否被线程使用，如果被使用返回True</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isLocked</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 检查当前线程是否获得此锁（这个和上面的区别就是该方法可以判断是否当前线程获得此锁，而不是此锁是否被线程占有）</span></span><br><span class="line"><span class="comment">     * 这个比上面那个实用</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isHeldByCurrentThread</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 中断锁 和上面中断锁差不多，只是这里如果获得锁成功,添加锁的有效时间</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> leaseTime  锁有效时间</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> unit       时间单位 小时、分、秒、毫秒等</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">lockInterruptibly</span><span class="params">(<span class="keyword">long</span> leaseTime, TimeUnit unit)</span></span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="RedissonLock实现类"><a href="#RedissonLock实现类" class="headerlink" title="RedissonLock实现类"></a>RedissonLock实现类</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedissonLock</span> <span class="keyword">extends</span> <span class="title">RedissonExpirable</span> <span class="keyword">implements</span> <span class="title">RLock</span></span></span><br></pre></td></tr></table></figure><h3 id="void-lock-方法"><a href="#void-lock-方法" class="headerlink" title="void lock()方法"></a>void lock()方法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">lock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        lockInterruptibly();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">        Thread.currentThread().interrupt();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>发现lock锁里面进去其实用的是lockInterruptibly(中断锁,表示可以被中断),而且捕获异常后用Thread.currentThread().interupt()来真正中断当前线程,其实它们是搭配一起使用的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 1、带上默认值调另一个中断锁方法</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="meta">@Override</span></span><br><span class="line"> <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">lockInterruptibly</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">     lockInterruptibly(-<span class="number">1</span>, <span class="keyword">null</span>);</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 2、另一个中断锁的方法</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> <span class="function"><span class="keyword">void</span> <span class="title">lockInterruptibly</span><span class="params">(<span class="keyword">long</span> leaseTime, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException </span></span><br><span class="line"><span class="function"> <span class="comment">/**</span></span></span><br><span class="line"><span class="function"><span class="comment">  * 3、这里已经设置了锁的有效时间默认为30秒  （commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout()=30）</span></span></span><br><span class="line"><span class="function"><span class="comment">  */</span></span></span><br><span class="line"><span class="function"> RFuture&lt;Long&gt; ttlRemainingFuture </span>= tryLockInnerAsync(commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);</span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * 4、最后通过lua脚本访问Redis,保证操作的原子性</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"> &lt;T&gt; <span class="function">RFuture&lt;T&gt; <span class="title">tryLockInnerAsync</span><span class="params">(<span class="keyword">long</span> leaseTime, TimeUnit unit, <span class="keyword">long</span> threadId, RedisStrictCommand&lt;T&gt; command)</span> </span>&#123;</span><br><span class="line">     internalLockLeaseTime = unit.toMillis(leaseTime);</span><br><span class="line"></span><br><span class="line">     <span class="keyword">return</span> commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,</span><br><span class="line">             <span class="string">"if (redis.call('exists', KEYS[1]) == 0) then "</span> +</span><br><span class="line">                     <span class="string">"redis.call('hset', KEYS[1], ARGV[2], 1); "</span> +</span><br><span class="line">                     <span class="string">"redis.call('pexpire', KEYS[1], ARGV[1]); "</span> +</span><br><span class="line">                     <span class="string">"return nil; "</span> +</span><br><span class="line">                     <span class="string">"end; "</span> +</span><br><span class="line">                     <span class="string">"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then "</span> +</span><br><span class="line">                     <span class="string">"redis.call('hincrby', KEYS[1], ARGV[2], 1); "</span> +</span><br><span class="line">                     <span class="string">"redis.call('pexpire', KEYS[1], ARGV[1]); "</span> +</span><br><span class="line">                     <span class="string">"return nil; "</span> +</span><br><span class="line">                     <span class="string">"end; "</span> +</span><br><span class="line">                     <span class="string">"return redis.call('pttl', KEYS[1]);"</span>,</span><br><span class="line">             Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId));</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h3 id="tryLock-long-waitTime-long-leaseTime-TimeUnit-unit"><a href="#tryLock-long-waitTime-long-leaseTime-TimeUnit-unit" class="headerlink" title="tryLock(long waitTime,long leaseTime,TimeUnit unit)"></a>tryLock(long waitTime,long leaseTime,TimeUnit unit)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">(<span class="keyword">long</span> waitTime, <span class="keyword">long</span> leaseTime, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">       <span class="keyword">long</span> time = unit.toMillis(waitTime);</span><br><span class="line">       <span class="keyword">long</span> current = System.currentTimeMillis();</span><br><span class="line">       <span class="keyword">long</span> threadId = Thread.currentThread().getId();</span><br><span class="line">       Long ttl = tryAcquire(leaseTime, unit, threadId);</span><br><span class="line">       <span class="comment">//1、 获取锁同时获取成功的情况下，和lock(...)方法是一样的 直接返回True，获取锁False再往下走</span></span><br><span class="line">       <span class="keyword">if</span> (ttl == <span class="keyword">null</span>) &#123;</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="comment">//2、如果超过了尝试获取锁的等待时间,当然返回false 了。</span></span><br><span class="line">       time -= System.currentTimeMillis() - current;</span><br><span class="line">       <span class="keyword">if</span> (time &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">           acquireFailed(threadId);</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       <span class="comment">// 3、订阅监听redis消息，并且创建RedissonLockEntry，其中RedissonLockEntry中比较关键的是一个 Semaphore属性对象,用来控制本地的锁请求的信号量同步，返回的是netty框架的Future实现。</span></span><br><span class="line">       <span class="keyword">final</span> RFuture&lt;RedissonLockEntry&gt; subscribeFuture = subscribe(threadId);</span><br><span class="line">       <span class="comment">//  阻塞等待subscribe的future的结果对象，如果subscribe方法调用超过了time，说明已经超过了客户端设置的最大wait time，则直接返回false，取消订阅，不再继续申请锁了。</span></span><br><span class="line">       <span class="comment">//  只有await返回true，才进入循环尝试获取锁</span></span><br><span class="line">       <span class="keyword">if</span> (!await(subscribeFuture, time, TimeUnit.MILLISECONDS)) &#123;</span><br><span class="line">           <span class="keyword">if</span> (!subscribeFuture.cancel(<span class="keyword">false</span>)) &#123;</span><br><span class="line">               subscribeFuture.addListener(<span class="keyword">new</span> FutureListener&lt;RedissonLockEntry&gt;() &#123;</span><br><span class="line">                   <span class="meta">@Override</span></span><br><span class="line">                   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">operationComplete</span><span class="params">(Future&lt;RedissonLockEntry&gt; future)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                       <span class="keyword">if</span> (subscribeFuture.isSuccess()) &#123;</span><br><span class="line">                           unsubscribe(subscribeFuture, threadId);</span><br><span class="line">                       &#125;</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;);</span><br><span class="line">           &#125;</span><br><span class="line">           acquireFailed(threadId);</span><br><span class="line">           <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//4、如果没有超过尝试获取锁的等待时间，那么通过While一直获取锁。最终只会有两种结果</span></span><br><span class="line">       <span class="comment">//1)、在等待时间内获取锁成功 返回true。2）等待时间结束了还没有获取到锁那么返回false。</span></span><br><span class="line">       <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">           <span class="keyword">long</span> currentTime = System.currentTimeMillis();</span><br><span class="line">           ttl = tryAcquire(leaseTime, unit, threadId);</span><br><span class="line">           <span class="comment">// 获取锁成功</span></span><br><span class="line">           <span class="keyword">if</span> (ttl == <span class="keyword">null</span>) &#123;</span><br><span class="line">               <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">           &#125;</span><br><span class="line">          <span class="comment">//   获取锁失败</span></span><br><span class="line">           time -= System.currentTimeMillis() - currentTime;</span><br><span class="line">           <span class="keyword">if</span> (time &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">               acquireFailed(threadId);</span><br><span class="line">               <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>tryLock一般用于特定满足需求的场合,但不建议作为一般需求的分布式锁，一般分布式锁建议用void lock(long leaseTime,TimeUnit unit)。因此性能上考虑，在高并发情况下后者效率是前者的好几倍。</p><h3 id="unlock"><a href="#unlock" class="headerlink" title="unlock()"></a>unlock()</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">unlock</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 1.通过 Lua 脚本执行 Redis 命令释放锁</span></span><br><span class="line">        Boolean opStatus = commandExecutor.evalWrite(getName(), LongCodec.INSTANCE,</span><br><span class="line">                RedisCommands.EVAL_BOOLEAN,</span><br><span class="line">                <span class="string">"if (redis.call('exists', KEYS[1]) == 0) then "</span> +</span><br><span class="line">                        <span class="string">"redis.call('publish', KEYS[2], ARGV[1]); "</span> +</span><br><span class="line">                        <span class="string">"return 1; "</span> +</span><br><span class="line">                        <span class="string">"end;"</span> +</span><br><span class="line">                        <span class="string">"if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then "</span> +</span><br><span class="line">                        <span class="string">"return nil;"</span> +</span><br><span class="line">                        <span class="string">"end; "</span> +</span><br><span class="line">                        <span class="string">"local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); "</span> +</span><br><span class="line">                        <span class="string">"if (counter &gt; 0) then "</span> +</span><br><span class="line">                        <span class="string">"redis.call('pexpire', KEYS[1], ARGV[2]); "</span> +</span><br><span class="line">                        <span class="string">"return 0; "</span> +</span><br><span class="line">                        <span class="string">"else "</span> +</span><br><span class="line">                        <span class="string">"redis.call('del', KEYS[1]); "</span> +</span><br><span class="line">                        <span class="string">"redis.call('publish', KEYS[2], ARGV[1]); "</span> +</span><br><span class="line">                        <span class="string">"return 1; "</span>+</span><br><span class="line">                        <span class="string">"end; "</span> +</span><br><span class="line">                        <span class="string">"return nil;"</span>,</span><br><span class="line">                Arrays.&lt;Object&gt;asList(getName(), getChannelName()),</span><br><span class="line">                LockPubSub.unlockMessage, internalLockLeaseTime,</span><br><span class="line">                getLockName(Thread.currentThread().getId()));</span><br><span class="line">        <span class="comment">// 2.非锁的持有者释放锁时抛出异常</span></span><br><span class="line">        <span class="keyword">if</span> (opStatus == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalMonitorStateException(</span><br><span class="line">                    <span class="string">"attempt to unlock lock, not locked by current thread by node id: "</span></span><br><span class="line">                            + id + <span class="string">" thread-id: "</span> + Thread.currentThread().getId());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 3.释放锁后取消刷新锁失效时间的调度任务</span></span><br><span class="line">        <span class="keyword">if</span> (opStatus) &#123;</span><br><span class="line">            cancelExpirationRenewal();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>使用EVAL命令执行Lua脚本来释放锁:</p><ol><li>key 不存在,说明锁已经释放,直接执行<code>public</code>命令发布释放锁消息并返回1</li><li>key存在,但field在 Hash 中不存在，说明自己不是锁持有者，无权释放锁，返回 <code>nil</code>。</li><li>因为锁可重入,所以释放锁时不能把所有已获取的锁全部释放掉,一次只能释放一把锁,因此执行<code>hincrby</code>对锁的值减1。</li><li>释放一把锁后，如果还有剩余的锁,则刷新锁的失效时间并返回<code>0</code>；如果刚才释放的已经是最后一把锁，则执行 <code>del</code> 命令删除锁的 key，并发布锁释放消息，返回 <code>1</code>。</li></ol><p><code>注意</code>这里有个实际开发过程中，容易出现很容易出现上面第二步异常，非锁的持有者释放锁时抛出异常。比如下面这种情况</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//设置锁1秒过去</span></span><br><span class="line">      redissonLock.lock(<span class="string">"redisson"</span>, <span class="number">1</span>);</span><br><span class="line">      <span class="comment">/**</span></span><br><span class="line"><span class="comment">       * 业务逻辑需要咨询2秒</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">      redissonLock.release(<span class="string">"redisson"</span>);</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 线程1 进来获得锁后，线程一切正常并没有宕机，但它的业务逻辑需要执行2秒，这就会有个问题，在 线程1 执行1秒后，这个锁就自动过期了，</span></span><br><span class="line"><span class="comment">     * 那么这个时候 线程2 进来了。在线程1去解锁就会抛上面这个异常（因为解锁和当前锁已经不是同一线程了）</span></span><br><span class="line"><span class="comment">     */</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;分布式锁&quot;&gt;&lt;a href=&quot;#分布式锁&quot; class=&quot;headerlink&quot; title=&quot;分布式锁&quot;&gt;&lt;/a&gt;分布式锁&lt;/h1&gt;&lt;h2 id=&quot;什么是分布式锁&quot;&gt;&lt;a href=&quot;#什么是分布式锁&quot; class=&quot;headerlink&quot; title=&quot;什么是
      
    
    </summary>
    
      <category term="Nosql" scheme="https://jameslin23.gitee.io/categories/Nosql/"/>
    
    
      <category term="缓存" scheme="https://jameslin23.gitee.io/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>redis缓存故障</title>
    <link href="https://jameslin23.gitee.io/2020/12/07/redis%E7%BC%93%E5%AD%98%E6%95%85%E9%9A%9C/"/>
    <id>https://jameslin23.gitee.io/2020/12/07/redis缓存故障/</id>
    <published>2020-12-07T06:25:23.000Z</published>
    <updated>2020-12-07T12:03:56.269Z</updated>
    
    <content type="html"><![CDATA[<h1 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h1><p><strong>缓存穿透的概念,用户想查询一个数据，发现Redis没有，也就是缓存没有命中，于是向持久层数据库查询。发现也没有，于是本次查询失败。当用户很多时候，缓存都没有命中，于是都去请求了持久层数据库。这个给持久层数据库造成很多的压力。</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/07/redis%E7%BC%93%E5%AD%98%E6%95%85%E9%9A%9C/image-20201207150041108.png" alt="image-20201207150041108"></p><p> <strong>解决方法:</strong></p><p><strong>1、缓存空对象</strong></p><p>当存储层不命中时,即使返回空对象也将其缓存起来,设置一个过期时间，之后再访问这个数据将会从缓存中获取，保护了后端数据源</p><p><img src="https://jameslin23.gitee.io/2020/12/07/redis%E7%BC%93%E5%AD%98%E6%95%85%E9%9A%9C/image-20201207150510313.png" alt="image-20201207150510313"></p><p><strong>但是这种方法会存在两个问题：</strong></p><blockquote><p>1、缓存区可能存在大量空值的键</p><p>2、可能会存在缓存层和存储层会有一段时间空窗不一致，对保持一致性的业务会有影响</p></blockquote><p><strong>2、布隆过滤器</strong></p><p>在查询缓存之间先在到布隆过滤器查询，没有则返回，有再走redis，DB查询操作</p><p><img src="https://jameslin23.gitee.io/2020/12/07/redis%E7%BC%93%E5%AD%98%E6%95%85%E9%9A%9C/image-20201207153906629.png" alt="image-20201207153906629"></p><p><strong>布隆过滤器原理</strong></p><p>本质上布隆过滤器是一个数据结构,比较巧妙的概率型数据结构,特点高效的插入和查询。</p><p>根据查询结果可以用来告诉你<strong>某样东西一定不存在或者可能存在</strong>。这句话是算法的核心。</p><p>相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的，同时布隆过滤器还有一个缺陷就是<strong>数据只能插入不能删除。</strong></p><p><strong>数据如何存入布隆过滤器</strong></p><p>布隆过滤器是由一个很长的<strong>bit数组</strong>和一系列<strong>哈希函数</strong>组成的</p><p>数组的每个元素都只占1bit空间,并且每个元素只能0或者1</p><p>布隆过滤器还拥有k个哈希函数,当一个元素加入布隆过滤器时,会使用k个函数对其进行k次计算，得到k个哈希值，并且根据得到哈希值,在维数据对应下标的值置位1。</p><p><strong>判断某个数是否在布隆过滤器中，就对该元素进行k次哈希计算，得到的值在位数组中判断每个元素是否都为1，如果每个元素都为1，就说明这个值在布隆过滤器中。</strong></p><p><strong>布隆过滤器为什么会有误判</strong></p><p>当插入元素越来越多时,当一个不在布隆过滤器中的元素,经过同样规则哈希计算后，得到的值在位数据组中查询，有可能这些位置被其它元素先置为1了。</p><p>所以布隆过滤器存在误判的情况。</p><p><strong>但如果布隆过滤器判断某个元素不在布隆过滤器中，那么这个值就一定不在。</strong></p><p><strong>使用场景</strong></p><blockquote><ul><li><strong>网页爬虫对URL的去重</strong></li><li><strong>垃圾邮件过滤</strong></li><li><strong>解决数据库缓存击穿</strong></li><li><strong>秒杀系统</strong></li></ul></blockquote><h1 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h1><p>这里需要注意和缓存穿透的区别。缓存穿透，是指一个key非常热点,在不停的扛着大并发,大并发集中对这个点进行访问，当这个key在失效的瞬间,持续的大并发就穿破缓存,直接请求数据库，就像一个屏幕凿开一个洞。</p><p>当某个key在过期的瞬间,有大量的请求并发访问,这类数据一般是热点数据,由于缓存过期，会同时访问数据库来查询最新的数据，并回写缓存，会导致数据库压力过大。</p><p><strong>解决方法：</strong></p><p><strong>1、设置热点数据永不过期</strong></p><p><strong>2、加互斥锁</strong></p><p>分布式锁:使用分布式锁,保证了对每个Key只有一个线程去查询后端服务,其它线程没有获得分布式锁的权限，因此只需要等待即可。</p><h1 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h1><p>缓存雪崩,是指在某一个时间段,缓存集中过期失效（或者redis宕机）。</p><p>比如马上就双12零点,很快就会有一波抢购，这波抢购商品比较集中的放在redis，假设缓存一个小时，那么到凌晨一点钟，这批缓存就都过期了，而对这批商品的访问查询,都落在数据库上，对于数据库而言，都会产生周期性的压力波峰。于是所有的请求都会到达存储层，存储层的调用量会暴增，造成存储层也回掉的情况</p><p><strong>解决方案：</strong></p><p><strong>1、redis高可用</strong></p><p>这个思想的含义是，既然 redis 有可能挂掉，那我多增设几台 redis，这样一台挂掉之后其他的还可以继续工作，其实就是搭建的集群。</p><p><strong>2、限流降级</strong></p><p>这个解决方案的思想是，在缓存失效后，通过加锁或者队列来控制数据库写缓存的线程数量。比如对某个 key 只允许一个线程查询数据和写缓存，其他线程等待。</p><p><strong>3、数据预热</strong></p><p>数据预热的含义是在正式部署之前，把可能的数据线预先访问一遍，这样部分可能大量访问的数据就会加载到缓存。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;缓存穿透&quot;&gt;&lt;a href=&quot;#缓存穿透&quot; class=&quot;headerlink&quot; title=&quot;缓存穿透&quot;&gt;&lt;/a&gt;缓存穿透&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;缓存穿透的概念,用户想查询一个数据，发现Redis没有，也就是缓存没有命中，于是向持久层数据库查询。发现也没
      
    
    </summary>
    
      <category term="Nosql" scheme="https://jameslin23.gitee.io/categories/Nosql/"/>
    
    
      <category term="缓存" scheme="https://jameslin23.gitee.io/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>redis哨兵模式</title>
    <link href="https://jameslin23.gitee.io/2020/12/05/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"/>
    <id>https://jameslin23.gitee.io/2020/12/05/redis哨兵模式/</id>
    <published>2020-12-05T06:55:30.000Z</published>
    <updated>2020-12-09T13:03:05.731Z</updated>
    
    <content type="html"><![CDATA[<h1 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h1><p><strong>Sentinel(哨兵)是redis的高可用性解决方案:由一个或者多个Sentinel实例组成的Sentinel系统可以监视任意多个主服务器以及这些主服务器属下所有从服务器，并在被监视的主服务器进入下线状态时,自动将下线主服务器属下的某个从服务器升级为新的服务器，然后由新的主服务器代替已下线的主服务器继续处理请求命令,他主要功能如下:</strong></p><ul><li><strong>监控(Monitoring)</strong>：Sentinel会不断地检查你的主服务器和从服务器是否运作正常。</li><li><strong>通知(Notification)</strong>：当被监控的某个 Redis 服务器出现问题时， Sentinel可以通过API向管理员或者其他应用程序发送通知。</li><li><strong>故障迁移</strong>：当主服务器不能正常工作时，Sentinel会自动进行故障迁移，也就是主从切换。</li><li><strong>统一的配置管理</strong>：连接者询问sentinel取得主从的地址。</li></ul><h2 id="哨兵原理"><a href="#哨兵原理" class="headerlink" title="哨兵原理"></a>哨兵原理</h2><p><strong>Sentinel 使用核心算法是Raft算法,主要用途就是用于分布式系统,系统容错以及Leader选举,每个Sentinel都需要定期的执行以下任务:</strong></p><p><strong>主观下线</strong>(一个Sentinel判断)</p><p>在默认情况下,Sentinel会以每秒一次的频率像所有与它创建了命令连接的实例(包括主服务器,从服务器,其它Sentinel在内)发送PING命令回复来判断实例是否在线。</p><p>实例对PING命令的回复可以分为以下两种情况：</p><ul><li>有效回复:实例返回+PONG,-LOADING、-MASTERDOWN三种回复其中一种。</li><li>无效回复:有效回复之外的其它三种回复或者在指定时限内没有任何回复。</li></ul><p><strong>客观下线</strong></p><p>当Sentinel将一个主服务器判断为主观下线之后,为了确认这个主服务器是否真的下线了,它会向同样监视这个主服务器的其他Sentinel进行询问,看他们是否也认为主服务器已经进入下线状态,当Sentinel从其他Sentinel那里接收到足够数量的已经判断下线之后,Sentinel就会将服务器判断为客观下线,并对主服务器执行故障转移。</p><p><img src="https://jameslin23.gitee.io/2020/12/05/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/image-20201207141544018.png" alt="image-20201207141544018"></p><p><strong>如何从主机选取主机</strong></p><p><strong>故障转移操作的第一步</strong> 要做的就是在已下线主服务器属下的所有从服务器中，挑选出一个状态良好、数据完整的从服务器，然后向这个从服务器发送 <code>slaveof no one</code> 命令，将这个从服务器转换为主服务器。但是这个从服务器是怎么样被挑选出来的呢？</p><ul><li>在失效主服务器属下的从服务器当中， 那些被标记为主观下线、已断线、或者最后一次回复 PING 命令的时间大于五秒钟的从服务器都会被 <strong>淘汰</strong>。</li><li>在失效主服务器属下的从服务器当中， 那些与失效主服务器连接断开的时长超过 down-after 选项指定的时长十倍的从服务器都会被 <strong>淘汰</strong>。</li><li>在 <strong>经历了以上两轮淘汰之后</strong> 剩下来的从服务器中， 我们选出 <strong>复制偏移量（replication offset）最大</strong> 的那个 <strong>从服务器</strong> 作为新的主服务器；如果复制偏移量不可用，或者从服务器的复制偏移量相同，那么 <strong>带有最小运行 ID</strong> 的那个从服务器成为新的主服务器。</li></ul><h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><p><strong>配置文件详解</strong></p><p>哨兵的配置主要就是修改sentinel.conf配置文件中的参数，在Redis安装目录即可看到此配置文件，各参数详解如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"># 哨兵sentinel实例运行的端口，默认26379   </span><br><span class="line">port 26379 </span><br><span class="line"># 哨兵sentinel的工作目录 </span><br><span class="line">dir ./ </span><br><span class="line"># 是否开启保护模式，默认开启。 </span><br><span class="line">protected-mode no </span><br><span class="line"># 是否设置为后台启动。 </span><br><span class="line">daemonize yes </span><br><span class="line"> </span><br><span class="line"># 哨兵sentinel的日志文件 </span><br><span class="line">logfile:./sentinel.log </span><br><span class="line"> </span><br><span class="line"># 哨兵sentinel监控的redis主节点的  </span><br><span class="line">## ip：主机ip地址 </span><br><span class="line">## port：哨兵端口号 </span><br><span class="line">## master-name：可以自己命名的主节点名字（只能由字母A-z、数字0-9 、这三个字符&quot;.-_&quot;组成。） </span><br><span class="line">## quorum：当这些quorum个数sentinel哨兵认为master主节点失联 那么这时 客观上认为主节点失联了   </span><br><span class="line"># sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;   </span><br><span class="line">sentinel monitor mymaster 127.0.0.1 6379 2 </span><br><span class="line"> </span><br><span class="line"># 当在Redis实例中开启了requirepass，所有连接Redis实例的客户端都要提供密码。 </span><br><span class="line"># sentinel auth-pass &lt;master-name&gt; &lt;password&gt;   </span><br><span class="line">sentinel auth-pass mymaster 123456   </span><br><span class="line"> </span><br><span class="line"># 指定主节点应答哨兵sentinel的最大时间间隔，超过这个时间，哨兵主观上认为主节点下线，默认30秒   </span><br><span class="line"># sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt; </span><br><span class="line">sentinel down-after-milliseconds mymaster 30000   </span><br><span class="line"> </span><br><span class="line"># 指定了在发生failover主备切换时，最多可以有多少个slave同时对新的master进行同步。这个数字越小，完成failover所需的时间就越长；反之，但是如果这个数字越大，就意味着越多的slave因为replication而不可用。可以通过将这个值设为1，来保证每次只有一个slave，处于不能处理命令请求的状态。 </span><br><span class="line"># sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt; </span><br><span class="line">sentinel parallel-syncs mymaster 1   </span><br><span class="line"> </span><br><span class="line"># 故障转移的超时时间failover-timeout，默认三分钟，可以用在以下这些方面： </span><br><span class="line">## 1. 同一个sentinel对同一个master两次failover之间的间隔时间。   </span><br><span class="line">## 2. 当一个slave从一个错误的master那里同步数据时开始，直到slave被纠正为从正确的master那里同步数据时结束。   </span><br><span class="line">## 3. 当想要取消一个正在进行的failover时所需要的时间。 </span><br><span class="line">## 4.当进行failover时，配置所有slaves指向新的master所需的最大时间。不过，即使过了这个超时，slaves依然会被正确配置为指向master，但是就不按parallel-syncs所配置的规则来同步数据了 </span><br><span class="line"># sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt;   </span><br><span class="line">sentinel failover-timeout mymaster 180000 </span><br><span class="line"> </span><br><span class="line"># 当sentinel有任何警告级别的事件发生时（比如说redis实例的主观失效和客观失效等等），将会去调用这个脚本。一个脚本的最大执行时间为60s，如果超过这个时间，脚本将会被一个SIGKILL信号终止，之后重新执行。 </span><br><span class="line"># 对于脚本的运行结果有以下规则：   </span><br><span class="line">## 1. 若脚本执行后返回1，那么该脚本稍后将会被再次执行，重复次数目前默认为10。 </span><br><span class="line">## 2. 若脚本执行后返回2，或者比2更高的一个返回值，脚本将不会重复执行。   </span><br><span class="line">## 3. 如果脚本在执行过程中由于收到系统中断信号被终止了，则同返回值为1时的行为相同。 </span><br><span class="line"># sentinel notification-script &lt;master-name&gt; &lt;script-path&gt;   </span><br><span class="line">sentinel notification-script mymaster /var/redis/notify.sh </span><br><span class="line"> </span><br><span class="line"># 这个脚本应该是通用的，能被多次调用，不是针对性的。 </span><br><span class="line"># sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt; </span><br><span class="line">sentinel client-reconfig-script mymaster /var/redis/reconfig.sh</span><br></pre></td></tr></table></figure><p><strong>对应配置修改</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 端口默认为26379。 </span><br><span class="line">port:26379 </span><br><span class="line"># 关闭保护模式，可以外部访问。 </span><br><span class="line">protected-mode:no </span><br><span class="line"># 设置为后台启动。 </span><br><span class="line">daemonize yes </span><br><span class="line"># 日志文件。 </span><br><span class="line">logfile &quot;/data/redis/redis-5.0.7/logs/sentinel.log&quot;</span><br><span class="line"># 指定主机IP地址和端口，并且指定当有2台哨兵认为主机挂了，则对主机进行容灾切换。 </span><br><span class="line">sentinel monitor mymaster 192.168.10.8 6379 2 </span><br><span class="line"># 当在Redis实例中开启了requirepass，这里就需要提供密码。 </span><br><span class="line">sentinel auth-pass mymaster 123456 </span><br><span class="line"># 这里设置了主机多少秒无响应，则认为挂了。 </span><br><span class="line">sentinel down-after-milliseconds mymaster 3000 </span><br><span class="line"># 主备切换时，最多有多少个slave同时对新的master进行同步，这里设置为默认的1。 </span><br><span class="line">snetinel parallel-syncs mymaster 1 </span><br><span class="line"># 故障转移的超时时间，这里设置为三分钟。 </span><br><span class="line">sentinel failover-timeout mymaster 180000</span><br></pre></td></tr></table></figure><p><strong>启动三个哨兵：</strong></p><blockquote><p>cd /data/redis/redis-5.0.7/bin</p><p>redis-sentinel  ../conf/sentinel.conf </p></blockquote><p><strong>查看状态</strong></p><blockquote><ol><li>redis-cli -p 26379 </li><li>info sentinel </li></ol></blockquote><p><img src="https://jameslin23.gitee.io/2020/12/05/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/image-20201207140008319.png" alt="image-20201207140008319"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;哨兵模式&quot;&gt;&lt;a href=&quot;#哨兵模式&quot; class=&quot;headerlink&quot; title=&quot;哨兵模式&quot;&gt;&lt;/a&gt;哨兵模式&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;Sentinel(哨兵)是redis的高可用性解决方案:由一个或者多个Sentinel实例组成的Sentin
      
    
    </summary>
    
      <category term="Nosql" scheme="https://jameslin23.gitee.io/categories/Nosql/"/>
    
    
      <category term="缓存" scheme="https://jameslin23.gitee.io/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>redis主从复制</title>
    <link href="https://jameslin23.gitee.io/2020/12/05/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"/>
    <id>https://jameslin23.gitee.io/2020/12/05/redis主从复制/</id>
    <published>2020-12-05T02:24:07.000Z</published>
    <updated>2020-12-07T03:02:06.269Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p><strong>主从复制,是指将一台Redis服务器的数据,复制到其它的Redis服务器。前称为主节点(master),后者称为从节点(slave);数据的复制是当向的。只能由主节点到从节点。Master负责写，Slave以读为主。</strong></p><p><strong>主从复制的作用主要包括:</strong></p><ul><li>数据冗余: 主从复制实现了数据的热备份，是持久化之外的一种数据冗余方法</li><li>故障恢复: 当节点出现问题时,可以由从节点提供服务器,实现快速故障恢复</li><li>负载均衡: 在主从复制的基础上,配合读写分离,可以由节点提供些服务,由从节点提供读服务(即写redis数据时应用连接主节点，读Redis数据时应用连接从节点),分担服务器负载；尤其是在写少读多的场景，通过多个节点分担读负载,可以大大提高Redis服务的并发量</li></ul><p><strong>缺点</strong></p><ul><li>当主节点宕机时,需要自己手动恢复，当恢复不及时会造成线上故障</li></ul><h1 id="旧版复制原理"><a href="#旧版复制原理" class="headerlink" title="旧版复制原理"></a>旧版复制原理</h1><p><strong>Redis的复制功能分为同步(sync) 和命令传播(command propagete)两个状态:</strong></p><ul><li>同步操作用于将从服务器的数据库状态更新至主服务器当前所处的数据库状态</li><li>命令传播操作则用于主服务器的数据库状态被修改,导致主从服务器的数据库状态出现不一致时，让主从服务器状态重新回到一致状态。</li></ul><h2 id="同步操作"><a href="#同步操作" class="headerlink" title="同步操作"></a>同步操作</h2><p>从服务对主服务器的同步操作需要通过向主服务器发送SYNC命令来完成,以下是SYNC命令的执行步骤:</p><blockquote><p>1) 从服务器向主服务器发送SYNC命令</p><p>2) 收到SYNC命令的主服务器执行BGSAVE命令,在后台生成一个RDB文件,并使用一个缓冲区记录从现在开始执行的所有写命令。</p><p>3) 当主服务器BGSAVE执行完毕，主服务器会将从BGSAVE生成RDB文件发送给从服务器，从服务器接收并载入这个RDB文件,将自己的数据库更新至主服务器执行BGSAVE命令时的数据库状态。</p><p>4) 主服务器将记录在缓冲区里面的所有命令发送给从服务器，从服务器执行这些写命令，将自己的数据库状态更新至主服务器数据库当前所处的状态。</p></blockquote><p><img src="https://jameslin23.gitee.io/2020/12/05/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/image-20201205110020380.png" alt="image-20201205110020380"></p><p><strong>同步过程</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/05/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/image-20201205180035866.png" alt="image-20201205180035866"></p><h2 id="命令传播"><a href="#命令传播" class="headerlink" title="命令传播"></a>命令传播</h2><p>在同步操作执行完毕之后,主从服务器两者的数据库将达到一致状态，但这种一致并不是一成不变的，每当主服务器执行客户端发送的写命令时，主服务器的数据库就有可能会被修改，并导致主从服务器状态不再一致。</p><p><strong>举个例子</strong></p><p>假设一个主服务器和一个从服务器刚刚完成同步操作，他们的数据库都保存了相同的5个键k1至k5,如果这时候，客户端向主服务器发送命令DEL K3,那么主服务器在执行完成这个DEL K3之后，主从服务器状态出现不一致。</p><p><img src="https://jameslin23.gitee.io/2020/12/05/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/image-20201205113817827.png" alt="image-20201205113817827"></p><p><strong>为了让主从服务器再次回到一致状态，主服务器需要对服务器执行命令传播操作，主服务器会将自己执行命令操作发送给从服务器，让主从服务器再次回到一致。</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/05/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/image-20201205114120580.png" alt="image-20201205114120580"></p><h2 id="旧版复制缺陷"><a href="#旧版复制缺陷" class="headerlink" title="旧版复制缺陷"></a>旧版复制缺陷</h2><p>在redis中,从服务器对主服务器复制可以分以下2种情况</p><p><strong>初次复制：</strong> 从服务器以前没有复制过任何主服务器，或者从服务器当前要复制的主服务器和上次复制的主服务器不同。</p><p><strong>断线后重新复制：</strong> 处于命令传播阶段的主从服务器因为网络原因中断复制，但从服务器通过自动重连重新连上主服务器，并继续复制服务器。</p><p><strong>但对于旧版初次复制，能够很好的完成任务，但对于断线后复制来说，旧版本复制让主从服务器重新回到一致状态，效率很低。</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/05/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/image-20201205180010434.png" alt="image-20201205180010434"></p><p><strong>断开期间，主从增加3个命令（现实实际不止），从服务器发送SYNC,却从K1-K5生成RDB，实际K1,K2是没必要，如果命令多，这部分造成很大资源浪费，效率低下。Redis2.8版本开始，使用PSYNC命令代替SYNC命令来执行复制时的同步同步操作。</strong></p><h1 id="新版复制原理"><a href="#新版复制原理" class="headerlink" title="新版复制原理"></a>新版复制原理</h1><h2 id="PSYNC命令"><a href="#PSYNC命令" class="headerlink" title="PSYNC命令"></a>PSYNC命令</h2><p><strong>PSYNC命令具有完整同步和部分重同步</strong></p><ul><li><strong>其中完整重同步用于处理初次复制情况</strong>:完整同步的执行步骤和SYNC命令的执行步骤基本一样，他们都是通过主服务器创建并发送RDB文件,以及向从服务器发送保存的缓冲区里面的写命令进行同步。</li><li><strong>而部分同步则用于处理断线后重复情况</strong>:当从服务器在断线后重新连接主服务器时，如果条件允许，主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器,从服务器只要接收并执行这些写命令,就可以将数据库更新至主服务器当前所处状态。</li></ul><h2 id="部分同步的实现"><a href="#部分同步的实现" class="headerlink" title="部分同步的实现"></a>部分同步的实现</h2><p>部分同步功能由以下部分构成:</p><ul><li><strong>主服务器的复制偏移量和从服务器的复制偏移量</strong></li><li><strong>主服务器的复制积压缓冲区</strong></li><li><strong>服务器的运行ID</strong></li></ul><h3 id="复制偏移量"><a href="#复制偏移量" class="headerlink" title="复制偏移量"></a>复制偏移量</h3><p>执行复制双方——主服务器和从服务器会分别维护一个复制偏移量</p><ul><li><strong>主服务器每次向从服务器传播N个字节的数据，就将自己的复制偏移量的值加上N</strong></li><li><strong>从服务器每次收到主服务器传播来N个字节的数据时，就将自己复制偏移量的值加上N</strong></li></ul><p>通过对比主从服务器的复制偏移量,程序可以很容易地知道主从服务器是否处于一致状态:</p><ul><li>如果主从服务器处于一致状态，那么主从服务器两者的偏移量总是相同</li><li>相反,如果主从服务器两者的偏移量并不相同,那么说明状态不一致。</li></ul><h3 id="复制积压缓冲区"><a href="#复制积压缓冲区" class="headerlink" title="复制积压缓冲区"></a>复制积压缓冲区</h3><p><strong>复制积压缓冲区是由主从服务器维护的一个固定长度先进先出队列,默认大小为1MB</strong></p><p>当主服务器进行命令传播时,他不仅会将命令发送给所有从服务器,还会将写命令入队列到复制积压缓冲区里面。</p><p><img src="https://jameslin23.gitee.io/2020/12/05/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/image-20201205142401789.png" alt="image-20201205142401789"></p><p>因此,主服务器的复制积压缓冲区里面会保存着一份最近传播的写命令,并且复制积压缓冲区会为队列中每个字节记录相应的复制偏移量</p><p><img src="https://jameslin23.gitee.io/2020/12/05/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6//image-20201205142551707.png" alt="image-20201205142551707"></p><p><strong>过程</strong></p><ul><li><p>当服务器断线之后,它立即重新连接主服务器,并向主服务器发送PSYNC命令,报告自己的复制偏移量10086。</p></li><li><p>当服务器收到从服务器发来PSYNC命令以及偏移量10086之后的数据是否在于复制积压缓冲区里面,结果发现这些数据依然存在，</p><p>于是主服务器向从服务器发送+CONTINUE回复，表示数据同步以部分同步模式。</p></li><li><p>接着主服务器会将复制积压缓冲区10086偏移之后所有数据都发给从服务器</p></li><li><p>从服务器只要接收这33字节缺失数据,就可以回到主服务器一致状态。</p></li></ul><h3 id="服务器运行ID"><a href="#服务器运行ID" class="headerlink" title="服务器运行ID"></a>服务器运行ID</h3><p>除了复制偏移量和复制积压缓冲区之外,实现部分同步还需要用到服务器运行状态ID</p><ul><li><strong>每个redis服务器,不论主服务器还是从服务器,都会有自己的运行ID</strong></li><li><strong>运行ID在服务器启动时自动生成,由40个随机的16进制字符组成</strong></li></ul><p>当从服务器对主服务器进行初次复制,主服务器会将自己的运行ID传给从服务器,而从服务器则会将这个运行ID保存起来。</p><p>当从服务器断线并且重新连上一个主服务器时，从服务器将像当前连接主服务器发送之前保存的运行ID</p><ul><li><strong>如果从服务器保存的运行ID和当前连接的主服务器运行ID相同，主服务器可以尝试执行部分同步。</strong></li><li><strong>相反，ID不相同，则对从服务器执行完全同步。</strong></li></ul><h1 id="Redis安装"><a href="#Redis安装" class="headerlink" title="Redis安装"></a>Redis安装</h1><h2 id="单机版安装"><a href="#单机版安装" class="headerlink" title="单机版安装"></a>单机版安装</h2><ol><li><p><strong>下载安装包</strong></p><blockquote><p>wget <a href="http://download.redis.io/releases/redis-5.0.7.tar.gz" target="_blank" rel="noopener">http://download.redis.io/releases/redis-5.0.7.tar.gz</a> </p></blockquote></li><li><p><strong>解压</strong></p><blockquote><p> tar  -xvf  redis-5.0.7.tar.gz</p></blockquote></li><li><p><strong>编译</strong></p><blockquote><p>(1) cd redis-5.0.7/</p><p>(2) make</p><p>(3) cd src/</p><p>(4) make instal</p></blockquote></li><li><p><strong>整理配置文件和启动文件</strong></p><blockquote><p>(1) mkdir conf</p><p>(2) mkdir bin</p><p>(3) 将redis.conf 和sentinel.conf 放入conf</p><p>(4) 进入src目录,将mkreleasehdr.sh、redis-benchmark、redis-check-aof、redis-check-rdb、redis-cli、redis-server、redis-sentinel文件复制到 bin 文件夹</p><p>(5) cp mkreleasehdr.sh redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-server redis-sentinel ../bin/</p></blockquote></li><li><p><strong>启动</strong></p><blockquote><p> ./redis-server ../conf/redis.conf </p></blockquote></li></ol><h2 id="主从配置"><a href="#主从配置" class="headerlink" title="主从配置"></a>主从配置</h2><p><strong>首先看一下redis.conf 配置文件中的各个参数，详解如下</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"># redis进程是否以守护进程的方式运行，yes为是，no为否(不以守护进程的方式运行会占用一个终端)。 </span><br><span class="line">daemonize no </span><br><span class="line"># 指定redis进程的PID文件存放位置 </span><br><span class="line">pidfile /var/run/redis.pid </span><br><span class="line"># redis进程的端口号 </span><br><span class="line">port 6379 </span><br><span class="line">#是否开启保护模式，默认开启。要是配置里没有指定bind和密码。开启该参数后，redis只会本地进行访问，拒绝外部访问。要是开启了密码和bind，可以开启。否则最好关闭设置为no。 </span><br><span class="line">protected-mode yes </span><br><span class="line"># 绑定的主机地址 </span><br><span class="line">bind 127.0.0.1 </span><br><span class="line"># 客户端闲置多长时间后关闭连接，默认此参数为0即关闭此功能 </span><br><span class="line">timeout 300 </span><br><span class="line"># redis日志级别，可用的级别有debug.verbose.notice.warning </span><br><span class="line">loglevel verbose </span><br><span class="line"># log文件输出位置，如果进程以守护进程的方式运行，此处又将输出文件设置为stdout的话，就会将日志信息输出到/dev/null里面去了 </span><br><span class="line">logfile stdout </span><br><span class="line"># 设置数据库的数量，默认为0可以使用select &lt;dbid&gt;命令在连接上指定数据库id </span><br><span class="line">databases 16 </span><br><span class="line"># 指定在多少时间内刷新次数达到多少的时候会将数据同步到数据文件 </span><br><span class="line">save &lt;seconds&gt; &lt;changes&gt; </span><br><span class="line"># 指定存储至本地数据库时是否压缩文件，默认为yes即启用存储 </span><br><span class="line">rdbcompression yes </span><br><span class="line"># 指定本地数据库文件名 </span><br><span class="line">dbfilename dump.db </span><br><span class="line"># 指定本地数据问就按存放位置 </span><br><span class="line">dir ./ </span><br><span class="line"># 指定当本机为slave服务时，设置master服务的IP地址及端口，在redis启动的时候他会自动跟master进行数据同步 </span><br><span class="line">replicaof &lt;masterip&gt; &lt;masterport&gt; </span><br><span class="line"># 当master设置了密码保护时，slave服务连接master的密码 </span><br><span class="line">masterauth &lt;master-password&gt; </span><br><span class="line"># 设置redis连接密码，如果配置了连接密码，客户端在连接redis是需要通过AUTH&lt;password&gt;命令提供密码，默认关闭 </span><br><span class="line">requirepass footbared </span><br><span class="line"># 设置同一时间最大客户连接数，默认无限制。redis可以同时连接的客户端数为redis程序可以打开的最大文件描述符，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回 max number of clients reached 错误信息 </span><br><span class="line">maxclients 128 </span><br><span class="line"># 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key。当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区 </span><br><span class="line">maxmemory&lt;bytes&gt; </span><br><span class="line"># 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no。 </span><br><span class="line">appendonly no </span><br><span class="line"># 指定跟新日志文件名默认为appendonly.aof </span><br><span class="line">appendfilename appendonly.aof </span><br><span class="line"># 指定更新日志的条件，有三个可选参数 - no：表示等操作系统进行数据缓存同步到磁盘(快)，always：表示每次更新操作后手动调用fsync()将数据写到磁盘(慢，安全)， everysec：表示每秒同步一次(折衷，默认值)； </span><br><span class="line">appendfsync everysec</span><br></pre></td></tr></table></figure><p><strong>主机配置(192.168.10.8)</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Redis 默认只允许本机访问，把 bind 修改为 0.0.0.0 表示允许所有远程访问。如果想指定限制访问，可设置对应的 ip。</span><br><span class="line">bind 0.0.0.0 </span><br><span class="line"># 端口</span><br><span class="line">port 6379 </span><br><span class="line"># 关闭保护模式，可以外部访问。</span><br><span class="line">protected-mode：no </span><br><span class="line"># 后台启动</span><br><span class="line">daemonize yes</span><br><span class="line"># 日志文件</span><br><span class="line">logfile ./redis.log </span><br><span class="line">#  设置 redis 连接密码。</span><br><span class="line">requirepass 123456</span><br><span class="line"># slave 服务连接 master 的密码。。</span><br><span class="line">masterauth 123456</span><br></pre></td></tr></table></figure><p><strong>从机配置(192.168.10.10)</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># Redis 默认只允许本机访问，把 bind 修改为 0.0.0.0 表示允许所有远程访问。如果想指定限制访问，可设置对应的 ip。</span><br><span class="line">bind 0.0.0.0 </span><br><span class="line"># 端口</span><br><span class="line">port 6379 </span><br><span class="line"># 关闭保护模式，可以外部访问。</span><br><span class="line">protected-mode：no </span><br><span class="line"># 后台启动</span><br><span class="line">daemonize yes</span><br><span class="line"># 日志文件</span><br><span class="line">logfile ./redis.log </span><br><span class="line">#  设置 redis 连接密码。</span><br><span class="line">requirepass 123456</span><br><span class="line"># slave 服务连接 master 的密码。。</span><br><span class="line">masterauth 123456 </span><br><span class="line"># 配置主机地址</span><br><span class="line">replicaof 192.168.10.8 6379</span><br></pre></td></tr></table></figure><p><strong>从机配置:(192.168.10.3)</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># Redis 默认只允许本机访问，把 bind 修改为 0.0.0.0 表示允许所有远程访问。如果想指定限制访问，可设置对应的 ip。</span><br><span class="line">bind 0.0.0.0 </span><br><span class="line"># 端口</span><br><span class="line">port 6379 </span><br><span class="line"># 关闭保护模式，可以外部访问。</span><br><span class="line">protected-mode：no </span><br><span class="line"># 后台启动</span><br><span class="line">daemonize yes</span><br><span class="line"># 日志文件</span><br><span class="line">logfile ./redis.log </span><br><span class="line">#  设置 redis 连接密码。</span><br><span class="line">requirepass 123456</span><br><span class="line"># slave 服务连接 master 的密码。。</span><br><span class="line">masterauth 123456 </span><br><span class="line"># 配置主机地址 </span><br><span class="line">replicaof 192.168.10.8 6379</span><br></pre></td></tr></table></figure><h1 id="小总结"><a href="#小总结" class="headerlink" title="小总结"></a>小总结</h1><ul><li><strong>Redis2.8之前的复制功能不能高效地处理断线后重复复制情况,但Redis2.8新添的部分功能重同步功能可以解决这个问题</strong></li><li><strong>部分重同步通过复制偏移量、复制积压缓冲区、服务器运行ID三个部分来实现</strong></li><li><strong>在复制操作刚开始时候，从服务器会成为主服务器客户端，并通过向主服务器发送命令请求执行复制步骤,而在复制操作后期。主从复制会互相成为对方的客户端。</strong></li><li><strong>主服务器通过从服务器传播命令来更新服务器状态，保存主从一致,而从服务器则通过向主服务器发送命令来进行心跳检测,以及命令丢失检测。</strong></li><li><strong>单机版和主从配置部署</strong></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;概念&quot;&gt;&lt;a href=&quot;#概念&quot; class=&quot;headerlink&quot; title=&quot;概念&quot;&gt;&lt;/a&gt;概念&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;主从复制,是指将一台Redis服务器的数据,复制到其它的Redis服务器。前称为主节点(master),后者称为从节点(sl
      
    
    </summary>
    
      <category term="Nosql" scheme="https://jameslin23.gitee.io/categories/Nosql/"/>
    
    
      <category term="缓存" scheme="https://jameslin23.gitee.io/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ分布式事务</title>
    <link href="https://jameslin23.gitee.io/2020/12/04/RocketMQ%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    <id>https://jameslin23.gitee.io/2020/12/04/RocketMQ分布式事务/</id>
    <published>2020-12-04T11:37:59.000Z</published>
    <updated>2020-12-05T02:26:33.310Z</updated>
    
    <content type="html"><![CDATA[<h1 id="RocketMQ事务机制"><a href="#RocketMQ事务机制" class="headerlink" title="RocketMQ事务机制"></a>RocketMQ事务机制</h1><h2 id="举个分布式事务场景"><a href="#举个分布式事务场景" class="headerlink" title="举个分布式事务场景"></a>举个分布式事务场景</h2><p>例子: 假设A给B转100块，同时他们不是在同一个服务器上</p><p>目标: 就是 <strong>A</strong> 减100块钱，<strong>B</strong> 加100块钱。</p><p>实际可能情况</p><blockquote><p>1）就是A账户减100 （成功），B账户加100 （成功）</p><p>2）就是A账户减100（失败），B账户加100 （失败） </p><p>3）就是A账户减100（成功），B账户加100 （失败） </p><p>4）就是A账户减100 （失败），B账户加100 （成功）</p></blockquote><p>这里 <strong>第1和第2</strong> 种情况是能够保证事务的一致性的，但是 <strong>第3和第4</strong> 是无法保证事务的一致性的</p><h2 id="RocketMQ实现分布式事务原理"><a href="#RocketMQ实现分布式事务原理" class="headerlink" title="RocketMQ实现分布式事务原理"></a>RocketMQ实现分布式事务原理</h2><p><strong>RocketMQ虽然之前也支持分布式事务，但并没有开源，等到RocketMQ 4.3才正式开源。</strong></p><h3 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h3><p><strong>最终一致性</strong></p><blockquote><p><strong>RocketMQ是一种最终一致性的分布式事务</strong>，就是说它保证的是消息最终一致性，而不是像2PC、3PC、TCC那样强一致分布式事务，至于为什么说它是最终一致性事务下面会详细说明。</p></blockquote><p><strong>Half Message(半消息)</strong></p><blockquote><p><strong>是指暂不能被Consumer消费的消息</strong>。Producer 已经把消息成功发送到了 Broker 端，但此消息被标记为<code>暂不能投递</code>状态，处于该种状态下的消息称为半消息。需要 Producer</p><p>对消息的<code>二次确认</code>后，Consumer才能去消费它。</p></blockquote><p><strong>消息回查</strong></p><blockquote><p>由于网络闪段，生产者应用重启等原因。导致 Producer 端一直没有对 <strong>Half Message(半消息)</strong> 进行 <strong>二次确认</strong>。这是Brock服务器会定时扫描<code>长期处于半消息的消息</code>，会</p><p>主动询问 Producer端 该消息的最终状态(<strong>Commit或者Rollback</strong>),该消息即为 <strong>消息回查</strong></p></blockquote><h2 id="分布式事务交互流程"><a href="#分布式事务交互流程" class="headerlink" title="分布式事务交互流程"></a>分布式事务交互流程</h2><p><img src="https://jameslin23.gitee.io/2020/12/01/RocketMQ/image-20201203112838421.png" alt="image-20201203112838421"></p><p>我们来说明下上面这张图</p><blockquote><p>1、A服务先发送个Half Message给Brock端，消息中携带 B服务 即将要+100元的信息。 </p><p>2、当A服务知道Half Message发送成功后，那么开始第3步执行本地事务。 </p><p>3、执行本地事务(会有三种情况1、执行成功。2、执行失败。3、网络等原因导致没有响应) </p><p>4.1)、如果本地事务成功，那么Product像Brock服务器发送Commit,这样B服务就可以消费该message。</p><p>4.2)、如果本地事务失败，那么Product像Brock服务器发送Rollback,那么就会直接删除上面这条半消息。 </p><p>4.3)、如果因为网络等原因迟迟没有返回失败还是成功，那么会执行RocketMQ的回调接口,来进行事务的回查。</p></blockquote><p><strong>为什么要先发送Half Message(半消息)?</strong></p><blockquote><p>1）可以先确认 Brock服务器是否正常 ，如果半消息都发送失败了 那说明Brock挂了。</p><p>2）可以通过半消息来回查事务，如果半消息发送成功后一直没有被二次确认，那么就会回查事务状态。</p></blockquote><p><strong>什么情况会回查</strong></p><blockquote><p>1）执行本地事务的时候，由于突然网络等原因一直没有返回执行事务的结果(commit或者rollback)导致最终返回UNKNOW，那么就会回查。</p><p>2) 本地事务执行成功后，返回Commit进行消息二次确认的时候的服务挂了，在重启服务那么这个时候在brock端   它还是个Half Message(半消息)，这也会回查。</p></blockquote><p><strong>通过上面这幅图，我们可以看出，在上面举例事务不一致的两种情况中，永远不会发生</strong></p><p><strong>A账户减100 （失败），B账户加100 （成功）</strong></p><p><strong>A账户减100 （成功），B账户加100 （失败）有可能发生</strong></p><blockquote><p>如果B最终执行失败，几乎可以断定就是代码有问题所以才引起的异常，因为消费端RocketMQ有重试机制，如果不是代码问题一般重试几次就能成功。</p><p>如果是代码的原因引起多次重试失败后，也没有关系，将该异常记录下来，由<code>人工处理</code>，人工兜底处理后，就可以让事务达到最终的一致性。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;RocketMQ事务机制&quot;&gt;&lt;a href=&quot;#RocketMQ事务机制&quot; class=&quot;headerlink&quot; title=&quot;RocketMQ事务机制&quot;&gt;&lt;/a&gt;RocketMQ事务机制&lt;/h1&gt;&lt;h2 id=&quot;举个分布式事务场景&quot;&gt;&lt;a href=&quot;#举个分布
      
    
    </summary>
    
      <category term="消息队列" scheme="https://jameslin23.gitee.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
      <category term="MQ" scheme="https://jameslin23.gitee.io/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ拉取策略</title>
    <link href="https://jameslin23.gitee.io/2020/12/04/RocketMQ%E6%8B%89%E5%8F%96%E7%AD%96%E7%95%A5/"/>
    <id>https://jameslin23.gitee.io/2020/12/04/RocketMQ拉取策略/</id>
    <published>2020-12-04T11:28:57.000Z</published>
    <updated>2020-12-04T11:37:34.408Z</updated>
    
    <content type="html"><![CDATA[<h1 id="消费者拉取策略（Master-Slave）"><a href="#消费者拉取策略（Master-Slave）" class="headerlink" title="消费者拉取策略（Master-Slave）"></a>消费者拉取策略（Master-Slave）</h1><h1 id="ConsumeQueue文件也是基于os-cache的"><a href="#ConsumeQueue文件也是基于os-cache的" class="headerlink" title="ConsumeQueue文件也是基于os cache的"></a>ConsumeQueue文件也是基于os cache的</h1><blockquote><p>ConsumeQueue会被大量的消费者发送的请求高并发读取，所以ComsumeQueue文件读取操作非常频繁，而且同时会极大影响到消费者进行拉取的性能和消费吞吐量</p><p>对于Broker机器的磁盘上的大量的comsumeQueue文件，在写入的时候也都是优先进os cache中，ConsumeQueue文件主要存放消息CommitLog消息offest,所以每个文件很小,30万条消息的offset就只有5.72MB，他们整体数据量小,几乎可以完全被os缓存在内存cache里面。</p><p>实际上在消费者拉取消息的时候，第一步大量的频繁读取ConsumeQueue文件,几乎可以说是跟读内存里的数据的性能是一样的，通过这个可以保证数据消费的高性能以及高吞吐量。</p></blockquote><h2 id="读取CommitLog基于cache-磁盘一起读的"><a href="#读取CommitLog基于cache-磁盘一起读的" class="headerlink" title="读取CommitLog基于cache+磁盘一起读的"></a>读取CommitLog基于cache+磁盘一起读的</h2><blockquote><p>当你拉取消息时候，可以轻松从os cache里读取少量的ConsumeQueue文件offest,这个性能极高，但是当去CommitLog文件读取完整消息数据时候，会有两种可能</p></blockquote><p><strong>第一种</strong></p><blockquote><p>如果你读取的是那种刚刚写入CommitLog的数据，那么大概率他们还停留在os cache中，此时你可以顺利的直接从os cache里面读取CommitLog中的数据，这个是内存读取，性能很高。</p></blockquote><p><strong>第二种</strong></p><blockquote><p>你也许读取的是比较早之前写入CommitLog的数据，那些数据早就被刷入磁盘了，已经不在os cache里了，那么此时你<br>就只能从磁盘上的文件里读取了，这个性能是比较差一些的。</p></blockquote><p><strong>什么时候会从os cache读？什么时候会从磁盘读？</strong></p><blockquote><p>其实这个问题很简单了，如果你的消费者机器一直快速的在拉取和消费处理，紧紧的跟上了生产者写入broker的消息速率，那么你每次拉取几乎都是在拉取最近人家刚写入CommitLog的数据，那几乎都在os cache里。</p><p>但是如果broker的负载很高，导致你拉取消息的速度很慢，或者是你自己的消费者机器拉取到一批消息之后处理的时候性能很低，处理的速度很慢，这都会导致你跟不上生产者写入的速率。</p><p>比如人家都写入10万条数据了，结果你才拉取了2万条数据，此时有5万条最新的数据是在os cache里，有3万条你还没拉取的数据是在磁盘里，那么当后续你再拉取的时候，必然很大概率是从磁盘里读取早就刷入磁盘的3万条数据。</p></blockquote><h2 id="Master-Broker什么时候会让你从Slave-Broker拉取数据？"><a href="#Master-Broker什么时候会让你从Slave-Broker拉取数据？" class="headerlink" title="Master Broker什么时候会让你从Slave Broker拉取数据？"></a>Master Broker什么时候会让你从Slave Broker拉取数据？</h2><blockquote><p>假设此时你的broker里已经写入了10万条数据，但是你仅仅拉取了2万条数据，</p><p>下次你拉取的时候，是从第2万零1条数据开始继续往后拉取的，是不是？</p><p>也就是说，此时你有8万条数据是没有拉取的！</p><p>然后broker自己是知道机器上当前的整体物理内存有多大的，而且他也知道自己可用的最大空间占里面的比例，他是知道自己的消息最多可以在内存里放多少的！比如他心知肚明，他最多也就在内存里放5万条消息而已！</p><p>因为他知道，他最多只能利用10GB的os cache去放消息，这么多内存最多也就放5万左右的消息。</p><p>然后这个时候你过来拉取消息，他发现你还有8万条消息没有拉取，这个8万条消息他发现是大于10GB内存最多存放的5万条消息的，那么此时就说明，肯定有3万条消息目前是在磁盘上的，不在os cache内存里！</p><p>所以他经过上述判断，会发现此时你很大概率会从磁盘里加载3万条消息出来！他会认为，出现这种情况，很可能是因为自己作为<br>master broker负载太高了，导致没法及时的把消息给你，所以你落后的进度比较多。</p><p>这个时候，他就会告诉你，我这次给你从磁盘里读取3万条消息，但是下次你还是从slave broker去拉取吧！</p></blockquote><h1 id="基于mmap内存映射实现磁盘文件的高性能读写"><a href="#基于mmap内存映射实现磁盘文件的高性能读写" class="headerlink" title="基于mmap内存映射实现磁盘文件的高性能读写"></a>基于mmap内存映射实现磁盘文件的高性能读写</h1><h2 id="传统IO拷贝"><a href="#传统IO拷贝" class="headerlink" title="传统IO拷贝"></a>传统IO拷贝</h2><p><img src="https://jameslin23.gitee.io/2020/12/01/RocketMQ/image-20201203104024287.png" alt="image-20201203104024287"></p><p><strong>读跟写的过程都发生2次拷贝</strong></p><h2 id="mmap技术"><a href="#mmap技术" class="headerlink" title="mmap技术"></a>mmap技术</h2><blockquote><p>mmap内存映射，把物理上磁盘文件的一些地址和用户进程私有空间的一些虚拟内存进行一个映射</p><p>内存映射，简而言之就是将用户空间的一段内存区域映射到内核空间，映射成功后，用户对这段内存区域的修改可以直接反映到内核空间，同样，内核空间对这段区域的修改也直接反映用户空间。那么对于内核空间&lt;—-&gt;用户空间两者之间需要大量数据传输等操作的话效率是非常高的。</p><p>基于JDK NIO包下的MappedByteBuffer的map()函数，先将一个磁盘文件(比如一个CommitLog文件或者一个ComsumeQueue文件)映射到内存中</p></blockquote><p><img src="https://jameslin23.gitee.io/2020/12/01/RocketMQ/image-20201203104910237.png" alt="image-20201203104910237"></p><p><strong>mmap技术在进行文件映射的时候，一般有大小限制，在1G~2GB之间</strong></p><p><strong>所以RocketMQ才能让CommitLog单个文件在1GB,ConsumeQueue在5.72MB，不会太大</strong></p><h2 id="基于mmap技术-pagecache技术实现高性能的文件读写"><a href="#基于mmap技术-pagecache技术实现高性能的文件读写" class="headerlink" title="基于mmap技术+pagecache技术实现高性能的文件读写"></a>基于mmap技术+pagecache技术实现高性能的文件读写</h2><h3 id="写过程"><a href="#写过程" class="headerlink" title="写过程"></a>写过程</h3><blockquote><p>比如写入消息到CommitLog文件，你先把一个CommitLog文件通过MappedByteBuffer的map()函数映射其它地址到你的虚拟内存地址,接着就可以对这个MappedByteBuffer执行写入操作了，写入时候他会直接进入PageCache中，然后过一段时间之后,由os的线程异步刷入磁盘中</p></blockquote><p><img src="https://jameslin23.gitee.io/2020/12/01/RocketMQ/image-20201203110819924.png" alt="image-20201203110819924"></p><p><strong>只有一次数据拷贝</strong></p><h3 id="读过程"><a href="#读过程" class="headerlink" title="读过程"></a>读过程</h3><blockquote><p>先判断读取的数据是否在PageCache里，如果在就直接从PageCache读取，如果不在，就会从磁盘文件加载到PageCache中去。而PageCache技术在加载数据时候，还会将你加载数据块的临近的其它数据块也一起加载到PageCache里</p></blockquote><p><img src="https://jameslin23.gitee.io/2020/12/01/RocketMQ/image-20201204090234982.png" alt="image-20201204090234982"></p><h2 id="预映射机制-文件预热机制"><a href="#预映射机制-文件预热机制" class="headerlink" title="预映射机制 + 文件预热机制"></a>预映射机制 + 文件预热机制</h2><p><strong>(1)内存预映射机制</strong>：Broker会针对磁盘上的各种CommitLog、ConsumeQueue文件预先分配好MappedFile，也就是提前对一些<br>可能接下来要读写的磁盘文件，提前使用MappedByteBuffer执行map()函数完成映射，这样后续读写文件的时候，就可以直接执行<br>了。</p><p><strong>(2)文件预热：</strong>在提前对一些文件完成映射之后，因为映射不会直接将数据加载到内存里来，那么后续在读取尤其是CommitLog、<br>ConsumeQueue的时候，其实有可能会频繁的从磁盘里加载数据到内存中去。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;消费者拉取策略（Master-Slave）&quot;&gt;&lt;a href=&quot;#消费者拉取策略（Master-Slave）&quot; class=&quot;headerlink&quot; title=&quot;消费者拉取策略（Master-Slave）&quot;&gt;&lt;/a&gt;消费者拉取策略（Master-Slave）&lt;/
      
    
    </summary>
    
      <category term="消息队列" scheme="https://jameslin23.gitee.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
      <category term="MQ" scheme="https://jameslin23.gitee.io/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ集群模式</title>
    <link href="https://jameslin23.gitee.io/2020/12/04/RocketMQ%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/"/>
    <id>https://jameslin23.gitee.io/2020/12/04/RocketMQ集群模式/</id>
    <published>2020-12-04T10:52:53.000Z</published>
    <updated>2020-12-07T01:26:47.749Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Master-Slave主从模式"><a href="#Master-Slave主从模式" class="headerlink" title="Master-Slave主从模式"></a>Master-Slave主从模式</h1><blockquote><p>生产者发数据只会发到Master上，然后slave 从Master pull数据同步下来，<br>跟master保存一份一模一样的数据。</p><p>消费者在系统获取消息时候会先发送请求到Master Broker上去,请求获取一批消息，<br>此时Master Broker是会返回一批消息给消费者系统的。然后Master Broker在返回消息给消费者系统的时候，</p><p>会根据当时Master Broker的负载情况和Slave Broker的同步情况，向消费者系统建议下一次拉取消息的时候是从Master Broker拉取还是从Slave Broker拉取。</p></blockquote><blockquote><p>在RocketMQ 4.5版本之前，都是用Slave Broker同步数据，尽量保证数据不丢失，但是一旦Master故障了，Slave是没法自动切换成Master的，在这种情况下，如果Master Broker宕机了，这时就得手动做一些运维操作，把Slave Broker重新修改一些配置，重启机器给调整为Master Broker，这是有点麻烦的，而且会导致中间一段时间不可用。Master-Slave模式不是彻底的高可用模式，他没法实现自动把Slave切换为Master</p></blockquote><h1 id="基于DLedger高可用自动切换"><a href="#基于DLedger高可用自动切换" class="headerlink" title="基于DLedger高可用自动切换"></a>基于DLedger高可用自动切换</h1><h2 id="什么是DLedger"><a href="#什么是DLedger" class="headerlink" title="什么是DLedger"></a>什么是DLedger</h2><blockquote><p>DLedger有一个CommitLog机制，你把数据交给他，他会写入CommitLog磁盘文件里去，这些他做的第一件事。如下图可见，基于DLedger技术来实现Broker高可用框架，实际就是用DLedger先替换原来Broker自己来管理的CommitLog，由DLedger来管理CommitLog</p></blockquote><p><img src="https://jameslin23.gitee.io/2020/12/01/RocketMQ/image-20201203081710737.png" alt="image-20201203081710737"></p><h2 id="DLedger基于Raft协议选举Leader-Broker"><a href="#DLedger基于Raft协议选举Leader-Broker" class="headerlink" title="DLedger基于Raft协议选举Leader Broker"></a>DLedger基于Raft协议选举Leader Broker</h2><blockquote><p>简单来说,三台Broker机器启动时，他们都会投票自己作为Leader,然后把这个投票发送给其它Broker。</p><p>举个例子,Broker01是投票给自己的，Broker02是投票给自己的，Broker03是投票给自己的，他们都把自己的投票发送给了别<br>人。</p><hr><p>第一轮选举中，Broker01会收到别人的投票，他发现自己是投票给自己，但是Broker02投票给Broker02自己，Broker03投票给Broker03自己，似乎每个人都很自私，都在投票给自己，所以第一轮选举是失败的</p><hr><p>每个人会进入一个随机时间的休眠，比如说Broker01休眠3秒，Broker02休眠5秒，Broker03休眠4秒。</p><hr><p>Broker01必然是先苏醒过来的，他苏醒过来之后，直接会继续尝试投票给自己，并且发送自己的选票给别人。接着Broker03休眠4秒后苏醒过来，他发现Broker01已经发送来了一个选票是投给Broker01自己的，此时他自己因为没投票，所以会尊重别人的选择，就直接把票投给Broker01了，同时把自己的投票发送给别人。接着Broker02苏醒了，他收到了Broker01投票给Broker01自己，收到了Broker03也投票给了Broker01，那么他此时自己是没投票<br>的，直接就会尊重别人的选择，直接就投票给Broker01，并且把自己的投票发送给别人</p><hr><p>此时所有人都会收到三张投票，都是投给Broker01的，那么Broker01就会当选为Leader。</p></blockquote><p><strong>Raft协议中选举leader算法的简单描述，简单来说，他确保有人可以成为Leader的核心机制就是一轮选举不出来Leader的话，</strong><br><strong>就让大家随机休眠一下，先苏醒过来的人会投票给自己，其他人苏醒过后发现自己收到选票了，就会直接投票给那个人。</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/01/RocketMQ/image-20201203082435078.png" alt="image-20201203082435078"></p><h2 id="DLedger基于Raft协议进行副本同步"><a href="#DLedger基于Raft协议进行副本同步" class="headerlink" title="DLedger基于Raft协议进行副本同步"></a>DLedger基于Raft协议进行副本同步</h2><p><strong>数据同步会分为两个阶段，一个是uncommitted阶段，一个是commited阶段</strong></p><blockquote><p>首先Leader Broker上的DLedger收到一个条数据之后，会标记为uncommitted状态，然后通过自己的DLedgerServer组件把这个</p><p>uncommitted数据发送给Follower Broker的DLedgerServer。</p></blockquote><p><img src="https://jameslin23.gitee.io/2020/12/01/RocketMQ/image-20201203082959966.png" alt="image-20201203082959966"></p><blockquote><p>接着Follower Broker的DLedgerServer收到uncommitted消息之后，必须返回一个ack给Leader Broker的DLedgerServer,然后如果Leader Broker收到超过半数的Follower Broker返回的ack之后，就会将消息标记为committed状态。</p><p>然后Leader Broker上的DLedgerServer就会发送commited消息给Follower Broker机器的DLedgerServer,让他们也把消息标记commited状态</p></blockquote><p><strong>这个就是基于Raft协议实现的两阶段完成的数据同步机制。</strong></p><h2 id="如何使用心跳维护leader地位"><a href="#如何使用心跳维护leader地位" class="headerlink" title="如何使用心跳维护leader地位"></a>如何使用心跳维护leader地位</h2><p><strong>当选节点之后，首选要维护自己的leader地位，他要告诉集群其它节点，我是集群中leader，你们要成为我的follower，负责同步我的数据，并且保证只要我还活着，你们就不要妄想重新进行选举</strong></p><ol><li>每隔几秒钟leader节点会向所有follower节点发送心跳请求；</li><li>follower收到心跳请求之后，更新本地倒计时时间，同时给leader节点一个确认回复</li><li>leader节点收到过半数follower节点回复，则说明自己还是leader</li><li>如果没有收到过半数follower节点回复，则会变更为candidate状态，重新触发选举；同样的，如果follower节点一直没有收到leader节点的心跳请求,follower节点也会变更为candidate状态，触发leader选举。</li></ol><h1 id="实践部署"><a href="#实践部署" class="headerlink" title="实践部署"></a>实践部署</h1><h2 id="下载MQ，要求版本4-5以上"><a href="#下载MQ，要求版本4-5以上" class="headerlink" title="下载MQ，要求版本4.5以上"></a>下载MQ，要求版本4.5以上</h2><ol><li><a href="https://github.com/apache/rocketmq/releases" target="_blank" rel="noopener">https://github.com/apache/rocketmq/releases</a> 这里下载需要的RocketMQ版本</li><li>unzip rocketmq-all-4.7.0-bin-release.zip</li></ol><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p>服务器说明：(生产中应该将 NameServer 部署到其他服务器中，在这为了方便，与Broker部署在一起)</p><table><thead><tr><th align="center"><strong>服务器</strong></th><th align="center"><strong>ip</strong></th><th align="center"><strong>安装的服务</strong></th></tr></thead><tbody><tr><td align="center">服务器1-主</td><td align="center">192.168.10.8</td><td align="center">DLedger，Broker，NameServer</td></tr><tr><td align="center">服务器2-从</td><td align="center">192.168.10.10</td><td align="center">DLedger，Broker，NameServer</td></tr><tr><td align="center">服务器3-从</td><td align="center">192.168.10.3</td><td align="center">DLedger，Broker，NameServer</td></tr></tbody></table><p><strong>服务器1配置-Master</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">#  ## 集群名</span><br><span class="line">brokerClusterName = RaftCluster</span><br><span class="line">## broker组名，同一个RaftClusterGroup内，brokerName名要一样</span><br><span class="line">brokerName=RaftNode00</span><br><span class="line">## 监听的端口</span><br><span class="line">listenPort=30911</span><br><span class="line"># 你设置的NameServer地址和端口</span><br><span class="line">namesrvAddr=192.168.10.8:9876;192.168.10.10:9876;192.168.10.3:9876</span><br><span class="line"># 数据存储路径</span><br><span class="line">storePathRootDir=/tmp/rmqstore/node1</span><br><span class="line">storePathCommitLog=/tmp/rmqstore/node1/commitlog</span><br><span class="line"># 是否启动 DLedger</span><br><span class="line">enableDLegerCommitLog=true</span><br><span class="line"># DLedger Raft Group的名字，建议和 brokerName 保持一致</span><br><span class="line">dLegerGroup=RaftNode00</span><br><span class="line"># DLedger Group 内各节点的端口信息，同一个 Group 内的各个节点配置必须要保证一致</span><br><span class="line">dLegerPeers=n1-192.168.10.8:40911;n2-192.168.10.10:40912;n3-192.168.10.3:40913</span><br><span class="line">#节点 id, 必须属于 dLegerPeers 中的一个；同 Group 内各个节点要唯一</span><br><span class="line">dLegerSelfId=n1</span><br><span class="line"># 发送线程个数，建议配置成 Cpu 核数</span><br><span class="line">sendMessageThreadPoolNums=16</span><br></pre></td></tr></table></figure><p><strong>服务器2配置-Slave</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">brokerClusterName = RaftCluster</span><br><span class="line">brokerName=RaftNode00</span><br><span class="line">listenPort=30922</span><br><span class="line">namesrvAddr=192.168.10.8:9876;192.168.10.3:9876;192.168.10.10:9876</span><br><span class="line">storePathRootDir=/tmp/rmqstore/node2</span><br><span class="line">storePathCommitLog=/tmp/rmqstore/node2/commitlog</span><br><span class="line">enableDLegerCommitLog=true</span><br><span class="line">dLegerGroup=RaftNode00</span><br><span class="line">dLegerPeers=n1-192.168.10.8:40911;n2-192.168.10.10:40912;n3-192.168.10.3:40913</span><br><span class="line">## must be unique</span><br><span class="line">dLegerSelfId=n2</span><br><span class="line">sendMessageThreadPoolNums=16</span><br></pre></td></tr></table></figure><p><strong>服务器3配置-Slave</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">brokerClusterName = RaftCluster</span><br><span class="line">brokerName=RaftNode00</span><br><span class="line">listenPort=30933</span><br><span class="line">namesrvAddr=192.168.10.8:9876;192.168.10.3:9876;192.168.10.10:9876</span><br><span class="line">storePathRootDir=/tmp/rmqstore/node03</span><br><span class="line">storePathCommitLog=/tmp/rmqstore/node03/commitlog</span><br><span class="line">enableDLegerCommitLog=true</span><br><span class="line">dLegerGroup=RaftNode00</span><br><span class="line">dLegerPeers=n1-192.168.10.8:40911;n2-192.168.10.10:40912;n3-192.168.10.3:40913</span><br><span class="line">## must be unique</span><br><span class="line">dLegerSelfId=n3</span><br><span class="line">sendMessageThreadPoolNums=16</span><br></pre></td></tr></table></figure><h2 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h2><ol><li><p><strong>在服务器1 执行</strong></p><blockquote><p>先启动mqnamesrv服务 nohup sh mqnamesrv &gt;/dev/null 2&gt;log &amp;</p><p>再启动broker服务 nohup sh mqbroker -c ../conf/dledger/broker-node1.conf &gt;/dev/null 2&gt;log &amp;</p></blockquote></li><li><p><strong>在服务器2 执行</strong></p><blockquote><p>先启动mqnamesrv服务 nohup sh mqnamesrv &gt;/dev/null 2&gt;log &amp;</p><p>再启动broker服务 nohup sh mqbroker -c ../conf/dledger/broker-node2.conf &gt;/dev/null 2&gt;log &amp;</p></blockquote></li><li><p><strong>在服务器3 执行</strong></p><blockquote><p>先启动mqnamesrv服务 nohup sh mqnamesrv &gt;/dev/null 2&gt;log &amp;</p><p>再启动broker服务 nohup sh mqbroker -c ../conf/dledger/broker-node3.conf &gt;/dev/null 2&gt;log &amp;</p></blockquote><p><strong>内存不足，修改runbroker.sh，runserver.sh 参数</strong></p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -server -Xms8g -Xmx8g -Xmn4g"</span></span><br><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -XX:MaxDirectMemorySize=1g</span></span><br></pre></td></tr></table></figure><p><strong>连接超时，查看防火墙状态</strong></p><p>查看防火墙服务状态 <code>systemctl status firewalld</code></p><p>将防火墙关闭 <code>systemctl stop firewalld</code></p><p><strong>查看集群状态</strong></p><p><strong>sh mqadmin clusterList -n 127.0.0.1:9876</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/04/RocketMQ%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/image-20201207084050039.png" alt="image-20201207084050039"></p><p><strong>使用控制台查看</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/04/RocketMQ%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/image-20201207084942295.png" alt="image-20201207084942295"></p><p><strong>测试生产者-消费者</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/04/RocketMQ%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/image-20201207085123126.png" alt="image-20201207085123126"></p><p><img src="https://jameslin23.gitee.io/2020/12/04/RocketMQ%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/image-20201207085144645.png" alt="image-20201207085144645"></p><p><strong>测试集群高可用，关闭192.168.10.8节点，集群重新竞选master</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/04/RocketMQ%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/image-20201207085319420.png" alt="image-20201207085319420"></p><p><strong>发送消息</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/04/RocketMQ%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/image-20201207085522551.png" alt="image-20201207085522551"></p><p><strong>重启192.168.10.8节点,变成slave</strong></p><p><img src="https://jameslin23.gitee.io/2020/12/04/RocketMQ%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/image-20201207085809732.png" alt="image-20201207085809732"></p><h1 id="配置参数说明"><a href="#配置参数说明" class="headerlink" title="配置参数说明"></a>配置参数说明</h1><table><thead><tr><th>参数名</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>listenPort</td><td>10911</td><td>接受客户端连接的监听端口</td></tr><tr><td>namesrvAddr</td><td>null</td><td>nameServer 地址</td></tr><tr><td>brokerIP1</td><td>网卡的 InetAddress</td><td>当前 broker 监听的 IP</td></tr><tr><td>brokerIP2</td><td>跟 brokerIP1 一样</td><td>存在主从 broker 时，如果在 broker 主节点上配置了 brokerIP2 属性，broker 从节点会连接主节点配置的 brokerIP2 进行同步</td></tr><tr><td>brokerName</td><td>null</td><td>broker 的名称</td></tr><tr><td>brokerClusterName</td><td>DefaultCluster</td><td>本 broker 所属的 Cluser 名称</td></tr><tr><td>brokerId</td><td>0</td><td>broker id, 0 表示 master, 其他的正整数表示 slave</td></tr><tr><td>storePathCommitLog</td><td>$HOME/store/commitlog/</td><td>存储 commit log 的路径</td></tr><tr><td>storePathConsumerQueue</td><td>$HOME/store/consumequeue/</td><td>存储 consume queue 的路径</td></tr><tr><td>mappedFileSizeCommitLog</td><td>1024 * 1024 * 1024(1G)</td><td>commit log 的映射文件大小</td></tr><tr><td>deleteWhen</td><td>04</td><td>在每天的什么时间删除已经超过文件保留时间的 commit log</td></tr><tr><td>fileReservedTime</td><td>72</td><td>以小时计算的文件保留时间</td></tr><tr><td>brokerRole</td><td>ASYNC_MASTER</td><td>SYNC_MASTER/ASYNC_MASTER/SLAVE</td></tr><tr><td>flushDiskType</td><td>ASYNC_FLUSH</td><td>SYNC_FLUSH/ASYNC_FLUSH SYNC_FLUSH 模式下的 broker 保证在收到确认生产者之前将消息刷盘。ASYNC_FLUSH 模式下的 broker 则利用刷盘一组消息的模式，可以取得更好的性能。</td></tr><tr><td>enableDLegerCommitLog</td><td>是否启动 DLedger</td><td>true</td></tr><tr><td>dLegerGroup</td><td>DLedger Raft Group的名字，建议和 brokerName 保持一致</td><td>RaftNode00</td></tr><tr><td>dLegerPeers</td><td>DLedger Group 内各节点的端口信息，同一个 Group 内的各个节点配置必须要保证一致</td><td>n0-127.0.0.1:40911;n1-127.0.0.1:40912;n2-127.0.0.1:40913</td></tr><tr><td>dLegerSelfId</td><td>节点 id, 必须属于 dLegerPeers 中的一个；同 Group 内各个节点要唯一</td><td>n0</td></tr><tr><td>sendMessageThreadPoolNums</td><td>发送线程个数，建议配置成 Cpu 核数</td><td>16</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Master-Slave主从模式&quot;&gt;&lt;a href=&quot;#Master-Slave主从模式&quot; class=&quot;headerlink&quot; title=&quot;Master-Slave主从模式&quot;&gt;&lt;/a&gt;Master-Slave主从模式&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;生
      
    
    </summary>
    
      <category term="消息队列" scheme="https://jameslin23.gitee.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
      <category term="MQ" scheme="https://jameslin23.gitee.io/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ单机模式</title>
    <link href="https://jameslin23.gitee.io/2020/12/04/RocketMQ%E5%8D%95%E6%9C%BA%E6%A8%A1%E5%BC%8F/"/>
    <id>https://jameslin23.gitee.io/2020/12/04/RocketMQ单机模式/</id>
    <published>2020-12-04T10:20:49.000Z</published>
    <updated>2020-12-04T10:50:36.052Z</updated>
    
    <content type="html"><![CDATA[<h1 id="按照步骤"><a href="#按照步骤" class="headerlink" title="按照步骤"></a>按照步骤</h1><h2 id="官网下载"><a href="#官网下载" class="headerlink" title="官网下载"></a>官网下载</h2><p><a href="http://rocketmq.apache.org/" target="_blank" rel="noopener">http://rocketmq.apache.org/</a></p><p>rocketmq-all-4.6.1-bin-release.zip</p><p><strong>unzip rocketmq-all-4.6.1-bin-release.zip</strong></p><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><p><strong>在MQ目录下 conf/2m-noslave 创建新的配置文件</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">#broker 集群名称</span><br><span class="line">brokerClusterName = cluster-bus</span><br><span class="line">#broker 名称</span><br><span class="line">brokerName = broker-4</span><br><span class="line">#broker id</span><br><span class="line">brokerId = 0</span><br><span class="line">#指定nameserver 的地址端口</span><br><span class="line">namesrvAddr=192.168.2.4:9876</span><br><span class="line">#数据清除时间</span><br><span class="line">deleteWhen=04</span><br><span class="line">#文件保存时间</span><br><span class="line">fileReservedTime=48</span><br><span class="line">#磁盘阀值</span><br><span class="line">diskMaxUsedSpaceRatio=95</span><br><span class="line">#broker 角色</span><br><span class="line">brokerRole=ASYNC_MASTER</span><br><span class="line">#刷盘方式</span><br><span class="line">flushDiskType=ASYNC_FLUSH</span><br><span class="line">#CommitLog 存储路径</span><br><span class="line">storePathCommitLog=/data/mq/store/commitlog</span><br><span class="line">#数据存储根路径</span><br><span class="line">storePathRootDir=/data/mq/store</span><br><span class="line">#storePathConsumerQueue 消息队列存储路径</span><br><span class="line">#storePathConsumerQueue=/home/apps/data/rocketmq/store/consumerqueue/</span><br><span class="line">#storePathIndex 消息索引存储队列</span><br><span class="line">#storePathIndex=/home/apps/data/rocketmq/store/index/ </span><br><span class="line">#单次从内存最大消费字节数</span><br><span class="line">#maxTransferBytesOnMessageInMemory=2621440</span><br><span class="line">#单次从内存最大消费信息条数   </span><br><span class="line">maxTransferCountOnMessageInMemory=20000</span><br><span class="line">#单次从磁盘获取信息的最大条数</span><br><span class="line">maxTransferCountOnMessageInDisk=1000</span><br><span class="line">#单次从磁盘获取信息的最大字节数</span><br><span class="line">maxTransferBytesOnMessageInDisk=6553500</span><br><span class="line">#生产者最大发送线程池</span><br><span class="line">sendThreadPoolQueueCapacity=100000</span><br><span class="line">#消费者最大拉取线程池</span><br><span class="line">pullThreadPoolQueueCapacity=1000000</span><br><span class="line">#客户管理端线程池</span><br><span class="line">clientManagerThreadPoolQueueCapacity=10000000</span><br><span class="line">#消费管理端线程池</span><br><span class="line">consumerManagerThreadPoolQueueCapacity=10000000</span><br><span class="line">#发送等待时间</span><br><span class="line">waitTimeMillsInSendQueue=10000</span><br><span class="line">#发送线程</span><br><span class="line">sendMessageThreadPoolNums=4</span><br><span class="line">#刷入内存等待时间</span><br><span class="line">osPageCacheBusyTimeOutMills=3000</span><br></pre></td></tr></table></figure><h2 id="修改启动参数"><a href="#修改启动参数" class="headerlink" title="修改启动参数"></a>修改启动参数</h2><p>如果服务器的内存足够，无需修改</p><p>MQ根目录bin目录，对runbroker.sh，runserver.sh启动文件</p><p><strong>runbroker.sh</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -server -Xms8g -Xmx8g -Xmn4g"</span></span><br><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -XX:MaxDirectMemorySize=1g"</span></span><br></pre></td></tr></table></figure><p><strong>runserver.sh</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -server -Xms2g -Xmx2g -Xmn1g -XX:PermSize=512m -XX:MaxPermSize=512m"</span></span><br><span class="line"><span class="comment"># 默认是磁盘90%,当磁盘空间达到90%,MQ就没办法处理数据,此设置可以提高98%</span></span><br><span class="line">JAVA_OPT=<span class="string">"<span class="variable">$&#123;JAVA_OPT&#125;</span> -Drocketmq.broker.diskSpaceWarningLevelRatio=0.98"</span></span><br></pre></td></tr></table></figure><h2 id="启动MQ"><a href="#启动MQ" class="headerlink" title="启动MQ"></a>启动MQ</h2><blockquote><p>先启动mqnamesrv服务 nohup sh mqnamesrv &gt;/dev/null 2&gt;log &amp;</p><p>再启动broker服务 nohup sh mqbroker -c ../conf/2m-noslave/broker-57.properties &gt;/dev/null 2&gt;log &amp;</p></blockquote><h2 id="查看进程"><a href="#查看进程" class="headerlink" title="查看进程"></a>查看进程</h2><blockquote><p>jps -l</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;按照步骤&quot;&gt;&lt;a href=&quot;#按照步骤&quot; class=&quot;headerlink&quot; title=&quot;按照步骤&quot;&gt;&lt;/a&gt;按照步骤&lt;/h1&gt;&lt;h2 id=&quot;官网下载&quot;&gt;&lt;a href=&quot;#官网下载&quot; class=&quot;headerlink&quot; title=&quot;官网下载&quot;&gt;&lt;/a
      
    
    </summary>
    
      <category term="消息队列" scheme="https://jameslin23.gitee.io/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
      <category term="MQ" scheme="https://jameslin23.gitee.io/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>redis</title>
    <link href="https://jameslin23.gitee.io/2020/12/04/redis/"/>
    <id>https://jameslin23.gitee.io/2020/12/04/redis/</id>
    <published>2020-12-04T02:34:34.000Z</published>
    <updated>2020-12-09T12:00:55.431Z</updated>
    
    <content type="html"><![CDATA[<h1 id="redis基础知识"><a href="#redis基础知识" class="headerlink" title="redis基础知识"></a>redis基础知识</h1><ul><li><strong>Key-Value数据库，NOSQL</strong></li><li><strong>存储，查询高效(Redis读的速度是110000次/秒,写的速度80000次/秒)</strong></li><li><strong>单线程，基于内存操作，CPU不是redis性能瓶颈，瓶颈是机器带宽和内存</strong></li></ul><h2 id="存储数据结构"><a href="#存储数据结构" class="headerlink" title="存储数据结构"></a>存储数据结构</h2><p><strong>String类型</strong></p><p><strong>这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存</strong></p><p>String的实际应用比较广泛</p><ul><li><strong>缓存功能:**</strong>String<strong>字符串是最常用的数据类型，不仅仅是</strong>Redis<strong>，各个语言都是最基本类型，因此，利用</strong>Redis<strong>作为缓存，配合其它数据库作为存储层，利用</strong>Redis**支持高并发的特点，可以大大加快系统的读写速度、以及降低后端数据库的压力。</li><li><strong>计数器:</strong>许多系统都会使用<strong>Redis</strong>作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。</li><li><strong>共享用户Session：</strong>用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存<strong>Cookie</strong>，但是可以利用<strong>Redis</strong>将用户的<strong>Session</strong>集中管理，在这种模式只需要保证<strong>Redis</strong>的高可用，每次用户<strong>Session</strong>的更新和获取都可以快速完成。大大提高效率。</li></ul><p><strong>List列表</strong></p><p> 比如可以通过 <strong>List</strong> 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。</p><ul><li><p><strong>消息队列：Redis</strong>的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过<strong>Lpush</strong>命令从左边插入数据，多个数据消费者，可以使用<strong>BRpop</strong>命令阻塞的“抢”列表尾部的数据。</p></li><li><p>文章列表或者数据分页展示的应用。</p><p>比如，我们常用的博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用<strong>Redis</strong>的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。</p></li></ul><p><strong>Set集合</strong></p><p><strong>Set</strong> 是无序集合，会自动去重的那种</p><p>可以基于 <strong>Set</strong> 玩儿交集、并集、差集的操作，比如交集吧，我们可以把两个人的好友列表整一个交集，看看俩人的共同好友是谁</p><p><strong>Hash类型</strong></p><blockquote><p>key-value</p></blockquote><p><strong>Zset有序集合</strong></p><p><strong>Sorted set</strong> 是排序的 <strong>Set</strong>，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。</p><p>有序集合的使用场景与集合类似，但是set集合不是自动有序的，而<strong>Sorted set</strong>可以利用分数进行成员间的排序，而且是插入时就排序好。所以当你需要一个有序且不重复的集合列表时，就可以选择<strong>Sorted set</strong>数据结构作为选择方案。</p><ul><li><p><strong>排行榜</strong>：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。</p></li><li><p>用<strong>Sorted Sets</strong>来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。</p><p>微博热搜榜，就是有个后面的热度值，前面就是名称</p></li></ul><p><strong>Geospatial地理位置</strong></p><p>代补充</p><p><strong>Hyperloglog基数统计</strong></p><p><strong>通常是用来统计一个集合中不重复的元素个数</strong></p><blockquote><p>如果统计 PV 那非常好办，给每个网页一个独立的 Redis 计数器就可以了，这个计数器的 key 后缀加上当天的日期。这样来一个请求，incrby 一次，最终就可以统计出所有的 PV 数据。</p><p>但是 UV 不一样，它要去重，同一个用户一天之内的多次访问请求只能计数一次。</p><p>这就要求每一个网页请求都需要带上用户的 ID，无论是登陆用户还是未登陆用户都需要一个唯一 ID 来标识</p><p>你也许已经想到了一个简单的方案，那就是为每一个页面一个独立的 set 集合来存储所有当天访问过此页面的用户 ID。</p><p>当一个请求过来时，我们使用 sadd 将用户 ID 塞进去就可以了。</p><p>通过 scard 可以取出这个集合的大小，这个数字就是这个页面的 UV 数据。没错，这是一个非常简单的方案。</p><p>但是，如果你的页面访问量非常大，比如一个爆款页面几千万的 UV，你需要一个很大的 set 集合来统计，这就非常浪费空间。</p><p>如果这样的页面很多，那所需要的存储空间是惊人的。为这样一个去重功能就耗费这样多的存储空间，值得么？其实老板需要的数据又不需要太精确，105w 和 106w 这两个数字对于老板们来说并没有多大区别，So，有没有更好的解决方案呢？</p><p>HyperLogLog 提供了两个指令 pfadd 和 pfcount，根据字面意义很好理解，一个是增加计数，一个是获取计数。</p><p>pfadd 用法和 set 集合的 sadd 是一样的，来一个用户 ID，就将用户 ID 塞进去就是，pfcount 和 scard 用法是一样的，直接获取计数值。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">127.0</span>.0.1:<span class="number">6379</span>&gt; pfadd codehole user1</span><br><span class="line">(integer) <span class="number">1</span></span><br><span class="line"><span class="number">127.0</span>.0.1:<span class="number">6379</span>&gt; pfcount codehole</span><br><span class="line">(integer) <span class="number">1</span></span><br><span class="line"><span class="number">127.0</span>.0.1:<span class="number">6379</span>&gt; pfadd codehole user2</span><br><span class="line">(integer) <span class="number">1</span></span><br><span class="line"><span class="number">127.0</span>.0.1:<span class="number">6379</span>&gt; pfcount codehole</span><br><span class="line">(integer) <span class="number">2</span></span><br><span class="line"><span class="number">127.0</span>.0.1:<span class="number">6379</span>&gt; pfadd codehole user3</span><br><span class="line">(integer) <span class="number">1</span></span><br><span class="line"><span class="number">127.0</span>.0.1:<span class="number">6379</span>&gt; pfcount codehole</span><br><span class="line">(integer) <span class="number">3</span></span><br><span class="line"><span class="number">127.0</span>.0.1:<span class="number">6379</span>&gt; pfadd codehole user4</span><br><span class="line">(integer) <span class="number">1</span></span><br><span class="line"><span class="number">127.0</span>.0.1:<span class="number">6379</span>&gt; pfcount codehole</span><br><span class="line">(integer) <span class="number">4</span></span><br><span class="line"><span class="number">127.0</span>.0.1:<span class="number">6379</span>&gt; pfadd codehole user5</span><br><span class="line">(integer) <span class="number">1</span></span><br><span class="line"><span class="number">127.0</span>.0.1:<span class="number">6379</span>&gt; pfcount codehole</span><br><span class="line">(integer) <span class="number">5</span></span><br><span class="line"><span class="number">127.0</span>.0.1:<span class="number">6379</span>&gt; pfadd codehole user6</span><br><span class="line">(integer) <span class="number">1</span></span><br><span class="line"><span class="number">127.0</span>.0.1:<span class="number">6379</span>&gt; pfcount codehole</span><br><span class="line">(integer) <span class="number">6</span></span><br><span class="line"><span class="number">127.0</span>.0.1:<span class="number">6379</span>&gt; pfadd codehole user7 user8 user9 user10</span><br><span class="line">(integer) <span class="number">1</span></span><br><span class="line"><span class="number">127.0</span>.0.1:<span class="number">6379</span>&gt; pfcount codehole</span><br><span class="line">(integer) <span class="number">10</span></span><br></pre></td></tr></table></figure><p><strong>Hyperloglog原理—–&gt;</strong> <a href="https://mp.weixin.qq.com/s/9dtGe3d_mbbxW5FpVPDNow" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/9dtGe3d_mbbxW5FpVPDNow</a></p><p><strong>BitMap位图场景</strong></p><blockquote><p>位存储,都是操作二进制进行记录,0和1</p><p>Redis提供了SETBIT、GETBIT、BITCOUNT、BITOP四个命令用于处理二进制位数组。</p></blockquote><h2 id="BitMap原理"><a href="#BitMap原理" class="headerlink" title="BitMap原理"></a>BitMap原理</h2><blockquote><p>BitMap的基本原理就是用一个bit来标记某个元素对应的value,而key即是该元素。由于采用一个bit来存储一个数据，因此可以大大的节省空间。</p><p>我们通过一个具体例子来说明BitMap的原理。假设我们要对0-31内的3个元素(10,17,28)排序。我们就可以采用BitMap方法(假设这些元素没有重复)</p><p>如下图,要表示32个数，我们只需要32个bit(4Bytes)，首先我们开辟4Byte的空间,将这些空间的所有bit位都设置为0</p></blockquote><p><img src="https://jameslin23.gitee.io/2020/12/04/redis/image-20201204150535800.png" alt="image-20201204150535800"></p><p>然后，我们要添加(10, 17,28) 这三个数到 BitMap 中，需要的操作就是在相应的位置上将0置为1即可。如下图，比如现在要插入 10 这个元素，只需要将蓝色的那一位变为1即可。</p><p><img src="https://jameslin23.gitee.io/2020/12/04/redis/image-20201204150638693.png" alt="image-20201204150638693"></p><p>将这些数据插入后，假设我们想对数据进行排序或者检索数据是否存在，就可以依次遍历这个数据结构，碰到位为 1 的情况，就当这个数据存在。</p><p><strong>字符串映射</strong></p><blockquote><p>BitMap 也可以用来表述字符串类型的数据，但是需要有一层Hash映射，如下图，通过一层映射关系，可以表述字符串是否存在。</p></blockquote><p><img src="https://jameslin23.gitee.io/2020/12/04/redis/image-20201204150738688.png" alt="image-20201204150738688"></p><p>当然这种方式会有数据碰撞的问题，但可以通过 Bloom Filter 做一些优化。</p><p><strong>使用场景一：统计活跃用户</strong></p><blockquote><p>使用时间作为cacheKey，然后用户ID为offset(当用户很大时，需要优化)，如果当日活跃过就设置为1</p></blockquote><p><strong>使用场景二：户在线状态</strong></p><blockquote><p>只需要一个key，然后用户ID为offset(当用户很大时，需要优化)，如果在线就设置为1，不在线就设置为0</p></blockquote><p><strong>使用场景三 : 用户签到</strong></p><blockquote><p>用户ID作为key，签到的天数offest</p></blockquote><h1 id="redis持久化"><a href="#redis持久化" class="headerlink" title="redis持久化"></a>redis持久化</h1><p><strong>SAVE  保存是阻塞主进程，客户端无法连接redis，等SAVE完成后，主进程才开始工作，客户端可以连接</strong></p><p><strong>BGSAVE  是fork一个save的子进程，在执行save过程中，不影响主进程，客户端可以正常链接redis，等子进程fork执行save完成后，通知主进程，子进程关闭。很明显BGSAVE</strong></p><h2 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h2><blockquote><p>快照方式，允许你每隔一段时间对内存数据做一次快照然后存储到硬盘中</p></blockquote><p><strong>RDB可以通过在配置文件中配置时间或者改动键的个数来定义快照条件，编辑配置文件redis.conf</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 默认配置</span><br><span class="line">save 900 1    #15分钟之内至少有一个键被更改则进行快照</span><br><span class="line">save 300 10   #5分钟之内至少有10个键被更改则进行快照 </span><br><span class="line">save 60 10000 #1分钟之内至少有1000个键被更改则进行快照</span><br></pre></td></tr></table></figure><p>RDB持久化到磁盘文件默认路径是当前安装目录，文件名为dump.rdb，你可以通过配置文件dir和dbfilename来指定文件目录和文件名称，rdb文件还可以进行压缩,你可以通过配置rdbcompression参数进行压缩</p><p><img src="https://jameslin23.gitee.io/2020/12/04/redis/image-20201204162833185.png" alt="image-20201204162833185"></p><p><strong>执行流程</strong></p><blockquote><p>（1）redis根据配置自己尝试去生成rdb快照文件</p><p>（2）fork一个子进程出来</p><p>（3）子进程尝试将数据dump到临时的rdb快照文件中</p><p>（4）完成rdb快照文件的生成之后，就替换之前的旧的快照文件</p></blockquote><p><strong>存在问题</strong></p><blockquote><p>当还没进行sava，触发存储快照时，服务器宕机，会丢失上次保存快照-到宕机时这段时间的数据。</p></blockquote><h2 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h2><blockquote><p>记录客户端对服务器的每一个写操作命令,并将这些写操作以Redis协议追加保存到.aof文件,在redis服务器重启时,在redis服务器重启时，会加载并运行aof文件命令，已达到恢复数据的目的。</p></blockquote><p><img src="https://jameslin23.gitee.io/2020/12/04/redis/image-20201204162946548.png" alt="image-20201204162946548"></p><p><strong>开启AOF持久化方式</strong></p><p>Redis默认不开启AOF持久化方式，我们可以在配置文件中开启并进行更加详细的配置，如下面的redis.conf文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 开启aof机制</span><br><span class="line">appendonly yes</span><br><span class="line"></span><br><span class="line"># aof文件名</span><br><span class="line">appendfilename &quot;appendonly.aof&quot;</span><br><span class="line"></span><br><span class="line"># 写入策略,always表示每个写操作都保存到aof文件中,也可以是everysec或no</span><br><span class="line">appendfsync always</span><br><span class="line"></span><br><span class="line"># 默认不重写aof文件</span><br><span class="line">no-appendfsync-on-rewrite no</span><br><span class="line"></span><br><span class="line"># 保存目录</span><br><span class="line">dir ~/redis/</span><br></pre></td></tr></table></figure><p><strong>执行方式</strong></p><ul><li><p><strong>always</strong>: Redis的每条写命令都写入到系统缓冲区，然后每条写命令都使用fsync“写入”硬盘。</p><blockquote><p>客户端的每一个写操作都保存到aof文件当，这种策略很安全，但是每个写请注都有IO操作，所以也很慢。</p></blockquote></li><li><p><strong>everysec</strong>: 过程与always相同，只是fsync的频率为1秒钟一次。这个是Redis默认配置，如果系统宕机，会丢失一秒左右的数据</p><blockquote><p>appendfsync的默认写入策略，每秒写入一次aof文件，因此，最多可能会丢失1s的数据。</p></blockquote></li><li><p><strong>no</strong>: 由操作系统决定什么时候从系统缓冲区刷新到硬盘。</p><blockquote><p>Redis服务器不负责写入aof，而是交由操作系统来处理什么时候写入aof文件。更快，但也是最不安全的选择，不推荐使用。</p></blockquote></li></ul><p><strong>AOF文件重写</strong></p><blockquote><p>AOF将客户端的每一个写操作都追加到aof文件末尾，比如对一个key多次执行incr命令，这时候，aof保存每一次命令到aof文件中，aof文件会变得非常大。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">incr num <span class="number">1</span></span><br><span class="line">incr num <span class="number">2</span></span><br><span class="line">incr num <span class="number">3</span></span><br><span class="line">...</span><br><span class="line">incr num <span class="number">100000</span></span><br></pre></td></tr></table></figure><p>aof文件太大，加载aof文件恢复数据时，就会非常慢，为了解决这个问题，Redis支持aof文件重写，通过重写aof，可以生成一个恢复当前数据的最少命令集，比如上面的例子中那么多条命令，可以重写为:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set num 100000</span><br></pre></td></tr></table></figure><p><strong>注意：通过在redis.conf配置文件中的选项no-appendfsync-on-rewrite可以设置是否开启重写，这种方式会在每次fsync时都重写，影响服务器性以，因此默认值为no，不推荐使用。</strong></p><p><strong>AOF文件损坏</strong></p><blockquote><p>在写入aof日志文件时，如果redis服务器宕机,则aof日志文件会出格式错误,在重启redis服务器时,redis服务器会拒绝载入这个aof文件，可以通过以下步骤修复aof并恢复数据</p><p>使用redis-check-aof命令修复aof文件，该命令格式如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; redis-check-aof -fix file.aof</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p><strong>AOF的优点</strong></p><p>AOF只是追加日志文件，因此对服务器性能影响较小，速度比RDB要快，消耗的内存较小</p><p><strong>AOF的缺点</strong></p><ul><li>AOF方式生成的日志文件太大，即使通过AFO重写，文件体积仍然很大。</li><li>恢复数据的速度比RDB</li></ul><h2 id="RDB-VS-AOF"><a href="#RDB-VS-AOF" class="headerlink" title="RDB VS AOF"></a>RDB VS AOF</h2><table><thead><tr><th></th><th>RDB</th><th>AOF</th></tr></thead><tbody><tr><td>启动优先级</td><td>低</td><td>高</td></tr><tr><td>体积</td><td>小</td><td>大</td></tr><tr><td>恢复速度</td><td>快</td><td>慢</td></tr><tr><td>数据安全性</td><td>丢数据</td><td>根据策略</td></tr></tbody></table><h1 id="小总结"><a href="#小总结" class="headerlink" title="小总结"></a>小总结</h1><ul><li><strong>简单概述redis基础，8大数据结构，及bitmap原理，运用场景</strong></li><li><strong>redis两大持久化机制,RDB原理，AOF原理及各种优缺点</strong></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;redis基础知识&quot;&gt;&lt;a href=&quot;#redis基础知识&quot; class=&quot;headerlink&quot; title=&quot;redis基础知识&quot;&gt;&lt;/a&gt;redis基础知识&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Key-Value数据库，NOSQL&lt;/strong&gt;&lt;
      
    
    </summary>
    
      <category term="Nosql" scheme="https://jameslin23.gitee.io/categories/Nosql/"/>
    
    
      <category term="缓存" scheme="https://jameslin23.gitee.io/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
</feed>
