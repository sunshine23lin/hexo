{"meta":{"title":"JAVA","subtitle":null,"description":null,"author":"LeBron Tao","url":"https://jameslin23.gitee.io","root":"/"},"pages":[{"title":"关于","date":"2020-11-26T07:46:56.447Z","updated":"2020-11-26T07:44:08.707Z","comments":false,"path":"about/index.html","permalink":"https://jameslin23.gitee.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"书单","date":"2020-11-26T07:46:56.450Z","updated":"2020-11-26T07:44:08.708Z","comments":false,"path":"books/index.html","permalink":"https://jameslin23.gitee.io/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2020-11-26T07:46:56.453Z","updated":"2020-11-26T07:44:08.709Z","comments":false,"path":"categories/index.html","permalink":"https://jameslin23.gitee.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2020-11-26T07:46:56.458Z","updated":"2020-11-26T07:44:08.711Z","comments":true,"path":"links/index.html","permalink":"https://jameslin23.gitee.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2020-11-26T07:46:56.461Z","updated":"2020-11-26T07:44:08.712Z","comments":false,"path":"repository/index.html","permalink":"https://jameslin23.gitee.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-11-26T07:46:56.464Z","updated":"2020-11-26T07:44:08.713Z","comments":false,"path":"tags/index.html","permalink":"https://jameslin23.gitee.io/tags/index.html","excerpt":"","text":""},{"title":"","date":"2020-11-26T07:46:56.456Z","updated":"2020-11-26T07:44:08.709Z","comments":true,"path":"categories/Spring/index.html","permalink":"https://jameslin23.gitee.io/categories/Spring/index.html","excerpt":"","text":"分类: Spring | Hexo 昵称 Web Developer &amp; Designer Shenzhen, China × Toggle navigation 首页 归档 分类 标签 项目 书单 友链 关于 公告 欢迎交流与分享经验! 分类 Spring3 标签 web后端1 标签云 web后端 归档 六月 20193 最新文章 Spring post11 2019-06-05 Spring 初步搭建spring 2019-06-05 Spring Hello World 2019-06-05 分类: Spring 共 3 篇文章 All Spring Spring (Total 3 articles) 2019-06-05 &nbsp;&nbsp;&nbsp; post11 2019-06-05 &nbsp;&nbsp;&nbsp; 初步搭建spring 2019-06-05 &nbsp;&nbsp;&nbsp; Hello World Theme by cofess base on pure. window.jQuery || document.write('') (function (window) { var INSIGHT_CONFIG = { TRANSLATION: { POSTS: '文章', PAGES: '页面', CATEGORIES: '分类', TAGS: '标签', UNTITLED: '(未命名)', }, ROOT_URL: '/', CONTENT_URL: '/content.json', }; window.INSIGHT_CONFIG = INSIGHT_CONFIG; })(window);"}],"posts":[{"title":"排序算法之直接插入排序","slug":"排序算法之直接插入排序","date":"2021-01-09T11:54:50.000Z","updated":"2021-01-09T12:10:11.622Z","comments":true,"path":"2021/01/09/排序算法之直接插入排序/","link":"","permalink":"https://jameslin23.gitee.io/2021/01/09/排序算法之直接插入排序/","excerpt":"","text":"直接插入排序的规律每一步将一个待排序的记录，插入到前面已经排好序的有序序列中，直到插完位置 时间复杂度时间复杂度：平均时间O(N^2) 最差时间O(N^2) 相对稳定 编码思路 定义第一个for循环，从下标1开始，逐个进行排序 定义一个当前变量tmep[i] 定义第二个for循环，从已排好序的序列中进行查找 找到合适条件插入位置上 代码1234567891011121314151617181920212223public static int[] insertSort(int[] arr) &#123; for (int i=1;i&lt;arr.length;i++)&#123; int cur = arr[i]; boolean flag = false; for (int j=i-1;j&gt;-1;j--)&#123; // 继续往前查找 if (cur&lt;arr[j])&#123; // [j+1]此时就是cur arr[j+1] = arr[j]; &#125;else &#123; // 找到适合的位置 arr[j+1] = cur; flag = true; break; &#125; &#125; // 一直找不到说明是最小的值 if (!flag) &#123; arr[0] = cur; &#125; &#125; return arr; &#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://jameslin23.gitee.io/categories/数据结构与算法/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"https://jameslin23.gitee.io/tags/排序算法/"}]},{"title":"排序算法之选择排序","slug":"排序算法之选择排序","date":"2021-01-09T11:30:46.000Z","updated":"2021-01-09T12:09:36.996Z","comments":true,"path":"2021/01/09/排序算法之选择排序/","link":"","permalink":"https://jameslin23.gitee.io/2021/01/09/排序算法之选择排序/","excerpt":"","text":"选择排序规律 从待排序中，找到关键字最小的元素 如果最小元素不是待排序列中的第一个元素，将其和第一个元素互换 从余下N-1个元素中，找出关键字最小的元素，重复(1)、(2)步，直到排序结束 时间复杂度时间复杂度：平均时间O(N^2) 最差时间O(N^2) 相对稳定 编码思路 定义2个for循环，第一个for循环是需要比较的轮数，第二for循环找出最小的数并进行交换 代码12345678910111213public static int[] selectSort(int[] arr)&#123; for (int i=0;i&lt;arr.length-1;i++)&#123; int min = arr[i]; for (int j=i;j&lt;arr.length-1;j++)&#123; if (min&gt;arr[j+1])&#123; min = arr[j+1]; arr[j+1] = arr[i]; arr[i] = min; &#125; &#125; &#125; return arr;&#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://jameslin23.gitee.io/categories/数据结构与算法/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"https://jameslin23.gitee.io/tags/排序算法/"}]},{"title":"排序算法之冒泡排序","slug":"排序算法之冒泡排序","date":"2021-01-09T10:58:41.000Z","updated":"2021-01-09T12:09:07.390Z","comments":true,"path":"2021/01/09/排序算法之冒泡排序/","link":"","permalink":"https://jameslin23.gitee.io/2021/01/09/排序算法之冒泡排序/","excerpt":"","text":"冒泡算法规律 比较相邻的元素，如果第一个比第二个大，就交换。 对每一对相邻元素做同样的工作，从开始第一对到结尾的最后一对，这步做完，最后元素会是最大的数（第一波冒泡完成） 针对所有的元素以上的步骤，除了最后一个。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 时间复杂度时间复杂度：平均时间O(N^2) 最差时间O(N^2) 相对稳定 编码思路 两个for循环，第一个for循环冒泡轮数，第二个for循环进行换位判断。 定义变量temp 代码1234567891011121314public static int [] bubbleSort(int [] arr)&#123; // 需要比较的轮数 i for (int i=0;i&lt;arr.length-1;i++)&#123; // i-1对比的数量会依次递减 for (int j=0;j&lt;arr.length-i-1;j++)&#123; if (arr[j]&gt;arr[j+1])&#123; int temp = arr[j]; arr[j] = arr[j+1]; arr[j+1] = temp; &#125; &#125; &#125; return arr;&#125; 优化代码 当你这轮的数字都没有进行交换时，说明数字已经是顺序了，可以退出循环。 123456789101112131415161718192021// 优化 public static int [] bubbleSort2(int [] arr)&#123; boolean flag = false; // 调出循环标识 for (int i=0;i&lt;arr.length-1;i++)&#123; // i-1对比的数量会依次递减 for (int j=0;j&lt;arr.length-i-1;j++)&#123; if (arr[j]&gt;arr[j+1])&#123; int temp = arr[j]; arr[j] = arr[j+1]; arr[j+1] = temp; flag = true; &#125; &#125; if (!flag)&#123; break; &#125;else &#123; flag = false; // 重置 flag!!!, 进行下次判断 &#125; &#125; return arr; &#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://jameslin23.gitee.io/categories/数据结构与算法/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"https://jameslin23.gitee.io/tags/排序算法/"}]},{"title":"ThreadLocal","slug":"ThreadLocal","date":"2021-01-03T05:37:43.000Z","updated":"2021-01-09T10:45:10.179Z","comments":true,"path":"2021/01/03/ThreadLocal/","link":"","permalink":"https://jameslin23.gitee.io/2021/01/03/ThreadLocal/","excerpt":"","text":"ThreadLocalThreadLocal是一个本地线程副本变量工具类。主要用于将私有线程和该线程存放的副本对象做一个映射，各个线程之间的变量互不干扰，在高并发场景下，可以实现无状态的调用。适用于各个线程不共享变量值的操作。 ThreadLocal 工作原理每个线程的内部维护一个ThreadLocalMap，它是一个Map(key,value)数据格式，key是一个弱引用。也就是ThreadLocal本身,而value存在是线程变量的值。 也就是说ThreadLocal本身并不存储线程的变量值，它只是一个工具类，用来维护线程内部的Map,帮助存和取变量。 ThreadLocal解决Hash冲突与HashMap不同，ThreadLocalMap结构非常简单，没有next引用,也就是ThreadLocalMap中解决Hash冲突的方式并非链表的方法，而是采用线性探测方法。所谓线性探测，就是根据key的hashcode值确定元素在table数组中的位置，如果发现这个位置已经被其它key值占用，则利用固定算法寻找一定步长的下一个位置，依次判断，直至找到能够存放的位置。 12345678910111213/ * Increment i modulo len. */private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0);&#125;/ * Decrement i modulo len. */private static int prevIndex(int i, int len) &#123; return ((i - 1 &gt;= 0) ? i - 1 : len - 1);&#125; ThreadLocal内存泄漏ThreadLocal在ThreadLocalMap中是以一个弱引用身份被Entry中的key引用的，因此如果ThreadLocal没有外部强引用来引用它，那么ThreadLocal会在下次JVM垃圾收集时被回收。这个时候Entry中key已经被回收，但是value又是强引用不会被垃圾收集器回收。这样ThreadLocal的线程如果一直执行运行，value就一直得不到回收，这样就会发生内存泄漏。 ThreadLocalMap的key是弱引用 ThreadLocalMap中key是弱引用，而value是强引用才会导致内存泄漏的问题，至于为什么要这样设计，这样分2种情况来讨论： key使用强引用：这样会导致一个问题,引用的ThreadLocal对象被回收了，但是ThreadLocalMap还有持有ThreadLocal强引用，如果没有手动删除，ThreadLocal不会被回收，则会导致内存泄漏。 key使用弱引用：这样的话，引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。 比较以上两种情况，我可以发现：由于ThreadLocalMap的生命周期跟Thread一样，如果都没有手动删除对应key,会导致内存 泄漏，但是使用弱引用可以多一层保障。 ThreadLocal的应用场景ThreadLocal适用于独立变量副本的情况，比如Hibernate的session获取场景。 1234567891011121314private static final ThreadLocal&lt;Session&gt; threadLocal = new ThreadLocal&lt;Session&gt;();public static Session getCurrentSession()&#123; Session session = threadLocal.get(); try &#123; if(session ==null&amp;&amp;!session.isOpen())&#123; //... &#125; threadLocal.set(session); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; return session;&#125;","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://jameslin23.gitee.io/categories/并发编程/"}],"tags":[{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"https://jameslin23.gitee.io/tags/ThreadLocal/"}]},{"title":"JVM篇之垃圾回收器G1","slug":"JVM篇之垃圾回收器G1","date":"2020-12-31T02:10:36.000Z","updated":"2021-01-09T10:43:48.898Z","comments":true,"path":"2020/12/31/JVM篇之垃圾回收器G1/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/31/JVM篇之垃圾回收器G1/","excerpt":"","text":"背景G1（Garbage-First）是一款面向服务端应用的垃圾收集器，主要针对配备多核CPU及大容量内存的机器，以极高概率满足GC停顿时间的同时，还兼具高吞吐量的性质。 在JDK1.7版本正式启动，移除了Experimental的标识，是JDK9以后的默认垃圾回收器，取代了CMS回收器以及Parallel组合，被Oracle官方称为“全功能垃圾收集器”。 特点分代收集 从分代上看，G1依然属于分代型垃圾回收器，它会区分年轻代和老年代，年轻代依然有Eden区和Survivor区。从堆的结构上看，他不要求整个Eden区，Old区都是固定的，也不再坚持固定大小和固定数量。 将堆空间划分若干个区域，这些区域中包括了逻辑上年轻代和老年代。 空间整合 G1将内存划分为一个个的region，内存回收以region作为基本单位。Region之间是复制算法，但整体上实际可以看做标记-压缩算法。两种算法都可以避免内存碎片化。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。尤其当Java堆非常大时候，G1优势更加明显。 可预测模型 G1除了追求低停顿外，还能建立可预测模型的停顿时间，能让使用者明确规定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。 由于分区原因，G1可以只选取部分区域进行内存回收，这样缩小了回收的范畴，因此在全局停顿的情况下也能较好的控制 G1跟踪各个region里面的垃圾堆积的价值大小（回收所获得的空间大小和回收所需时间经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的region。保证了G1收集器在有限时间内可以获得尽可能高的收集效率。 分区Region使用G1收集器，它将整个java堆划分约2048个大小相同独立Region块，每个Region块大小根据堆空间的实际大小而定，整体被控制在1MB到32MB之间，且为2的N次幂，即1MB、2MB、4MB、8MB、16MB、32MB。可以通过-XX:C1HeapRegionSize设定，所有的Region大小相同，且在JVM生命周期内不会被改变。 一个region有可能属于Eden,Survivor或者Old内存区域。但一个region只能属于一个角色。 G1还增加一个新的内存区域，叫做Humongous内存区域，主要存储大对象。 设置H的原因 对于堆中的大对象，默认直接分配到老年代，但是如果它是一个短期存在的大对象，就会占用老年代内存。为了解决这个问题，G1划分了一个Humongous区，它用来专门存放大对象。如果一个H区装不下一个大对象，那么G1会寻找连续H区来存储。 垃圾回收过程G1垃圾回收主要包括以下3个环节 年轻代GC 老年代并发标记过程 混合回收 失败保护机制（Full GC） 总体概况 当年轻代的Eden区用尽时开始年轻代回收；G1暂停所有应用程序线程，启动多线程执行年轻代回收。年轻代区间存活对象移动到survivor区或者old；当堆内存使用达到一定值（默认45）时，开始老年代并发标记过程。标记完成马上开始混合回收过程。对于一个混合回收期，G1从老年代移动存活对象到空闲区，G1老年代回收不需要整个老年代被回收，一次只需要扫描/回收一小部分老年代的region即可。 Remembered Set 存在一个Region中的对象被其它任意Region对象引用，避免扫描整个java堆。 每个Region都有一个对应Remembered Set;记录其它对象对自己的引用。 常用的设置 -XX:+UseG1GC 手动指定使用G1收集器执行内存回收任务 -XX:G1HeapRegionSize 设置Region的大小，值是2的幂，范围是1MB到32MB之间，目标是根据最小堆可以划分约2048个区域，默认是堆内存的1/2000。 -XX:MaxGCPauseMillis 设置期望达到的最大GC停顿时间指标（JVM会尽力实现，但不能保证成功），默认值200ms -XX:ParallelGCThead 设置STW工作线程数的值，最多设置为8 -XX:ConcGCThreads 设置并发标记的线程数 -XX:InitiatingHeapOccupancyPercent 设置触发并发GC周期的Java堆占用率阈值，超过此值，就触发GC。默认值是45。 操作方法 开启G1垃圾收集器 设置堆最大内存 设置停顿时间 应用场景 面向服务端应用，针对具有大内存、多处理器的机器","categories":[{"name":"JVM","slug":"JVM","permalink":"https://jameslin23.gitee.io/categories/JVM/"}],"tags":[{"name":"垃圾回收器","slug":"垃圾回收器","permalink":"https://jameslin23.gitee.io/tags/垃圾回收器/"}]},{"title":"JVM篇之垃圾回收器CMS","slug":"JVM篇之垃圾回收器CMS","date":"2020-12-31T00:31:20.000Z","updated":"2021-01-09T10:43:15.249Z","comments":true,"path":"2020/12/31/JVM篇之垃圾回收器CMS/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/31/JVM篇之垃圾回收器CMS/","excerpt":"","text":"背景 在JDK 1.5时期，HotSpot推出一款在强交互应用中几乎认为有划时代意义的垃圾收集器：CMS(Concurrent-Mark-Sweep)收集器，这款收集器是HotSpot虚拟机中第一款真正意义上的并发收集器，他第一次实现了让垃圾收集线程与用户线程同时工作， CMS的关注点是尽可能缩短垃圾收集时用户线程的停顿时间。停顿时间越短（低延迟）就越适合与用户交互程序，良好的响应速度能提高用户体验。 工作原理CMS整个过程比之前收集器要复杂，整个过程分4个主要阶段，即初始标记阶段、并发标记阶段、重新标记阶段和并发清除阶段。 初始标记阶段：在这个阶段中，程序所有的工作线程都将会因为STW机制而出现短暂的暂停。这个阶段的主要任务仅仅只是标记处GC ROOTS能直接关联对象。一旦标记完成之后就会恢复之前被暂停的所有应用线程。由于直接关联对象比较少，速度很快。 并发标记阶段：从GC Roots的直接关联对象开始遍历整个对象图过程，这个过程耗时比较长，与用户线程一起并行执行。 重新标记：修正并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录。（STW） 并发清除：清除删除掉标记阶段判断已经死亡的对象，释放空间 示意图 尽管CMS收集器采用的是并发回收，但在其初始化标记和再次标记这两个阶段中仍然会出现STW，不过暂停时间不会太长，因此说明所有垃圾收集器都做不到完全不需要STW,只是尽可能地缩短暂停时间。 由于垃圾收集阶段用户没有线程中断，所以在CMS回收过程中，还应该确保应用程序用户线程有足够的内存可见。CMS收集器不能像其他收集器那样等到老年代几乎完全填满了再去收集，而是当堆内存使用率达到某一个阈值时，便开始回收。以确保应用程序在CMS工作过程中依然有足够的空间支持应用程序运行。要是CMS运行期间预留的内存无法满足程序需要，就出现一次”Concurrent Mode Failure”失败，这时虚拟机将启动后备预案：临时启用Serial Old收集器进行老年代的垃圾收集，这样停顿就会很长。 CMS的优点： 并发收集 低延迟 CMS的弊端 产生碎片化 对CPU资源非常敏感 无法处理浮动垃圾 参数设置-XX:+UseConcMarkSweepGC 手动指定使用CMS，收集器执行内存回收任务。开启该参数后会自动将-XX:+UseParNewGC打开，即ParNew+CMS+Serial Old组成 -XX:CMSlnitiatingOccupanyFraction 设置堆内存使用率的阈值，一旦到达阈值，即开始进行回收 JDK5以及以前版本默认为68，即当老年代的空间使用率达到68%时，会执行一次CMS回收，JDK6以上默认值92% 如果内存增长缓慢，则可以设置一个稍大的值，大的阈值可以有效降低CMS的触发频率，减少老年代回收的次数可以较为明显地改善应用程序性能。反之，如果应用程序内存使用增长率很快，则可以降低这个阈值，以避免触发Serial Old进行收集。 -XX:+UseCMSCompactAtFullCollection 用于指定在执行完Full GC后对内存空间进行压缩整理，以此避免内存碎片产生。不过由于内存压缩整理过程无法并行执行，带来问题停顿时间更长了。 -XX:CMSFullGSsBeforeCompaction 设置在执行多少次Full GC后对内存进行压缩整理。 -XX:ParallelCMSThreads 设置线程数量。 CMS默认启动线程数是（ParallelGCTheads+3）/4，ParallelGCTheads 是年轻代收集器线程数，当CPU资源比较紧张，受CMS收集器线程的影响，应用程序的性能在垃圾回收阶段可能会非常糟糕。 JDK后续版本中CMS的变化。 JDK9新特性：CMS被标记为Deprecate了（JEP291）,如果对JDK9及以上版本HotSpot虚拟机使用参数-XX:+UseConcMarkSweepGC来开启CMS收集器的话，用户会收到一个告警信息，提示CMS未来将会被废弃。 JDK14新特性：删除CMS垃圾回收器（JEP363）移除CMS垃圾回收器。如果在JDK14设置XX:+UseConcMarkSweepGC的话，JVM不会报错，只有给出一个warning信息，但是不会exit。JVM会自动回退默认GC方式启动JVM","categories":[{"name":"JVM","slug":"JVM","permalink":"https://jameslin23.gitee.io/categories/JVM/"}],"tags":[{"name":"垃圾回收器","slug":"垃圾回收器","permalink":"https://jameslin23.gitee.io/tags/垃圾回收器/"}]},{"title":"JVM篇之垃圾回收器Parallel","slug":"JVM篇之垃圾回收器Parallel","date":"2020-12-30T12:58:15.000Z","updated":"2021-01-09T10:41:45.166Z","comments":true,"path":"2020/12/30/JVM篇之垃圾回收器Parallel/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/30/JVM篇之垃圾回收器Parallel/","excerpt":"","text":"背景 图中展示了7种作用于不同分代的收集器，如果两个收集器相连，说明他们可以搭配使用。虚拟机所处区域表示它是属于新生代还是老年代收集器 新生代收集器：Serial、ParNew、Paraller Scavenge 老年代收集器：CMS、Serial Old、Parallel Old 整堆收集器：G1 Parallel Scavenge吞吐量优先的垃圾回收器，jdk1.8默认垃圾回收器 特点：属于新生代收集器，复制算法，并行的多线程收集器。 该收集器的目标是达到一个可控制的吞吐量，还有一个值得关注点：GC自适应调节策略 GC自适应调节策略：可设置-XX:+UseAdptiveSizePolicy参数，当开关打开时不需要手动指定新生代的大小（-xmn）、Eden与Surivor区的比例（-XX:SurvivorRation）、晋升老年代年龄（-XX：PretenureSizeThreshold）等。虚拟机会根据系统的运行状况收集性能监控信息，动态设置这些参数以提供最优的停顿时间和最高的吞吐量。 Parallel Scavenge收集器使用两个参数控制吞吐量： XX:MaxGCPauseMillis 控制最大垃圾收集停顿时间 XX:GCRatio 直接设置吞吐量大小 Parallel Old是Parallel Scavenge收集器的老年代版本 特点：多线程，采用标记-压缩算法 Ps/Po工作示意图","categories":[{"name":"JVM","slug":"JVM","permalink":"https://jameslin23.gitee.io/categories/JVM/"}],"tags":[{"name":"垃圾回收器","slug":"垃圾回收器","permalink":"https://jameslin23.gitee.io/tags/垃圾回收器/"}]},{"title":"JVM篇之垃圾回收器Serial","slug":"JVM篇之垃圾回收器Serial","date":"2020-12-30T12:21:10.000Z","updated":"2021-01-09T10:40:13.336Z","comments":true,"path":"2020/12/30/JVM篇之垃圾回收器Serial/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/30/JVM篇之垃圾回收器Serial/","excerpt":"","text":"背景 图中展示了7种作用于不同分代的收集器，如果两个收集器相连，说明他们可以搭配使用。虚拟机所处区域表示它是属于新生代还是老年代收集器 新生代收集器：Serial、ParNew、Paraller Scavenge 老年代收集器：CMS、Serial Old、Parallel Old 整堆收集器：G1 Serialserial收集器是最基本、发展历史最悠久的收集器。 特点：单线程、简单高效，对应当个CPU的环境，Serial收集器由于没有线程交互的开销，专心做垃圾回收自然获得最高单线程效率， 收集进行垃圾时，必须暂停其他所有的工作线程（Stop The World）,直到它结束。 运用场景：适用于Clinet模式下的虚拟机 Serial/Serial Old收集器运用图 Serial OldSerial Old是Serial收集器的老年代版本 特点：同样是单线程收集器，采用标记-压缩算法 应用场景：适用于Clinet模式下的虚拟机 在JDK1.5以及以前的版本中与Parallel Scavenge收集器搭配使用 作为CMS收集器的后备方案，在并发收集Concurent Mode Failure时使用 ParNewParNew收集器其实是Serial收集器的多线程版本。 除了使用多线程其余均行为均和Serial收集器一模一样（参数控制、收集算法、Stop the World、对象分配规则、回收策略） 特点：多线程、ParNew收集器默认开启的收集线程与CPU的数量相同，在CPU非常多的环境中，可以使用-XX:ParallelGCThreads参数来限制垃圾回收器的线程数。 应用场景：ParNew收集器是许多运行在Server模式下的虚拟机中首选新生代收集器，他经常与CMS搭配。 ParNew/Serial Old组合收集器示意图","categories":[{"name":"JVM","slug":"JVM","permalink":"https://jameslin23.gitee.io/categories/JVM/"}],"tags":[{"name":"垃圾回收器","slug":"垃圾回收器","permalink":"https://jameslin23.gitee.io/tags/垃圾回收器/"}]},{"title":"JVM篇之标记压缩算法","slug":"JVM篇之标记压缩算法","date":"2020-12-30T12:06:38.000Z","updated":"2021-01-03T05:35:36.199Z","comments":true,"path":"2020/12/30/JVM篇之标记压缩算法/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/30/JVM篇之标记压缩算法/","excerpt":"","text":"标记-压缩算法背景复制算法的高效是建立在存活对象少的、垃圾对象多的前提下。这种情况在新生代经常发生，但是在老年代，更常见的情况大部分对象都是存活对象，如果采用复制算法，由于存活对象多，复制成本也很高，因此老年代垃圾回收特征，需要使用其他算法。 执行过程 第一阶段和标记清除一样，从根节点开始标记所有被引用对象。 第二阶段将所有存活的对象压缩到内存的一段，按顺序排放。 之后清理边界外所有空间。 内存图示 缺点 从效率来看，标记-整理算法要低于复制算法 移动对象的同时，如果对象被其它对象引用，则需要调整引用地址 移动过程中需要全程暂停用户应用，即STW。","categories":[{"name":"JVM","slug":"JVM","permalink":"https://jameslin23.gitee.io/categories/JVM/"}],"tags":[{"name":"垃圾回收算法","slug":"垃圾回收算法","permalink":"https://jameslin23.gitee.io/tags/垃圾回收算法/"}]},{"title":"JVM篇之复制算法","slug":"JVM篇之复制算法","date":"2020-12-30T10:20:19.000Z","updated":"2020-12-30T12:06:42.661Z","comments":true,"path":"2020/12/30/JVM篇之复制算法/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/30/JVM篇之复制算法/","excerpt":"","text":"复制算法背景为了解决标记-清除算法在垃圾收集效率方面的缺陷，M.L.Minsky于1963年发表了著名的论文，“使用双存储区的Lisp语言垃圾收集器CA Lisp Garbage Collector Algorithm Using Serial Secondary Storage”。M.L.Minsky在论文中描述的算法被人们称为复制（Copying）算法，它也被M.L.Minsky本人成功的引入到了Lisp语言的一个实现版本中。 核心思想将活着的内存空间分为两块，每次只使用其中一块，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中的所有对象，交换两个内存的角色，最后完成垃圾回收。 内存图示 优点 高效，且不产生碎片化 缺点 耗内存，需要两倍内存空间 运用场景用于新生代，由于复制算法需要复制存活的对象到另外一边，所以新生代存活率并不高，所以适合使用新生代。","categories":[{"name":"JVM","slug":"JVM","permalink":"https://jameslin23.gitee.io/categories/JVM/"}],"tags":[{"name":"垃圾回收算法","slug":"垃圾回收算法","permalink":"https://jameslin23.gitee.io/tags/垃圾回收算法/"}]},{"title":"JVM篇之标记清除算法","slug":"JVM篇之标记清除算法","date":"2020-12-30T09:19:13.000Z","updated":"2020-12-30T10:20:33.915Z","comments":true,"path":"2020/12/30/JVM篇之标记清除算法/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/30/JVM篇之标记清除算法/","excerpt":"","text":"标记清除算法背景标记-清除算法（Mark-Sweep）是一种非常基础和常见的垃圾收集算法，该算法被J.McCarthy等人在1960年提出并应用于Lisp语言。 执行过程当堆中的有效内存空间（available memory）被耗尽的时候，就会停止整个程序（也被称为Stop The World），然后进行两项工作，第一项是标记，第二项则是清除。 标记：从引用根节点开始遍历，标记所有被引用对象。一般是在对象Header中记录为可达对象。 清除：对堆内内存从头到尾进行线性的遍历，如果发现某个对象在其Header中没有标记可达对象，则其将回收。 内存图示 缺点 内存碎片化严重 效率不高","categories":[{"name":"JVM","slug":"JVM","permalink":"https://jameslin23.gitee.io/categories/JVM/"}],"tags":[{"name":"垃圾回收算法","slug":"垃圾回收算法","permalink":"https://jameslin23.gitee.io/tags/垃圾回收算法/"}]},{"title":"Synchronized分析篇","slug":"Synchronized分析篇","date":"2020-12-28T12:24:22.000Z","updated":"2020-12-29T03:52:43.903Z","comments":true,"path":"2020/12/28/Synchronized分析篇/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/28/Synchronized分析篇/","excerpt":"","text":"Synchronizedsynchronized是java提供的原子性内置锁（存在对象头里面），这种内置的并且使用者看不到的锁也称为监视器锁，使用synchronized之后，会在编译之后的同步代码块前面加上monitorenter和monitorexit字节码指令，他依赖操作系统底层互斥锁实现。它的作用主要就是要实现原子性操作和解决共享变量的内存可见性。 执行monitorenter指令时会尝试获取对象锁，如果对象没有被锁或者已经获得锁，锁的计数器+1.此时其它竞争锁的线程则进入等待队列中。 执行monitorexit指令会把计数器-1，当计数器值为0时，则锁释放，处于等待队列中的线程再继续竞争。 synchronized是排它锁，当一个线程获得锁之后，其它线程必须等待该线程释放锁才能获得锁，而且由于java中的线程和操作系统原生线程是一一对应，线程被阻塞或者唤醒时会从用户态切换到内核态，非常消耗性能。 Synchronized实际有两个队列waitSet和entryList。 1234567ObjectMonitor() &#123; _count = 0; //记录个数 _owner = NULL; // 运行的线程 //两个队列 _WaitSet = NULL; //调用 wait 方法会被加入到_WaitSet _EntryList = NULL ; //锁竞争失败，会被加入到该列表 &#125;","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://jameslin23.gitee.io/categories/并发编程/"}],"tags":[{"name":"Synchronized","slug":"Synchronized","permalink":"https://jameslin23.gitee.io/tags/Synchronized/"}]},{"title":"AQS源码分析","slug":"AQS源码分析","date":"2020-12-28T08:26:22.000Z","updated":"2021-01-07T03:56:41.478Z","comments":true,"path":"2020/12/28/AQS源码分析/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/28/AQS源码分析/","excerpt":"","text":"AQS简单介绍AQS定义两种资源：Exclusive(独占，只有一个线程能执行，如果ReentranLock) 和 Share(共享，多个线程可同时执行，如Semaphore/CountDownLatch)。 不同的自定义同步器争用共享的方式也不同。自定义同步器实现时只需要实现共享资源state的获取和释放即可。至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了，自定义同步器实现主要实现以下几种方法： isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。 tryAcquire(int)：独占方式，尝试获取资源，成功则返回true,失败返回false。 tryRelease(int)：独占方式，尝试释放资源，成功则返回true,失败返回false。 tryAcquireShared(int)：共享方式，尝试获取资源，负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源 tryReleaseShared(int)：共享方式，尝试释放资源，如果释放后允许唤醒后续等待节点返回true,否则返回false 以ReentrantLock为例 state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占锁并将state+1。此后，其它线程再tryAcquire()时就会失败，直到A线程unlock()到state=0(即释放锁)为止，其它线程才有机会获取该锁。释放之前，A线程自己可以重复获取此锁（state会累积），这是锁重入概念，但是主要，获取多少次就要释放多少次，这样才能保证state是能回到零。 CountDownLatch为例 任务分为N个子线程去执行，state也初始化为N（N和线程数一直）。这N个线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS-1,等到所有子线程都执行后（既state=0）,会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。 一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。 源码分析Node节点Node节点是对每一个等待获取资源的线程封装，其包含了需要同步线程本身及其等待状态，如是否被阻塞、是否等待唤醒、是否被取消等。变量waitStatus则表示当前Node节点的等待状态，共有5种取值 CANCELLED(1)：表示当前节点已经取消调度。当timeout或者被中断（响应中断的情况下），会触发变更此状态，进入该状态后的节点将不会再变化。 SIGNAL(-1)：表示后继节点在等待前节点唤醒。后续节点入队时，会将前继节点的状态更新为SIGNAL。 CONDITION(-2)：表示节点等待在Condition上，当其他线程调用condition的signal()方法后，CODIOTION状态节点从等待队列转移同步队列 PROPAGATE(-3)：共享模式下，前继节点不仅会唤醒后继节点，同时也可能唤醒后继的后继节点。 0：新节点入队时默认状态。 负值表示节点处于有效等待状态，而正值表示结点已被取消。 独占方式获取锁acquire(int) 此方法是独占模式下线程共享资源的顶层入口。如果获取到资源，线程直接返回，否则进入等待队列，直到获取资源为止。 1234public final void acquire(int arg)&#123; if(!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE),arg)) selfInterrupt();&#125; 方法如下： tryAcquire()尝试直接获取资源，如果成功则直接返回（这里体现了非公平，每个线程获取锁时会直接抢占一次） addWaiter()将该线程加入等待队列的尾部，并标记为独占模式 acquireQueued()使得线程阻塞在等待队列中获取资源，一直获取到资源才返回。如果整个过程中被中断，则返回true,否则返回false 如果线程在等待队列中被中断过，他是不响应的，只有获取资源后才进行自我中断selfInterrupt()，将中断补上 addWaiter(Node) 此方法用于将当前线程加入等待队列的队尾，并返回当前线程所在的节点。 123456789101112131415161718//注意：该入队方法的返回值就是新创建的节点 private Node addWaiter(Node mode) &#123; //基于当前线程，节点类型（Node.EXCLUSIVE）创建新的节点 //由于这里是独占模式，因此节点类型就是Node.EXCLUSIVE Node node = new Node(Thread.currentThread(), mode); Node pred = tail; //这里为了提搞性能，首先执行一次快速入队操作，即直接尝试将新节点加入队尾 if (pred != null) &#123; node.prev = pred; //这里根据CAS的逻辑，即使并发操作也只能有一个线程成功并返回，其余的都要执行后面的入队操作。即enq()方法 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node; &#125; enq(node) 1234567891011121314151617181920//完整的入队操作 private Node enq(final Node node) &#123; //自旋，直到成功加入队列 for (;;) &#123; Node t = tail; //如果队列还没有初始化，则进行初始化，即创建一个空的头节点 if (t == null) &#123; // 队列为空，创建一个空的标志结点作为head结点，并将tail也指向它。 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; // //正常流程，放入队尾 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; //该循环体唯一退出的操作，就是入队成功（否则就要无限重试） return t; &#125; &#125; &#125; &#125; acquireQueued(Node,int) 通过tryAcquire()和addWaiter(),该线程获取资源失败，已经被放入队列尾部了。那线程下一步操作该干什么呢？ 进入等待状态休息，直到其它线程彻底释放资源后唤醒自己。acquireQueued类似跟医院排队拿号，在等待队列中排队拿号，中间没有其它事可以做，可以休息，直到拿到号在返回。 12345678910111213141516171819202122232425final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true;//标记是否成功拿到资源 try &#123; boolean interrupted = false;//标记等待过程中是否被中断过 //又是一个“自旋”！ for (;;) &#123; final Node p = node.predecessor();//拿到前驱 //如果前驱是head，即该结点已成老二，那么便有资格去尝试获取资源（可能是老大释放完资源唤醒自己的，当然也可能被interrupt了）。 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node);//拿到资源后，将head指向该结点。所以head所指的标杆结点，就是当前获取到资源的那个结点或null。 p.next = null; // setHead中node.prev已置为null，此处再将head.next置为null，就是为了方便GC回收以前的head结点。也就意味着之前拿完资源的结点出队了！ failed = false; // 成功获取资源 return interrupted;//返回等待过程中是否被中断过 &#125; // 其它就通过park()进入waiting状态，直到被unpark()。如果不可中断的情况下被中断了，那么会从park()中醒过来，发现拿不到资源，从而继续进入park()等待。 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true;//如果等待过程中被中断过，哪怕只有那么一次，就将interrupted标记为true &#125; &#125; finally &#123; if (failed) // 如果等待过程中没有成功获取资源（如timeout，或者可中断的情况下被中断了），那么取消结点在队列中的等待。 cancelAcquire(node); &#125;&#125; shouldParkAfterFailedAcquire（Node,Node） 此方法主要用于检查状态，看看自己是否可以被挂起 1234567891011121314151617181920private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus;//拿到前驱的状态 if (ws == Node.SIGNAL) //如果已经告诉前驱拿完号后通知自己一下，那就可以被挂起 return true; if (ws &gt; 0) &#123; /* * 如果前驱放弃了，那就一直往前找，直到找到最近一个正常等待的状态，并排在它的后边。 * 注意：那些放弃的结点，由于被自己“加塞”到它们前边，它们相当于形成一个无引用链，稍后就会被保安大叔赶走了(GC回收)！ */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; //如果前驱正常，那就把前驱的状态设置成SIGNAL，告诉它拿完号后通知自己一下。有可能失败，人家说不定刚刚释放完呢！ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 整个流程，如果前驱节点状态不是SIGNAL，那么自己不能安心去休息（挂起），需要遍历前驱节点，找到正常可以唤醒自己的前驱节点。 parkAndCheckInterrupt() 如果线程找到可以唤醒自己前驱节点，也就是前驱节点的状态时SIGNAL,就可以挂起 1234 private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this);//调用park()使线程进入waiting状态 return Thread.interrupted();//如果被唤醒，查看自己是不是被中断的。&#125; park()会让自己线程进入waiting状态，在此状态下，有两种途径可以唤醒该线程 unpark() interrupt() cancelAcquire(node) 12345678910111213141516171819202122232425262728293031323334353637383940//传入的方法参数是当前获取锁资源失败的节点private void cancelAcquire(Node node) &#123; // 如果节点不存在则直接忽略 if (node == null) return; node.thread = null; // 跳过所有已经取消的前置节点，跟上面的那段跳转逻辑类似 Node pred = node.prev; while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; //这个是前置节点的后继节点，由于上面可能的跳节点的操作，所以这里可不一定就是当前节点，仔细想一下。^_^ Node predNext = pred.next; //把当前节点waitStatus置为取消，这样别的节点在处理时就会跳过该节点 node.waitStatus = Node.CANCELLED; //如果当前是尾节点，则直接删除，即出队 //注：这里不用关心CAS失败，因为即使并发导致失败，该节点也已经被成功删除 if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123; int ws; if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) //这里的判断逻辑很绕，具体就是如果当前节点的前置节点不是头节点且它后面的节点等待它唤醒（waitStatus小于0）， //再加上如果当前节点的后继节点没有被取消就把前置节点跟后置节点进行连接，相当于删除了当前节点 compareAndSetNext(pred, predNext, next); &#125; else &#123; //进入这里，要么当前节点的前置节点是头结点，要么前置节点的waitStatus是PROPAGATE，直接唤醒当前节点的后继节点 unparkSuccessor(node); &#125; node.next = node; // help GC &#125; &#125; 总结：首先会先调用tryacquire()方法尝试获取锁，如果获取得到就直接返回，通过addwaiter()方法创建一个node节点，通过CAS加入队列尾部，会一直尝试，直到成功为止。加入成功的node节点就会执行acquireQueued方法，这个办法主要是判断线程前驱节点是不是头节点，并尝试去获取资源，如果符合条件就退出自旋，并返回。如果获取不到就会进入判断是否可以挂起线程，如果可以就执行lockSupport.park挂起该线程， 等待其它线程唤醒。 释放锁12345678910public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; // 0表示没有其它被唤醒的节点 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; 12345678910111213141516171819private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; if (ws &lt; 0) //把标记为设置为0，表示唤醒操作已经开始进行，提高并发环境下性能 compareAndSetWaitStatus(node, ws, 0); Node s = node.next; //如果当前节点的后继节点为null，或者已经被取消 if (s == null || s.waitStatus &gt; 0) &#123; s = null; //注意这个循环没有break，也就是说它是从后往前找，一直找到离当前节点最近的一个等待唤醒的节点 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; //执行唤醒操作 if (s != null) LockSupport.unpark(s.thread); &#125; 总结：先将状态设置为0，从后往前找，找到离当前节点最近的一个等待唤醒的节点，进行unpark。 共享方式获取锁acquireShared(int) 此方法是共享模式下线程获取共享资源的顶层入口。它会获取指定量的资源，获取成功则直接返回，获取失败则进入等待队列，直到获取到资源为止。 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; 这里tryAcquireShared()依然需要自定义同步器去实现。但是AQS已经把其返回值的语义定义好了：负值代表获取失败；0代表获取成功，但没有剩余资源；正数表示获取成功，还有剩余资源，其他线程还可以去获取。所以这里acquireShared()的流程就是： tryAcquireShared()尝试获取资源，成功则直接返回 失败则通过doAcquireShared()进入等待队列，直到获取到资源为止才返回 doAcquireShared(int) 此方法用于当前线程加入等待队列休息，直到其它线程释放资源唤醒自己，自己成功拿到相应量的资源后才返回。 1234567891011121314151617181920212223242526272829private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED);//加入队列尾部 boolean failed = true;//是否成功标志 try &#123; boolean interrupted = false;//等待过程中是否被中断过的标志 for (;;) &#123; final Node p = node.predecessor();//前驱 if (p == head) &#123;//如果到head的下一个，因为head是拿到资源的线程，此时node被唤醒，很可能是head用完资源来唤醒自己的 int r = tryAcquireShared(arg);//尝试获取资源 if (r &gt;= 0) &#123;//成功 setHeadAndPropagate(node, r);//将head指向自己，还有剩余资源可以再唤醒之后的线程 p.next = null; // help GC if (interrupted)//如果等待过程中被打断过，此时将中断补上。 selfInterrupt(); failed = false; return; &#125; &#125; //判断状态，寻找安全点，进入waiting状态，等着被unpark()或interrupt() if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; setHeadAndPropagate(node, r) 12345678910private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; setHead(node);//head指向自己 //如果还有剩余量，继续唤醒下一个邻居线程 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 总结：首先tryAcquireShared去获取锁，如果返回值小于0说明没有剩余资源，进入同步队列。拿到队列的第二个节点去尝试获取资源。成功就将自己设置头节点，判断是否有资源继续唤醒后继节点 释放锁releaseShared() 此方法是共享模式下线程释放共享资源的顶层入口，它会释放指定量的资源，如果成功释放且允许唤醒等待线程，它会唤醒等待队列里的其它线程来获取资源 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123;//尝试释放资源 doReleaseShared();//唤醒后继结点 return true; &#125; return false;&#125; doReleaseShared() 123456789101112131415161718private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; unparkSuccessor(h);//唤醒后继 &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; &#125; if (h == head)// head发生变化 break; &#125;&#125; 总结：释放资源，唤醒后继","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://jameslin23.gitee.io/categories/并发编程/"}],"tags":[{"name":"AQS","slug":"AQS","permalink":"https://jameslin23.gitee.io/tags/AQS/"}]},{"title":"AQS原理分析","slug":"AQS原理分析","date":"2020-12-27T07:17:02.000Z","updated":"2021-01-09T10:36:52.118Z","comments":true,"path":"2020/12/27/AQS原理分析/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/27/AQS原理分析/","excerpt":"","text":"AQS概述AQS(Abstract Queued Synchronizer) 抽象队列同步器，定义了一套多线程访问共享资源的同步框架，许多同步类实现都依赖与它，常用ReentrantLock/Semaphoe/CountDownLatch 由一个资源状态int state和同步器（FIFO双向阻塞队列组成） 同步器同步器依赖内部的同步队列（FIFO）来完成同步状态的管理，当前线程获取同步状态失败时，同步器会使用CAS将当前线程以及等待状态等信息构造成一个节点Node并将其加入同步队列尾部，同时会阻塞当前线程，当同步状态释放时，会把首节点的线程唤醒，并其再尝试获取同步状态。 同步队列的节点Node用来保存获取同步状态失败的线程引用、等待状态以及前驱和后继节点。 同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后续节点，而后续节点将会在获取同步状态成功时将自己设置为首节点。 注：由于获取成功状态的线程只有一个，所有设置首节点不需要使用cas，而插入尾部竞争的线程有很多个，所以需要使用CAS。 独占式同步器的acquire方法 1234public final void acquire(int arg)&#123; if(!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE),arg)) selfInterrupt;&#125; 上述代码主要完成同步锁状态获取、节点构造、加入同步队列以及在同步队列中自旋等待相关工作。 其主要逻辑是：首先调用自定义同步器实现的tryAcquire(int arg)方法，该方法保证线程安全的获取同步状态，如果同步状态获取失败，则构造同步节点并通过addWaiter(Node node)方法将节点加入到同步队列的尾部,最后调用acquireQueued(Node node,int arg)方法，使得该节点以“死循环”的方式获取同步状态。如果获取不到则阻塞节点的线程，而被阻塞线程的唤醒主要依靠前驱节点的出队或者阻塞线程中断来实现。 当前线程在“死循环”中获取同步状态，而只有前驱节点是头节点才能尝试获取同步状态，这个为什么？ 头节点是成功获取到同步状态的节点，而头节点的线程释放了同步状态之后，将会唤醒其后继节点，后继节点的线程被唤醒后需要检查自己的前驱节点是否是头节点。 维护同步队列的FIFO原则 总结：在获取同步状态时，同步器维护一个同步队列，获取状态失败的线程通过CAS加入到队列尾部并在队列中；移除队列的条件是前驱节点为头节点且成功获取了同步状态。在释放同步状态时，同步器调用tryRelease(int arg)方法释放同步状态。然后唤醒头节点后继节点。 共享式共享式获取与独占式获取最主要的区别是在与同一个时刻能有多个线程获取同步状态 在acquireShared(int arg)方法中，同步器调用tryAcquireShared(int arg)方法尝试获取同步状态，tryAcquireShared(int arg)方法返回值为int类型，当返回值大于等于0时，表示能够获取到同步状态。因此，在共享式获取的自旋过程中，成功获取到同步状态并退出自旋的条件就是tryAcquireShared(int arg)方法返回值大于等于0。可以看到，在doAcquireShared(int arg)方法的自旋过程中，如果当前节点的前驱为头节点时，尝试获取同步状态，如果返回值大于等于0，表示该次获取同步状态成功并从自旋过程中退出。 与独占式一样，共享式获取也需要释放同步状态，通过调用releaseShared(int arg)方法可以释放同步状态 1234567public final boolean releaseShard(int arg)&#123; if(tryReleaseShard(arg))&#123; doReleaseShared(); return true; &#125; reture false;&#125; 该方法在释放同步状态之后，将会唤醒后续处于等待状态的节点。对于能够支持多个线程同时访问的并发组件（比如Semaphore），它和独占式主要区别在于tryReleaseShared(int arg)方法必须确保同步状态（或者资源数）线程安全释放，一般是通过循环和CAS来保证的，因为释放同步状态的操作会同时来自多个线程。 Condition接口任意一个java对象，都拥有一组监视器方法（定义在object上）,主要包括wait()、wait(long timeout)、notify()以及notifyAll()方法，这些方法与Synchronized同步关键字配合,可以实现等待/通知。condition接口也提供了类似Object的监听器方法，与Lock配合可以实现等待/通知模式。 Object的监听器方法与Condition接口的对比 对比项 Object Condition 前置条件 获取对象锁 调用Lock.lock()获取对象锁，调用Lock.newCondition()获取Condition对象 调用方式 直接调用 直接调用，例如condition.await() 等待队列个数 一个 多个 当前线程释放锁进入等待状态 支持 支持 当前线程释放锁并进入等待状态，在等待状态中不响应中断 不支持 支持 当前线程释放锁并进入超时等待状态 支持 支持 当前线程释放锁并进入等待状态到将来的某个时间 不支持 支持 唤醒等待队列中一个线程 支持 支持 唤醒等待队列中全部线程 支持 支持 实现分析ConditionObject是同步器AQS的内部类，因为Condition的操作需要相关联的锁，所以作为同步器的内部类也比较合理。每个condition对象都包含一个队列，该队列是Condition对象实现等待/通知功能的关键。 等待队列 等待队列是一个FIFO的队列，在队列中每个节点都包含一个线程引用，该线程就是在condition对象等待的线程，如果一个线程调用了condition.await()方法，那么该线程将会释放锁，构造成节点加入等待队列并进行等待中。实际上，节点的定义复用了同步器中节点的定义，也就是说，同步队列和等待队列中节点类型都是同步器静态内部类 一个Condition包含一个等待队列，Condition拥有首节点firstWaiter和尾节点lastWaiter。当前线程调用Condtion.await()方法，将会以当前线程构造节点，并将节点从尾部加入等待队列，等待队列基本构造 Condition拥有首尾节点的引用，而新增节点只需要将原有的尾节点nextWaiter指向它，并且更新尾节点即可。更新的过程并没有使用CAS保证，原因在于调用await()方法的线程必定获取了锁的线程，也就是该过程是由锁来保证线程安全的。 在Object的监视器模式上，一个对象拥有一个同步队列和等待队列 在Lock拥有一个同步队列和多个等待队列。 Condition的实现是同步器的内部类，因此每个condition实例都能够访问同步器提供的方法，相当于每个condition都拥有所属同步器的引用。 等待从队列（同步队列和等待队列）的角度看await()方法，当调用await()方法时，想当于同步队列的首节点（获取锁的节点）移动到Condition的等待队列中。 ConditionObject的await方法 1234567891011121314151617181920public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); // 当前线程加入等待队列 Node node = addConditionWaiter(); // 释放同步状态，也就是释放锁 int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode);&#125; 调用该方法的线程成功获取了锁的线程，也就是同步队里的首节点，该方法会将当前线程构造节点并加入等到队里中，然后释放同步状态，唤醒同步队列中的后继节点，然后当前线程会进入等待状态 当等待队列中的节点被唤醒，则唤醒节点的线程开始尝试获取同步状态。如果不是通过其他线程调用Condition.signal()方法唤醒，而是对等待线程进行中断，则会抛出InterruptedException。 通知调用condition的signal()方法，将会在唤醒等待队列中等待时间最长的节点（首节点），在唤醒之前，将节点移到同步队列。 ConditionObject的signal方法 1234567public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first);&#125; 调用该方法的前置条件是当前线程必须获取锁，可以看到signal()进行了isHeldExclusively()检查，也就是当前线程必须获取了锁的线程，接着获取等待队列的首节点，将其移动到同步队列并使用LockSupport唤醒节点中的线程。 通过调用同步器的enq(Node node)方法，等待队列中节点线程安全地移动到同步队列。当节点移动到同步队列后，当前线程再使用LockSupport唤醒该节点的线程。 被唤醒的线程，将从await()方法中的while循环中退出，进而调用同步器的acquireQueued()方法加入获取同步状态的竞争中。 Condition的signalAll()方法，相当于对等待队列中的每个节点均执行一次signal()方法，效果就是将等待队列中所有节点全部移动到同步队列中，并唤醒每个节点的线程。","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://jameslin23.gitee.io/categories/并发编程/"}],"tags":[{"name":"AQS","slug":"AQS","permalink":"https://jameslin23.gitee.io/tags/AQS/"}]},{"title":"ArrayList源码分析","slug":"ArrayList源码分析","date":"2020-12-26T06:07:16.000Z","updated":"2020-12-27T13:38:11.495Z","comments":true,"path":"2020/12/26/ArrayList源码分析/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/26/ArrayList源码分析/","excerpt":"","text":"属性123456789101112131415161718192021222324252627282930313233343536// 序列化版本UIDprivate static final long serialVersionUID = 8683452581122892189L;/** * 默认的初始容量 */private static final int DEFAULT_CAPACITY = 10;/** * 用于空实例的共享空数组实例 * new ArrayList(0); */private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;/** * 用于提供默认大小的实例的共享空数组实例 * new ArrayList(); */private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;/** * 存储ArrayList元素的数组缓冲区 * ArrayList的容量，是数组的长度 * * non-private to simplify nested class access */transient Object[] elementData;/** * ArrayList中元素的数量 */private int size; 构造方法 无参构造方法 12345678/** * 无参构造方法 将elementData 赋值为 * DEFAULTCAPACITY_EMPTY_ELEMENTDATA */public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 带初始容量构造方法 123456789101112131415161718/** * 带一个初始容量参数的构造方法 * * @param initialCapacity 初始容量 * @throws 如果初始容量非法就抛出 * IllegalArgumentException */public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException( \"Illegal Capacity: \"+ initialCapacity); &#125;&#125; 带一个集合参数的构造方法 123456789101112131415161718192021/** * 带一个集合参数的构造方法 * * @param c 集合，代表集合中的元素会被放到list中 * @throws 如果集合为空，抛出NullPointerException */public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); // 如果 size != 0 if ((size = elementData.length) != 0) &#123; // c.toArray 可能不正确的，不返回 Object[] // https://bugs.openjdk.java.net/browse/JDK-6260652 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf( elementData, size, Object[].class); &#125; else &#123; // size == 0 // 将EMPTY_ELEMENTDATA 赋值给 elementData this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; 扩容分析这里以无参构造函数创建的 ArrayList 为例分析： add方法 12345678910/** * 将指定的元素追加到此列表的末尾。 */ public boolean add(E e) &#123; //添加元素之前，先调用ensureCapacityInternal方法 ensureCapacityInternal(size + 1); // Increments modCount!! //这里看到ArrayList添加元素的实质就相当于为数组赋值 elementData[size++] = e; return true; &#125; ensureCapacityInternal方法 1234567891011private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity)); &#125; private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; // DEFAULT_CAPACITY=10, if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity; &#125; 由代码可知道，当add进第一个元素时，mincapacity是1，Math.max方法比较后，返回最大值是10 ensureExplicitCapacity方法 12345678 private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // 判断是否扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity); &#125; 我们来仔细分析一下： 当add进第一个元素到ArrayList时，elementData.length为0(因为第一个空的list),因为执行了ensureCapacityInternal()方法，所以minCapacity此时为10，此时minCapacity - elementData.length &gt; 0 成立，所以会进入 grow(minCapacity) 方法。 当add第2个元素时，minCapacity 为2，此时e lementData.length(容量)在添加第一个元素后扩容成 10 了。此时，minCapacity - elementData.length &gt; 0 不成立，所以不会进入 （执行）grow(minCapacity) 方法。 添加第3、4···到第10个元素时，依然不会执行grow方法，数组容量都为10。 直到添加第11个元素，minCapacity(为11)比elementData.length（为10）要大。进入grow方法进行扩容。 grow()方法 1234567891011121314151617181920212223private void grow(int minCapacity) &#123; // overflow-conscious code // oldCapacity为旧容量，newCapacity为新容量 int oldCapacity = elementData.length; // 将oldCapacity 右移一位，其效果相当于oldCapacity /2 // 我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍， int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量， if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125; // 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) `hugeCapacity()` 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，19 //如果minCapacity大于最大容量，则新容量则为`Integer.MAX_VALUE`，否则，新容量大小则为 MAX_ARRAY_SIZE MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8。private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; 总结ArrayList是属于动态扩容，当你未指定容量大小时，默认容量是10，每次add时候会判断当前长度+1-容量大小是否大于0。如果是，就会进行扩容，扩容新容量=旧容量+旧容量右移1位，也就是原来的1.5倍左右，此时会进行2个大小判断，一个判断是否小于最小容量，如果小于就取最小容量为新的容量，再次判断新容量是否&gt;inter.max.value-8,大于新的容量取integer.max.value。 本质就是计算出新的容量实例化数组，将原有的数组内容复制到新的数组去。","categories":[{"name":"java基础","slug":"java基础","permalink":"https://jameslin23.gitee.io/categories/java基础/"}],"tags":[{"name":"java集合","slug":"java集合","permalink":"https://jameslin23.gitee.io/tags/java集合/"}]},{"title":"java基础面试篇","slug":"java基础面试篇","date":"2020-12-26T01:31:02.000Z","updated":"2020-12-26T01:34:28.791Z","comments":true,"path":"2020/12/26/java基础面试篇/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/26/java基础面试篇/","excerpt":"","text":"","categories":[{"name":"面试专题","slug":"面试专题","permalink":"https://jameslin23.gitee.io/categories/面试专题/"}],"tags":[{"name":"java","slug":"java","permalink":"https://jameslin23.gitee.io/tags/java/"}]},{"title":"gateway","slug":"gateway","date":"2020-12-25T07:54:18.000Z","updated":"2020-12-25T09:21:37.395Z","comments":true,"path":"2020/12/25/gateway/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/25/gateway/","excerpt":"","text":"","categories":[{"name":"springCloud","slug":"springCloud","permalink":"https://jameslin23.gitee.io/categories/springCloud/"}],"tags":[{"name":"服务网关","slug":"服务网关","permalink":"https://jameslin23.gitee.io/tags/服务网关/"}]},{"title":"Hystrix","slug":"Hystrix","date":"2020-12-25T02:43:36.000Z","updated":"2020-12-25T06:36:02.112Z","comments":true,"path":"2020/12/25/Hystrix/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/25/Hystrix/","excerpt":"","text":"概述Hystrix是一个用于分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时，异常等。Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障。以提高分布式系统的弹性。 “断路器”本身是在一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控(类似熔断保险丝)，像调用方返回一个符合预期的，可处理的备选响应（FallBack）,而不是长时间的等待或者抛出调用方无法处理异常。避免服务调用方的线程不会被长时间，不必要的占用，从而避免故障在分布式系统中蔓延，乃至雪崩。 服务降级服务器忙，请稍后再试，不让客户等待并立刻返回一个友好提示，fallback。 以下情况会触发降级 程序运行异常 超时 服务熔断触发服务降级 线程池/信号量打满 Demo 服务A–当有很多个客户端请求时，该服务接口被困死，因为tomcat线程里面的工作线程已经被挤占完毕 服务B–调用A服务客户端访问响应缓慢，转圈圈 A服务限流配置@HystrixCommand 1234567891011121314151617// 失败 @HystrixCommand(fallbackMethod = \"paymentInfo_TimeOutHandler\",commandProperties = &#123; @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\",value = \"3000\") &#125;) public String paymentInfo_TimeOut(Integer id)&#123; int timeNumber = 3; try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return \"线程池：\"+Thread.currentThread().getName()+\" paymentInfo_TimeOut,id： \"+id+\"\\t\"+\"呜呜呜\"+\" 耗时(秒)\"+timeNumber; &#125; //兜底方法 public String paymentInfo_TimeOutHandler(Integer id)&#123; return \"线程池：\"+Thread.currentThread().getName()+\" 系统繁忙, 请稍候再试 ,id： \"+id+\"\\t\"+\"哭了哇呜\"; &#125; 启动配置增加注解@EnableCircuitBreaker 12345678@SpringBootApplication@EnableEurekaClient@EnableCircuitBreakerpublic class PaymentHystrixMain8001 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentHystrixMain8001.class,args); &#125;&#125; B服务设置服务降级 12345678910111213@GetMapping(\"/consumer/payment/hystrix/timeout/&#123;id&#125;\")@HystrixCommand(fallbackMethod = \"paymentTimeOutFallbackMethod\",commandProperties = &#123;@HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\",value = \"1500\") //3秒钟以内就是正常的业务逻辑&#125;)public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id)&#123;String result = paymentHystrixService.paymentInfo_TimeOut(id);return result;&#125;//兜底方法public String paymentTimeOutFallbackMethod(@PathVariable(\"id\") Integer id)&#123;return \"我是消费者80，对付支付系统繁忙请10秒钟后再试或者自己运行出错请检查自己,(┬＿┬)\";&#125; 主启动类 12345678@SpringBootApplication@EnableFeignClients@EnableHystrixpublic class PaymentHystrixMain80 &#123; public static void main(String[] args) &#123; SpringApplication.run(PaymentHystrixMain80.class,args); &#125;&#125; 存在问题 每个controller配置一个 和业务逻辑混合在一起 解决方案 重新新建一个类（PaymentFallbackService）实现该接口，统一为feign接口里面的方法进行异常处理 123456789101112@Servicepublic class PaymentFallbackService implements PaymentHystrixService &#123; @Override public String paymentInfo_OK(Integer id) &#123; return \"-----PaymentFallbackService fall back-paymentInfo_OK , (┬＿┬)\"; &#125; @Override public String paymentInfo_TimeOut(Integer id) &#123; return \"-----PaymentFallbackService fall back-paymentInfo_TimeOut , (┬＿┬)\"; &#125;&#125; feign接口 123456789@Service//,fallback = PaymentFallbackService.class@FeignClient(value = \"CLOUD-PROVIDER-HYSTRIX-PAYMENT\",fallback = PaymentFallbackService.class)public interface PaymentHystrixService &#123; @GetMapping(\"/payment/hystrix/ok/&#123;id&#125;\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id); @GetMapping(\"/payment/hystrix/timeout/&#123;id&#125;\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id);&#125; yml配置 123feign: hystrix: enabled: true #如果处理自身的容错就开启。开启方式与生产端不一样。 服务熔断类比保险丝达到最大服务访问后，直接拒绝访问，拉闸限电，然后调用服务降级的方法并返回友好提示 熔断机制 熔断机制是应对雪崩的一种微服务链路保护机制。当某个服务出错不可用或者响应时间太长了时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回错误的响应信息。 当检测到该节点微服务调用响应正常后，恢复链路调用 在spring cloud框架中，熔断机制通过Hystrix实现，Hystrix会监控微服务调用的状况，当失败的调用到一定阈值，缺省5秒内20调用失败，就会启动熔断机制。 服务层配置 123456789101112131415161718//服务熔断@HystrixCommand(fallbackMethod = \"paymentCircuitBreaker_fallback\",commandProperties = &#123;@HystrixProperty(name = \"circuitBreaker.enabled\",value = \"true\"), //是否开启断路器@HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\",value = \"10\"), //请求次数@HystrixProperty(name = \"circuitBreaker.sleepWindowInMilliseconds\",value = \"10000\"), //时间范围@HystrixProperty(name = \"circuitBreaker.errorThresholdPercentage\",value = \"60\"), //失败率达到多少后跳闸&#125;)public String paymentCircuitBreaker(@PathVariable(\"id\") Integer id)&#123;if (id 0)&#123;throw new RuntimeException(\"*****id 不能负数\"); &#125;String serialNumber = IdUtil.simpleUUID();return Thread.currentThread().getName()+\"\\t\"+\"调用成功,流水号：\"+serialNumber;&#125;public String paymentCircuitBreaker_fallback(@PathVariable(\"id\") Integer id)&#123;return \"id 不能负数，请稍候再试,(┬＿┬)/~~ id: \" +id;&#125; 熔断状态 熔断打开 熔断关闭 熔断半开 服务限流秒杀高并发等操作，严禁一窝蜂的过来拥挤，大家排队，一秒钟N个，有序进行 服务监控hystrixDashboard","categories":[{"name":"springCloud","slug":"springCloud","permalink":"https://jameslin23.gitee.io/categories/springCloud/"}],"tags":[{"name":"服务降级","slug":"服务降级","permalink":"https://jameslin23.gitee.io/tags/服务降级/"}]},{"title":"OpenFeign","slug":"OpenFeign","date":"2020-12-25T01:42:40.000Z","updated":"2020-12-25T02:43:50.736Z","comments":true,"path":"2020/12/25/OpenFeign/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/25/OpenFeign/","excerpt":"","text":"概述FeignFeign是一个声明式的web服务客户端，让编写web服务客户端变得非常容易，只需要创建一个接口并在接口上添加注解即可 Feign使得Java Http客户端变得更容易。Ribbon+RestTemplate时，利用RestTemplate对http请求的封装处理，形成了一套模板化的调用方法。但实际开发的调用可能不止一处。往往一个接口会被多处调用，所以通常都会针对每个微服务自行封装一些客户端类来包装。Feign在基础上做了进一步封装。由他来帮助我们定义和实现依赖服务接口的定义。在Feign的实现下，我们只需要创建一个接口并使用注解的方式来配置它，即可完成对服务提供方 的接口绑定，简化了使用Ribbon,自动封装服务调用客户端的开发量。 Feign &amp; OpenFeign Feign是Springcloud组件中的一个轻量级Restful的HTTP服务客户端，Feign内置了Ribbon，用来做客户端负载均衡，去调用服务注册中心的服务。Feign的使用方式是：使用Feign的注解定义接口，调用这个接口，就可以调用服务注册中心的服务 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&lt;/dependency&gt; OpenFeign是springcloud在Feign的基础上支持了SpringMVC的注解，如@RequestMapping等等。OpenFeign的@FeignClient可以解析SpringMVC的@RequestMapping注解下的接口，并通过动态代理的方式产生实现类，实现类中做负载均衡并调用其他服务。 1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 配置Feign接口实现 12345678910@FeignClient(value=\"content\") // 服务名@RequestMapping(\"/content\")public interface ContentFeign &#123; /*** * 根据分类ID查询所有广告 */ @GetMapping(value = \"/list/category/&#123;id&#125;\") Result&lt;List&lt;Content&gt;&gt; findByCategory(@PathVariable(name = \"id\") Long id);&#125; 启动类扫描对应接口包 1@EnableFeignClients(basePackages= &#123;\"com.haigou.content.feign\"&#125;) 超时控制OpenFeign默认等待一秒钟，超时后报错 可以在YML文件开启OpenFeign客户端超时控制 123ribbon: ReadTimeout: 5000 ConnectTimeout: 5000 日志打印Feign提供了日志打印功能，对Feign接口调用情况进行控制和输出。 配置Bean 123456789101112import feign.Logger;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class FeignConfig &#123;@BeanLogger.Level feignLoggerLevel()&#123;return Logger.Level.FULL; &#125;&#125; yml文件开启(xxx对应feign接口路径) 123logging: level: xxx.xxx: debug","categories":[{"name":"springCloud","slug":"springCloud","permalink":"https://jameslin23.gitee.io/categories/springCloud/"}],"tags":[{"name":"服务调用","slug":"服务调用","permalink":"https://jameslin23.gitee.io/tags/服务调用/"}]},{"title":"Ribbon","slug":"Ribbon","date":"2020-12-25T00:30:48.000Z","updated":"2020-12-25T01:43:33.233Z","comments":true,"path":"2020/12/25/Ribbon/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/25/Ribbon/","excerpt":"","text":"概述是什么？SpringCloud Ribbon是基于Netflix Ribbon实现的一套客户端负载均衡的工具。是Netflix发布开源项目，主要功能提供客户端的软件负载均衡和服务调用。Ribbon客户端组件提供一系列完善的配置项如连接超时，重试等。就是在配置文件中列出Load Balancer(Lb)后面的所有机器，Ribbon会自动的帮助你基于某种规则(如简单轮询，随机连接等)去连接这些机器。我们很容易使用Ribbon实现自定义的负载均衡算法。 LB（负载均衡）简单的来说就是将用户的请求平摊的分配到多个服务上,从而达到系统的HA(高可用)。常见的负载均衡有Nginx,LVS,硬件F5等。 Ribbon本地负载均衡客户端 VS Nginx服务端负载均衡区别 Nginx是服务器负载均衡，客户端所有请求都会交给Nginx,然后由nginx实现转发请求。负载均衡由服务实现的。 Ribbon本地负载均衡，在调用微服务接口时，会在注册中心上获取信息服务列表之后缓存到JVM,从而在本地实现RPC远程服务调用。 总结：负载均衡+RestTemplate调用 Ribbon在工作时分两步 先选择EurekaServer,他优先选择在同一个区域内负载比较少的server 再根据用户指定的策略，在从server取到服务注册列表中选择一个地址。其中Ribbon提供了多种策略: 比如轮询、随机和根据响应时间加权。 简单demo 核心代码 123456789@Configurationpublic class ApplicationContextConfig &#123; @Bean @LoadBalanced //赋予RestTemplate负载均衡的能力 public RestTemplate getRestTemplate()&#123; return new RestTemplate(); &#125;&#125; 1234567891011121314@RestController@Slf4jpublic class OrderController &#123; public static final String PAYMENT_URL = \"http://CLOUD-PAYMENT-SERVICE\"; @Resource private RestTemplate restTemplate; @GetMapping(\"/consumer/payment/get/&#123;id&#125;\") public CommonResult&lt;Payment&gt; getPayment(@PathVariable(\"id\") Long id)&#123; return restTemplate.getForObject(PAYMENT_URL+\"/payment/get/\"+id,CommonResult.class); &#125;&#125; 核心组件IRuleIRule根据特定算法从服务列表中选取要访问的服务 RoundRobinRule ：轮询 RandomRule ：随机 RetryRule ：先轮询策略获取服务，如果获取指定失败则在指定时间内进行重试 weightedResponseTimeRule： 对RoundRobinRule的扩展，响应速度越快实例选择权越大，越容易被选择 BestAvailableRule ：先会过滤掉由于多次访问故障而处于断路器跳闸状态的服务然后选择一个并大量最小的服务 AvailabilityFilteringRule：先过滤掉故障实例，在选择并发最小的实例 ZoneAvoidanceRule：默认规则，复合判断server所在区域的性能和server的可用性选择器 使用配置细节 自定义配置类不能放在@componentScan所扫描的当前包下以及子包下，否则我们自定义的配置类就会被所有Ribbon客户端所共享，达不到特殊化定制目的。 1234567@Configurationpublic class MySelfRule &#123; @Bean public IRule myRule()&#123; return new RandomRule();// 随机 &#125;&#125; 启动类配置 123456789@EnableEurekaClient@SpringBootApplication@RibbonClient(name = \"CLOUD-PAYMENT-SERVICE\",configuration = MySelfRule.class)public class OrderMain80 &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderMain80.class,args); &#125;&#125; 由于Ribbon目前也进入维护模式，但是生产还是有大规模的使用，还是需要学习一下。","categories":[{"name":"springCloud","slug":"springCloud","permalink":"https://jameslin23.gitee.io/categories/springCloud/"}],"tags":[{"name":"服务调用","slug":"服务调用","permalink":"https://jameslin23.gitee.io/tags/服务调用/"}]},{"title":"OpenResty","slug":"OpenResty","date":"2020-12-24T00:16:32.000Z","updated":"2020-12-24T00:44:33.460Z","comments":true,"path":"2020/12/24/OpenResty/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/24/OpenResty/","excerpt":"","text":"OpenResty介绍OpenResty(又称：ngx_openresty) 是一个基于 nginx的可伸缩的 Web 平台，由中国人章亦春发起，提供了很多高质量的第三方模块。 OpenResty 是一个强大的 Web 应用服务器，Web 开发人员可以使用 Lua 脚本语言调动 Nginx 支持的各种 C 以及 Lua 模块,更主要的是在性能方面，OpenResty可以 快速构造出足以胜任 10K 以上并发连接响应的超高性能 Web 应用系统。 360，UPYUN，阿里云，新浪，腾讯网，去哪儿网，酷狗音乐等都是 OpenResty 的深度用户。 OpenResty 简单理解成 就相当于封装了nginx,并且集成了LUA脚本，开发人员只需要简单的其提供了模块就可以实现相关的逻辑，而不再像之前，还需要在nginx中自己编写lua的脚本，再进行调用了。 安装OpenRestylinux 安装openresty 添加仓库执行命令 yum install yum-utils yum-config-manager –add-repo https://openresty.org/package/centos/openresty.repo 执行安装 yum install openresty 安装默认路径 /usr/local/openresty 安装nginx默认已经安装好了nginx,在目录: /usr/local/openresty/nginx 修改/usr/local/openresty/nginx/conf/nginx.conf,将配置文件使用的根设置为root,目的就是将来要使用lua脚本的时候 ，直接可以加载在root下的lua脚本。 cd /usr/local/openresty/nginx/confvi nginx.conf 测试访问输入网页访问 nginx+lua缓存如下思路: 首先访问nginx，先获取本地缓存，获取到直接响应 没有获取到，再访问redis，我们可以从redis获取数据，如果有则返回响应，并且缓存到nginx中 如果没有获取到，再次访问MySQL，我们从MySQL中获取数据，再将数据存储到redis中，返回 而在这里面，我们都可以使用LUA脚本嵌入到程序中执行这些查询相关的业务。 nginx增加缓存命名空间 lua_shared_dict dis_cache 128m nginx访问调用lua脚本 123location /read_content &#123; content_by_lua_file /root/lua/read_content.lua;&#125; 编辑lua脚本 read_content.lua 123456789101112131415161718192021222324252627282930313233343536373839404142ngx.header.content_type=\"application/json;charset=utf8\"local uri_args = ngx.req.get_uri_args();local id = uri_args[\"id\"];--获取本地缓存local cache_ngx = ngx.shared.dis_cache;--根据ID 获取本地缓存数据local contentCache = cache_ngx:get('content_cache_'..id);if contentCache == \"\" or contentCache == nil then local redis = require(\"resty.redis\"); local red = redis:new() red:set_timeout(2000) red:connect(\"192.168.10.132\", 6379) local rescontent=red:get(\"content_\"..id); if ngx.null == rescontent then local cjson = require(\"cjson\"); local mysql = require(\"resty.mysql\"); local db = mysql:new(); db:set_timeout(2000) local props = &#123; host = \"192.168.10.132\", port = 3306, database = \"changgou_content\", user = \"root\", password = \"123456\" &#125; local res = db:connect(props); local select_sql = \"select url,pic from tb_content where status ='1' and category_id=\"..id..\" order by sort_order\"; res = db:query(select_sql); local responsejson = cjson.encode(res); red:set(\"content_\"..id,responsejson); ngx.say(responsejson); db:close() else cache_ngx:set('content_cache_'..id, rescontent, 10*60); ngx.say(rescontent) end red:close()else ngx.say(contentCache)end","categories":[{"name":"web服务器","slug":"web服务器","permalink":"https://jameslin23.gitee.io/categories/web服务器/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://jameslin23.gitee.io/tags/缓存/"}]},{"title":"docker基础篇","slug":"docker基础篇","date":"2020-12-22T01:13:29.000Z","updated":"2020-12-23T08:32:49.068Z","comments":true,"path":"2020/12/22/docker基础篇/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/22/docker基础篇/","excerpt":"","text":"Docker简介什么是Docker？Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 Linux或Windows 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。 为什么用Docker?作为一种新兴的虚拟化方法，Docker跟传统的虚拟化方式相比具有众多的优势。 更高效的利用系统资源 由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。 更快速的启动时间 传统的虚拟机技术启动应用服务往往需要数分钟，而 Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。 一致的运行环境 开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。 持续交付和部署 对于开发和运维(DevOps)人员来说,最希望的就是一次创建或者配置，可以在任意地方正常运行。使用Docker可以通过定制应用镜像来实现持续继承、持续交付、部署。开发人员可以通过Dockerfile进行镜像构建，并结合持续集成系统进行集成测试。而运维人员可以直接在生产中快速部署该镜像，甚至结合持续部署系统进行自动部署。而使用而使用Dockerfile使镜像构建透明化，不仅仅开发团队可以理解应用运行环境，也方便运维团队理解应用运行所需条件，帮助更好的生产环境中部署该镜像。 更轻松的迁移 由于Docker确保了执行环境的一致性，使得应用的迁移更加容易。Docker可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结构是一致的。 更轻松的维护和扩展 Docker 使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，Docker 团队同各个开源项目团队一起维护了一大批高质量的 官方镜像，既可以直接在生产环境使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。 基本概念docker包括三个基本概念 镜像（Image） 容器（Container） 仓库（Repository） Docker 镜像我们都知道,操作系统分为内核和用户空间。对于Linux而言,内核启动后，会挂在root文件系统为其提供用户空间支持。而Docker镜像，就相当于一个root文件系统。比如官方镜像ubuntu:16.04就包含了完整的一套ubuntu16.04最小系统的root文件系统。Docker镜像是一个特殊文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外、还包含了一些为运行时准备的一些参数(如匿名卷、环境变量、用户等)。镜像不包含任何动态数据。其内容在构建之后也不会被改变。 分层存储 因为镜像包含操作系统完整的 root 文件系统，其体积往往是庞大的，因此在 Docker 设计时，就充分利用 Union FS 的技术，将其设计为分层存储的架构。所以严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。 Docker 容器镜像和容器的关系，就像是面向对象程序设计中类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、删除、暂停等。 容器实质是进程，但与直接在宿主执行的进程不同，容器进程运行属于自己的独立的命名空间。因此容器可以拥有自己root文件系统、自己的网络配置、自己进程空间，甚至自己的用户ID空间。容器内的进程是在运行一个隔离的环境中，使用起来好像是在一个独立于宿主的系统下的操作系统一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。 前面讲过镜像使用的是分层存储，容器也是如此。每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为容器存储层。容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。 按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。 数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。 Docker 仓库镜像构建完成后，可以很容易的在当前宿主机上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry 就是这样的服务。一个 Docker Registry 中可以包含多个仓库（ Repository ）；每个仓库可以包含多个标签（ Tag ）；每个标签对应一个镜像。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。 最常使用的 Registry 公开服务是官方的 Docker Hub，这也是默认的 Registry，并拥有大量的高质量的官方镜像。国内也有一些云服务商提供类似于 Docker Hub 的公开服务。比如 时速云镜像仓库、网易云镜像服务、DaoCloud 镜像市场、阿里云镜像库 等。 安装Docker操作系统选择CentOS 7.0以上 安装之前如果需要卸载的话，执行以下指令 12345678yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 按照Docker所需要的依赖 1yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 设置阿里云镜像库 1yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 安装Docker 1yum -y install docker-ce # ce 为社区版本免费，docker-ee 企业版本 设置镜像库加速 安装步骤设置即可 12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; \"registry-mirrors\": [\"https://qhyb8ixp.mirror.aliyuncs.com\"]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 开启Docker 1service docker start 测试 1docker run hello-world 使用镜像Docker运行容器前需要本地存在对应的镜像，如果本地不在该镜像,Docker会从镜像仓库下载该镜像。 从仓库获取镜像 管理本地主机上的镜像 镜像实现的基本原理 获取镜像从 Docker 镜像仓库获取镜像的命令是 docker pull 。其命令格式为： docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] 具体的选项可以通过 docker pull –help 命令看到，这里我们说一下镜像名称的格式。 Docker 镜像仓库地址：地址的格式一般是 &lt;域名/IP&gt;[:端口号] 。默认地址是 DockerHub。 仓库名：如之前所说，这里的仓库名是两段式名称，即 &lt;用户名&gt;/&lt;软件名&gt; 。对于 DockerHub，如果不给出用户名，则默认为 library ，也就是官方镜像。 docker pull centos 列出容器docker image ls REPOSITORY TAG IMAGE ID CREATED SIZEcentos latest 300e315adb2f 2 weeks ago 209MBhello-world latest bf756fb1ae65 11 months ago 13.3kB 列表包含了 仓库名 、 标签 、 镜像 ID 、 创建时间 以及 所占用的空间 。 可以通过docker system df来便捷的查看镜像、容器、数据卷所占用的空间 TYPE TOTAL ACTIVE SIZE RECLAIMABLEImages 2 1 209.4MB 209.3MB (99%)Containers 2 0 0B 0BLocal Volumes 0 0 0B 0BBuild Cache 0 0 0B 0B 删除镜像如果要删除本地的镜像，可以使用 docker image rm 命令，其格式为： docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; …] Commit命令docker commit命令除了学习外，还有一些特殊的应用场景，比如被入侵后保存现场等，但不要使用该命令指定镜像，指定镜像应该使用Dockerfile 完成 使用 docker commit 意味着所有对镜像的操作都是黑箱操作，生成的镜像也被称为黑箱镜像，换句话说，就是除了制作镜像的人知道执行过什么命令、怎么生成的镜像，别人根本无从得知。而且，即使是这个制作镜像的人，过一段时间后也无法记清具体在操作的。虽然 docker diff 或许可以告诉得到一些线索，但是远远不到可以确保生成一致镜像的地步。这种黑箱镜像的维护工作是非常痛苦的。而且，回顾之前提及的镜像所使用的分层存储的概念，除当前层外，之前的每一层都是不会发生改变的，换句话说，任何修改的结果仅仅是在当前层进行标记、添加、修改，而不会改动上一层。如果使用 docker commit 制作镜像，以及后期修改的话，每一次修改都会让镜像更加臃肿一次，所删除的上一层的东西并不会丢失，会一直如影随形的跟着这个镜像，即使根本无法访问到。这会让镜像更加臃肿。 DockerFile定制镜像DcokerFile是一个文本文件，其中包含了一条条的指令，每一条指令构建一层，因此每一条指令的你内容，就是描述该层应当如何构建。 DockerFile构建指令 FROM # 基础镜像，一切从这里开始构建 MAINTAINER # 镜像是谁写的， 姓名+邮箱 RUN # 镜像构建的时候需要运行的命令 ADD # 步骤，tomcat镜像，这个tomcat压缩包！添加内容 添加同目录 WORKDIR # 镜像的工作目录 VOLUME # 挂载的目录 EXPOSE # 保留端口配置 CMD # 指定这个容器启动的时候要运行的命令，只有最后一个会生效，可被替代 ENTRYPOINT # 指定这个容器启动的时候要运行的命令，可以追加命令 COPY # 类似ADD，将我们文件拷贝到镜像中 ENV # 构建的时候设置环境变量！ 定制centos镜像 编写Dockerfile(文件名不是Dockerfile，构建是需要-f指定文件名) 1234567891011FROM centosMAINTAINER MT&lt;1172952007@qq.com&gt;ENV MYPATH /usr/localWORKDIR $MYPATHRUN yum -y install vimEXPOSE 80CMD /bin/bash 构建mycentos镜像 1docker build -f mycentos -t mycentosdemodo:1.0 . 查看镜像历史 1docker history 镜像ID 定制tomcat镜像 编写Dockerfile(文件名不是Dockerfile，构建是需要-f指定文件名) 12345678910111213141516171819202122FROM centosMAINTAINER fortuneteller&lt;1172952007@qq.com&gt;COPY README.txt /usr/local/README.txtADD jdk-8u271-linux-x64.tar.gz /usr/localADD apache-tomcat-9.0.41.tar.gz /usr/localRUN yum -y install vimENV MYPATH /usr/localWORKDIR $MYPATHENV JAVA_HOME /usr/local/jdk1.8.0_271ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarENV CATALINA_HOME /usr/local/apache-tomcat-9.0.41ENV CATALINA_BASH /usr/local/apache-toacat-9.0.41ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/binEXPOSE 8080CMD [\"/usr/local/apache-tomcat-9.0.41/bin/catalina.sh\", \"run\"] 构建mytomcat镜像 1docker build -f Dockerfile-tomcat -t mytomcat . 启动tomcat 1docker run -d -p 3344:8080 --name mttomcat -v /data/docker-test/tomcat/test:/usr/local/apache-tomcat-9.0.41/webapps/test -v /data/docker-test/tomcat/test/logs:/usr/local/apache-tomcat-9.0.41/logs mytomcat 进入容器 1234#查看容器iddocker container ls# 进入容器docker exec -it 容器ID /bin/bash Docker 容器启动容器启动容器有两种方式，一种是基于镜像新建一个容器并启动,另外一个是将在终止状态（stopped）的容器重启启动 因为docker的容器实在太轻量级了，很多时候用户都是随时删除和新创建容器 新建容器并启动 docker run docker run -t -i mycentos:1.0 /bin/bash 存在容器启动 docker container start 参数说明 -t让docker分配一个伪终端并绑定到容器的标准输入上 -i 则让容器的标志输入保持打开 当利用docker run 来创建容器时，Docker在后台运行标准操作包括： 检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中 从地址池配置一个ip地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 终止容器docker container stop 查看容器状态 docker container ls -a 进入容器在使用 -d 参数时，容器启动后会进入后台。某些时候需要进入容器进行操作，包括使用 docker attach 命令或 docker exec 命令，推荐大家使用 docker exec 命令 更多参数说明请使用 docker exec –help 查看。 删除容器可以使用 docker container rm 来删除一个处于终止状态的容器。例如 docker container prune可以清理掉所有处于终止状态的容器。 Docker仓库目前 Docker 官方维护了一个公共仓库 Docker Hub，其中已经包括了数量超过 15,000 的镜像。大部分需求都可以通过在 Docker Hub 中直接下载镜像来实现。 注册你可以在 https://cloud.docker.com 免费注册一个 Docker 账号。 登录可以通过执行 docker login 命令交互式的输入用户名及密码来完成在命令行界面登录Docker Hub。你可以通过 docker logout 退出登录。 拉取镜像你可以通过 docker search 命令来查找官方仓库中的镜像，并利用 docker pull 命令来将它下载到本地。 推送镜像用户也可以在登录后通过 docker push 命令来将自己的镜像推送到 Docker Hub。 docker push username/ubuntu:17.10 Docker数据管理Docker 内部以及容器之间管理数据，在容器中管理数据主要有两种方式 数据卷(Volumes) 挂载主机目录（Bind mounts） 容器之间可以有一个数据共享的技术！Docker容器中产生的数据，同步到本地！ 这就是卷技术！目录的挂载，将我们容器内的目录，挂载到Linux上面！ 使用命令 docker run -it -v 主机目录:容器内目录 /bin/bash 挂载方式 -v 容器内路径 # 匿名挂载 -v 卷名:容器内路径 # 具名挂载 -v 宿主机路径:容器内路径 # 指定路径挂载 Docker容器内的卷、在没有指定目录情况下都在/var/lib/docker/volumes/xxx/_data下 扩展 # 通过 -v 容器内路径：ro rw 改变读写权限 ro # readonly 只读 rw # readwrite 可读可写 docker run -d nginx01 -v nginxdemo:/etc/nginx:ro nginx 网络配置实现原理Docker使用linux桥接，在宿主机虚拟一个Docker容器网桥(docker0),Docker启动一个容器时会根据Docker网桥的网段分配给容器一个IP地址，称为Container-IP,同时Docker网桥是每个容器默认网关。因为在同一个宿主机的容器都接入同一个网桥，这样容器之间就能够通过容器的Container直接通讯。 Docker网桥是宿主机虚拟出来的，并不是真实存在的网络设备，外部网络是无法寻址到的，这意味着外部网络无法通过直接Container-IP访问到容器，可以通过映射容器到宿主机(端口映射)，即docker run创建容器时候通过 -p 或 -P 参数来启用，访问容器的时候就通过[宿主机IP]:[容器端口]访问容器。 网络模式 bridge模式(默认)当Docker进程启动时，会在主机上创建一个名为docker0的虚拟网桥，此主机上启动的docker容器会连接到这个虚拟网桥上。从docker0子网络中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关,在主机上创建一对虚拟网卡veth pair设备,docker将veth pair设备的一端放入新的创建的容器中，并命名eth0(容器的网卡)，另一端放在主机中。以vethxxx这样类似的名字命名,并将这个网络设备加入到doker0网桥中，可以通过brctl show命令查看 birdge模式是docker的默认网络模式，不写–net参数，就是bridge模式。使用docker run -p 时,docker实际就是做iptables做了DNAT规则，实现端口转发功能。可以使用iptables -t nat -vnl查看 host模式如果启动容器 的时候使用host模式，那么这个容器将不会获得一个独立的Network Namespace,而是和宿主机共用一个Network Namespace 。容器将不会虚拟出自己的网卡，配置自己的ip等，而是使用宿主机ip和端口。但是容器的其他方面，如文件系统，进程列表等还是个宿主机隔离。 使用host模式的容器可以直接使用宿主机的ip地址与外界通信,容器内部的服务端口也可以使用宿主机的端口，不需要进行nat,host最大优势是网络性能比较好，但是docker host上已经使用的端口就不能再用了网络隔离性不好。 container 模式这个模式指定新创建的容器和已经存在一个容器共享一个Network Namespace,而不是和宿主机共享。新创建的容器不会创建自己的网卡，配自己IP。而是和一个指定的容器共享IP、端口等。同样2个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。2个容器进程可以通过lo网卡设备通信。 none模式使用none模式，docker容器拥有自己的Network Namespace,但是，并不为Docker容器进行任何网络配置，也就是说，这个容器没有网卡、IP、路由等信息。所以需要我们自己为docker容器添加网卡、配置IP等。 这种网络模式下容器只有lo回环网络，没有其他网卡。node模式可以在容器创建时通过–network=none来指定。这类型网络没有办法联网，封闭的网络能很好保证容器安全性。","categories":[{"name":"docker","slug":"docker","permalink":"https://jameslin23.gitee.io/categories/docker/"}],"tags":[{"name":"运维与虚拟化技术","slug":"运维与虚拟化技术","permalink":"https://jameslin23.gitee.io/tags/运维与虚拟化技术/"}]},{"title":"tcp可靠机制","slug":"tcp可靠机制","date":"2020-12-16T01:56:00.000Z","updated":"2020-12-16T02:41:22.671Z","comments":true,"path":"2020/12/16/tcp可靠机制/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/16/tcp可靠机制/","excerpt":"","text":"前言为了实现可靠性传输，需要考虑很多事情，例如数据的破坏、丢包、重复以及分片顺序混乱等问题。如不能解决这些问题，也就无从谈起可靠传输。 那么，TCP 是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的 今天，将重点介绍 TCP 的重传机制、滑动窗口、流量控制、拥塞控制。 ## 重传机制超时重传指在设置时间内未收到对方ACK确认应答报文，就会重发数据。 如果超时重发的数据，再次超时的时候，又需要重传时候，TCP的策略是超时间隔加倍。 每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。 存在问题: 超时周期可能相对较长 快速重传快速重传的工作方法是当收到三个相同ACK报文时，会在定时器过期之前，重传丢失报文。 存在问题： 重传的时候，是重传之前的一个，还是所有？ SACKSACK选择性确认 在TCP头部选项字段加一个SACK的东西，缓存发送的序列化，然后发送给发送方，让发送方可以知道哪些数据收到，哪些数据没收到。 知道这些信息，就可以只重传丢失的数据。 如果要支持 SACK，必须双方都要支持。在 Linux 下，可以通过 net.ipv4.tcp_sack 参数打开这个功能（Linux 2.4 后默认打开）。 D-SACK使用SACK来告诉有哪些数据被重复接收了 ACK丢包 「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499） 于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 D-SACK。 这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。 网络延迟 数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。 而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」； 所以「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。 这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。 滑动窗口流量控制拥塞控制","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://jameslin23.gitee.io/categories/计算机网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://jameslin23.gitee.io/tags/计算机网络/"}]},{"title":"http核心技术","slug":"http核心技术","date":"2020-12-15T02:03:03.000Z","updated":"2020-12-16T00:57:42.861Z","comments":true,"path":"2020/12/15/http核心技术/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/15/http核心技术/","excerpt":"","text":"前言 HTTP 基本概念 Get 与 Post HTTP 特性 HTTP 与 HTTPS HTTP/1.1、HTTP/2、HTTP/3 演练 HTTP基本概念初入认识http是超文本传输协议，是在一个计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范。 状态码 常见字段 Host 客户端发送请求时，用来指定服务器的域名 Content-Length 服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据长度。 如上面则是告诉浏览器，本次服务器回应的数据长度是 1000 个字节，后面的字节就属于下一个回应了。 Connection Connection 字段最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。 HTTP/1.1 版本的默认连接都是持久连接，但为了兼容老版本的 HTTP，需要指定 Connection 首部字段的值为 Keep-Alive。 Content-Type Content-Type 字段用于服务器回应时，告诉客户端，本次数据是什么格式。 1Content-Type: text/html; charset=utf-8 上面的类型表明，发送的是网页，而且编码是UTF-8。 1Accept: */* 上面代码中，客户端声明自己可以接受任何格式的数据。 Content-Encoding Content-Encoding 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式 1Content-Encoding: gzip 上面表示服务器返回的数据采用了 gzip 方式压缩，告知客户端需要用此方式解压。 客户端在请求时，用 Accept-Encoding 字段说明自己可以接受哪些压缩方法。 1Accept-Encoding: gzip, deflate GET和POSTGETGet 方法的含义是请求从服务器获取资源，这个资源可以是静态的文本、页面、图片视频等 比如，你打开我的文章，浏览器就会发送 GET 请求给服务器，服务器就会返回文章的所有文字及资源。 POST而POST 方法则是相反操作，它向 URI 指定的资源提交数据，数据就放在报文的 body 里。 比如，你在我文章底部，敲入了留言后点击「提交」，浏览器就会执行一次 POST 请求，把你的留言文字放进了报文 body 里，然后拼接好 POST 请求头，通过 TCP 协议发送给服务器。 GET 和 POST 区别？安全幂等先说明下安全和幂等的概念： 在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。 那么很明显 GET 方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。 POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。 参数存放 GET请求参数是放在URL后面，从而容易导致被攻击者窃取，对你的信息超成破坏和伪造，对URL有长度限制； POST请求参数是放在请求体BODY中。对数据长度没有要求。 TCP数量 get 请求在发送过程中会产生一个 TCP 数据包，浏览器会把 http header 和 data 一并发送出去，服务器响应 200（返回数据） post 在发送过程中会产生两个 TCP 数据包，浏览器先发送 header，服务器响应 100 continue，浏览器再发送 data，服务器响应 200 ok（返回数据）。 HTTP特性优点 简单 灵活和易于扩展 应用广泛跨平台 缺点HTTP 协议里有优缺点一体的双刃剑，分别是「无状态、明文传输」，同时还有一大缺点「不安全」。 无状态双刃剑 无状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。 无状态的坏处，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦 解决方法：使用cookie技术 Cookie 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。 相当于，在客户端第一次请求后，服务器会下发一个装有客户信息的「小贴纸」，后续客户端请求服务器的时候，带上「小贴纸」，服务器就能认得了了 明文传输双刃剑 明文意味着在传输过程中的信息，是可方便阅读的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。 但是这正是这样，HTTP 的所有信息都暴露在了光天化日下，相当于信息裸奔。在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能被窃取，如果里面有你的账号密码信息。 不安全 使用HTTPS解决。 HTTPSHTTP 由于是明文传输，所以安全上存在以下三个风险： 窃听风险，比如通信链路上可以获取通信内容，用户号容易没。 篡改风险，比如强制入垃圾广告，视觉污染，用户眼容易瞎。 冒充风险，比如冒充淘宝网站，用户钱容易没。 HTTPS 在HTTP与TCP层之间加入SSL/TLS协议 可以很好的解决了上述的风险： 信息加密：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。 校验机制：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。 身份证书：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。 HTTPS是如何解决上面的三个风险？ 混合加密的方式实现信息的机密性，解决了窃听的风险。 摘要算法的方式来实现完整性，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。 将服务器公钥放入到数字证书中，解决了冒充的风险。 混合加密 通过混合加密的方式可以保证信息的机密性，解决了窃听的风险。 HTTPS 采用的是对称加密和非对称加密结合的「混合加密」方式： 在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。 在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。 采用「混合加密」的方式的原因： 对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。 非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。 摘要算法 摘要算法用来实现完整性，能够为数据生成独一无二的「指纹」，用于校验数据的完整性，解决了篡改的风险。 客户端在发送明文之前会通过摘要算法算出明文的「指纹」，发送的时候把「指纹 + 明文」一同加密成密文后，发送给服务器，服务器解密后，用相同的摘要算法算出发送过来的明文，通过比较客户端携带的「指纹」和当前算出的「指纹」做比较，若「指纹」相同，说明数据是完整的。 数字证书 客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。 这就存在些问题，如何保证公钥不被篡改和信任度？ 所以这里就需要借助第三方权威机构 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。 HTTP/1.1、HTTP/2、HTTP/3 演变说说 HTTP/1.1 相比 HTTP/1.0 提高了什么性能？HTTP/1.1 相比 HTTP/1.0 性能上的改进： 使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。 支持 管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。 HTTP/1.1 还是有性能瓶颈： 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分； 发送冗长的首部。每次互相发送相同的首部造成的浪费较多； 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞； 没有请求优先级控制； 请求只能从客户端开始，服务器只能被动响应。 那上面的 HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？ HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。 HTTP/2 相比 HTTP/1.1 性能上的改进 头部压缩 HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你消除重复的分。 这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。 二进制格式 HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式。 头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧和数据帧。 这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这增加了数据传输的效率。 数据流 HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。 每个请求或回应的所有数据包，称为一个数据流（Stream）。 每个数据流都标记着一个独一无二的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数 客户端还可以指定数据流的优先级。优先级高的请求，服务器就先响应该请求。 多路复用 HTTP/2 是可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应。 移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，降低了延迟，大幅度提高了连接的利用率。 举例来说，在一个 TCP 连接里，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程非常耗时，于是就回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分。 服务器推送 HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以主动向客户端发送消息。 举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会用到的 JS、CSS 文件等静态资源主动发给客户端，减少延时的等待，也就是服务器推送（Server Push，也叫 Cache Push）。 HTTP/2 有哪些缺陷？HTTP/3 做了哪些优化？HTTP/2 主要的问题在于：多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。 所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。 HTTP/1.1 中的管道（ pipeline）传输中如果有一个请求阻塞了，那么队列后请求也统统被阻塞住了 HTTP/2 多请求复用一个TCP连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。 这都是基于 TCP 传输层的问题，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！ UDP 发生是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的一个丢包全部重传问题。 大家都知道 UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。 QUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响。 TL3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack。 HTTPS 要建立一个连接，要花费 6 次交互，先是建立三次握手，然后是 TLS/1.3 的三次握手。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数 所以， QUIC 是一个在 UDP 之上的伪 TCP + TLS + HTTP/2 的多路复用的协议。 QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题。所以 HTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。 无状态协议无状态协议就是指浏览器对于事务的处理没有记忆能力。例如比如客户请求获得网页之后关闭浏览器，然后再次启动浏览器，登陆该网站，但是服务器并不知道客户关闭了一次浏览器。 HTTP 就是一种无状态的协议，他对用户的操作没有记忆能力。可能大多数用户不相信，他可能觉得每次输入用户名和密码登陆一个网站后，下次登陆就不再重新输入用户名和密码了。这其实不是 HTTP 做的事情，起作用的是一个叫做 小甜饼(Cookie) 的机制。它能够让浏览器具有记忆能力。 如果你的浏览器允许 cookie 的话，查看方式 chrome://settings/content/cookies 当你向服务端发送请求时，服务端会给你发送一个认证信息，服务器第一次接收请求时，开辟了一块Session空间（创建了Session对象） 同时生成一个sessionID,并通过响应头的Set-Cookie: JSESSIONID=XXXXXXX 命令，向客户端发送要求设置Cookie的响应；客户端接收响应后，在本机客户端设置一个JSESSIONID=XXXXXXX 的 Cookie 信息，该 Cookie 的过期时间为浏览器会话结束。 ​ 接下来客户端每次向同一个网站发送请求时，请求头都会带上该Cookie信息（包含sessionid）,然后，服务器通过读取请求头中cookie信息，获取名称为JSESSIONID 的值，得到每次请求SessionID，这样，你的浏览器才具有记忆能力。 ​ 还有一种方式是使用 JWT 机制，它也是能够让你的浏览器具有记忆能力的一种机制。与 Cookie 不同，JWT 是保存在客户端的信息，它广泛的应用于单点登录的情况。JWT 具有两个特点 JWT 的 Cookie 信息存储在客户端，而不是服务端内存中。也就是说，JWT 直接本地进行验证就可以，验证完毕后，这个 Token 就会在 Session 中随请求一起发送到服务器，通过这种方式，可以节省服务器资源，并且 token 可以进行多次验证。 JWT 支持跨域认证，Cookies 只能用在单个节点的域或者它的子域中有效。如果它们尝试通过第三个节点访问，就会被禁止。使用 JWT 可以解决这个问题，使用 JWT 能够通过多个节点进行用户认证，也就是我们常说的跨域认证。","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://jameslin23.gitee.io/categories/计算机网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://jameslin23.gitee.io/tags/计算机网络/"}]},{"title":"TCP-IP","slug":"TCP-IP","date":"2020-12-14T01:47:40.000Z","updated":"2020-12-15T02:15:48.462Z","comments":true,"path":"2020/12/14/TCP-IP/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/14/TCP-IP/","excerpt":"","text":"OSI标准模型OSI标准模型是7层架构 ​ 应用层: 应用层是OSI标准模型的最顶层,是直接为应用进程提供服务。其作用在实现多个系统应用进程相互通信的同时，完成一系列业务处理所需要的服务。包括文件传输、电子邮件远程登录和远程接口调用等协议。 表示层: 表示层向上对应用服务，向下接收会话层提供的服务，表示层位于OSI标准模型的第六层，表示层的主要作用就是将设备的固有数据格式转换为网络标准传输格式。 会话层: 会话层位于OSI标准模型的第五层，它是建立在传输层之上，利用传输层提供的服务建立和维持会话。 传输层: 传输层为上面的应用层提供通讯服务,负责将上层数据分段并提供端到端的,可靠（TCP）或者不可靠（UDP）的传输，以及端到端的差错控制和流量控制 网络层: 实现两个端系统之间的数据透明传送，具体功能包括寻址和路由选择、连接的建立、保持和终止等。它提供的服务使传输层不需要了解网络中的数据传输和交换技术。（协议：IP、ICMP协议、ARR、RAPP协议，设备: 路由器） 链路层: 最基本服务是将来自网络层的数据可靠传输到相临节点的目标机（协议：以太网协议，设备：网桥和交换机） 物理层: 为上层提供了一个传输数据可靠的物理媒介 TCP/IP体系TCP/IP协议说的不仅仅只是TCP/IP这两种协议、TCP/IP指的协议簇，简单来说就是一系列协议的综合 TCP/IP 协议是我们程序员接触最多的协议，OSI 模型共有七层，从下到上分别是物理层、数据链路层、网络层、运输层、会话层、表示层和应用层。但是这显然是有些复杂的，所以在 TCP/IP 协议中，它们被简化为了四个层次 各层定义通信链路层通信链路层包括物理层和链路层 网络层实现两个端系统之间的数据传送，具体功能包括寻址和路由选择、连接的建立、保持和终止等。它提供的服务使传输层不需要了解网络中的数据传输和交换技术。 提供两种服务 虚电路服务 虚电路表示只是一条逻辑上的链接，分组都沿着这条逻辑链接按照存储转发的方式发送，而不是真正建立了一个物理连接。 数据报服务 提供简单灵活、无连接、尽最大努力交付的数据报服务 包括协议 IP协议(Internet Protocol,因特网协议) IP地址由四段组成，每个字段是一个字节，8位，最大值是255 IP地址由两部分组成，即网络地址和主机地址。网络地址表示其属于互联网的哪一个网络，主机地址表示其属于该网络中的哪一台主机。二者是主从关系。 IP地址的四大类型标识的是网络中的某台主机。IPv4的地址长度为32位，共4个字节，但实际中我们用点分十进制记法。 IP地址根据网络号和主机号来分,分为A、B、C、三类及特殊地址D、E。全0和全1都不保留不用。 A类：1.0.0.0 ~ 127.255.255.255 私有：10.0.0.0~10.255.255.255 B类：128.0.0.0 ~ 191.255.255.255 私有：172.16.0.0～172.31.255.255 C类：192.0.0.0~ 223.255.255.255 私有：192.168.0.0~192.168.255.255 D类：224.0.0.0 ~ 239.255.255.255 E类：240.0.0.0~247.255.255.255 回环地址：127.0.0.0/8被用作回环地址，回环地址表示本机的地址，常用于对本机的测试，用的最多的是127.0.0.1。 ICMP协议(Internet Control Message Protocol，因特网控制报文协议) ARP协议（Address Resolution Protocol，地址解析协议） 从网络层使用IP地址，解析出数据链路层使用的硬件地址（由IP地址解析出硬件地址） 当主机A预向本局域网上的某个主机B发送IP数据报时，就先其ARP高速缓存中查看有无主机B的IP地址。 有，就可查出其对应的硬件地址，再将此硬件地址写入MAC帧，然后通过局域网将该MAC帧发往此硬件地址。 没有，ARP进程在本局域网上广播发送一个ARP请求分组。收到ARP响应分组后，将得到IP地址到硬件地址的映射写入ARP高速缓存。 RARP协议（Reverse Address Resolution Protocol，逆地址解析协议） 传输层TCP/IP协议是Internet最基本的协议、Internet国际互联网络的基础，由网络层的IP协议和传输层的TCP协议组成。通俗而言：TCP负责发现传输的问题，一有问题就发出信号，要求重新传输，直到所有数据安全正确地传输到目的地。而IP是给因特网的每一台联网设备规定一个地址。 TCPTCP 是一种可靠的协议，它能够保证数据包的可靠性交付，TCP 能够正确处理传输过程中的丢包、传输顺序错乱等异常情况。此外，TCP 还提供拥塞控制用于缓解网络拥堵。 TCP报文首部格式： 三次握手 建立连接时，客户端发送syn包（syn=j）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。 服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态； 客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。 总结: 因为TCP面向连接，可靠的，3次足以满足一个安全连接请求和应答。clinet发出第一个连接请求报文段并没有丢失，而是在某个网络节点长时间堵塞，以致于延误连接释放以后某个时间点才到达server端，server端以为是clinet发送新请求，像客户端发送确认报文，如果不建立3次连接，只要客户端发送确认报文就建立连接，并一直等待clinet发来的数据，这样server端资源就被占用浪费了。 4次挥手 1）客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。2）服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。3）客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。4）服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。5）客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。6）服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。 总结： TCP面向连接，可靠的，断开连接需要双方都同意，才能断开连接。所以满足条件需要4次。 UDPUDP用户数据报协议,是面向无连接的通讯协议，UDP数据包括目的端口号和源端口号信息，由于通讯不需要连接，所以可以实现广播发送。 TCP 与 UDP 的区别：TCP是面向连接的，可靠的字节流服务；UDP是面向无连接的，不可靠的数据报服务。 应用层在TCP/IP协议簇中，将OSI标准模型中的会话层，表示层都归为了应用层。应用层的架构大多属于客户端/服务端，提供服务的程序叫做服务端，接受服务的程序就做客户端。在这种架构中，服务端通常会提前部署到服务器上，等待客户端连接，从而提供服务。 传输过程数据包结构 每一分层中，都会对所发送的数据增加一个首部，这个首部中包含该层必要的信息。每一层都会对数据进行处理并在数据包中附上这一层的必要信息。 数据包发送历程假设主机 A 和主机 B 进行通信，主机 A 想要向主机 B 发送一个数据包，都会经历哪些奇特的操作？ 1、应用层的处理 主机 A 也就是用户点击了某个应用或者打开了一个聊天窗口输入了cxuan，然后点击了发送，那么这个 cxuan 就作为一个数据包遨游在了网络中，等下还没完呢，应用层还需要对这个数据包进行处理，包括字符编码、格式化等等，这一层其实是 OSI 中表现层做的工作，只不过在 TCP/IP 协议中都归为了应用层。 数据包在发送的那一刻建立 TCP 连接，这个连接相当于通道，在这之后其他数据包也会使用通道传输数据。 2、传输层处理 为了描述信息能准确的到达另一方，我们使用 TCP 协议来进行描述。TCP 会根据应用的指示，负责建立连接、发送数据和断开连接。 TCP 会在应用数据层的前端附加一个 TCP 首部字段，TCP 首部包含了源端口号 和 目的端口号，这两个端口号用于表明数据包是从哪里发出的，需要发送到哪个应用程序上；TCP 首部还包含序号，用以表示该包中数据是发送端整个数据中第几个字节的序列号；TCP 首部还包含 校验和，用于判断数据是否损坏，随后将 TCP 头部附加在数据包的首部发送给 IP。 3、网络层处理 网络层主要负责处理数据包的是 IP 协议，IP 协议将 TCP 传过来的 TCP 首部和数据结合当作自己的数据，并在 TCP 首部的前端加上自己的 IP 首部。因此，IP 数据包后面会紧跟着 TCP 数据包，后面才是数据本身。IP 首部包含目的和源地址，紧随在 IP 首部的还有用来判断后面是 TCP 还是 UDP 的信息。 IP 包生成后，会由路由控制表判断应该发送至哪个主机，IP 修饰后的数据包继续向下发送给路由器或者网络接口的驱动程序，从而实现真正的数据传输。 4、通信链路层处理 经由 IP 传过来的数据包，以太网会给数据附上以太网首部并进行发送处理。以太网首部包含接收端的 MAC 地址、发送端的 MAC 地址以及标志以太网类型的以太网数据协议等 数据包接收历程1、通信链路的解析 目标主机收到数据包后，首先会从以太网的首部找到MAC地址判断是否是发给自己的数据包，如果不是发给自己的数据包则会丢弃该数据包。 如果收到的数据包是发送给自己，就会查以太网类型判断是哪种协议，如果是IP协议就扔给IP协议进行处理，如果是ARR协议就扔给ARP协议进行处理。如果协议无法识别，就丢弃。 2、网络层的解析 经过以太网处理后的数据包扔给网络层处理，我们假设协议类型是IP协议，那么在IP收到数据包后就会解析IP首部，判断IP首部中IP地址是不是与自己匹配，如果匹配接收并判断上一层协议是TCP或者UDP,不匹配直接丢弃。 注意：在路由转发的过程中，有的时候 IP 地址并不是自己的，这个时候需要借助路由表协助处理 3、传输层的处理 在传输层中，我们默认使用TCP协议，在TCP处理过程中，首先会计算一下校验和，判断数据是否被损坏。然后检测是否按照序号接收数据，最后检查端口号，确定是哪个应用程序。数据被完整的识别，会传递给由端口号识别的应用程序进行处理。 4、应用程序的处理 接收端指定的应用程序会处理发送方传递过来的数据，通过解码等操作识别出数据的内容，然后把对应的数据存储在磁盘上，返回一个保存成功的消息给发送方，如果保存失败，则返回错误消息。 下面是完整的处理过程和解析过程 数据包经过每层后，该层协议都会在数据包附上包首部，一个完整的包首部图如下所示","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://jameslin23.gitee.io/categories/计算机网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://jameslin23.gitee.io/tags/计算机网络/"}]},{"title":"平衡二叉搜索树","slug":"平衡二叉搜索树","date":"2020-12-12T03:36:28.000Z","updated":"2020-12-15T02:08:31.855Z","comments":true,"path":"2020/12/12/平衡二叉搜索树/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/12/平衡二叉搜索树/","excerpt":"","text":"平衡二叉搜索树平衡二叉搜索树简称:BBST 平衡二叉搜索树类型 AVL树 Windows NT 内核中广泛使用 红黑树 C++ STL(比如map、set) java的TreeMap、TreeSet、HashMap、HashSet Linux的进程调度 Ngix的timer管理 AVL树平衡因子(Balance Factor): 某节点的左右子树的高度差 特点 每个节点的平衡因子只可能是1、0、-1(如果绝对值-1,如果超过1,称为失衡) 每个节点的左右子树高度差不超过1 搜索、添加、删除的时间复杂度是o(logn) 旋转调整旋转有4种情况 LL-右旋转(单旋)当左子树出现不平衡情况，也就是LL(左节点-左节点)，就需要右旋转 g.left = p.right p.right = g 让P成为这个棵子树的根节点 仍然是一颗二叉搜索树: T0&lt; n &lt; T1 &lt; p &lt; T2 &lt; g &lt; T3 需要注意的维护内容 T2、p、g的parent属性 先后更新g、p的高度 RR - 左旋转(单旋)当右子树出现不平衡情况，也就是RR(右节点-右节点)，就需要左旋转 g.right = p.leftt p.left = g 让p成为这棵子树的根节点 仍然是一颗二叉搜索树: T0 &lt; g &lt; T1 &lt; p &lt; T2 &lt; n &lt;T3 需要维护内容 T1、p、g的parent属性 先后更新g、p的高度 LR-左旋转，右旋转出现LR情况、需要2次旋转，才能达到平衡 RL-右旋转,左旋转 总结添加 可能导致所有祖先节点都失衡 只要让高度最低的失衡节点恢复平衡,整棵树就恢复平衡[仅需o(1)次调整] 删除 只可能会导致父节点失衡 让父节点恢复平衡后,可能会导致更高层的祖先节点失衡[最多需要o(logn)次调整] 平均时间复杂度 搜索: o(logn) 添加:o(logn)，仅需o(1)次调整 删除:o(logn),最多需要o(logn)次旋转操作 红黑树特点（5大特点） 节点是RED或者BLACK 根节点是BLACK 叶子节点(外部节点,空节点) 都是BLACK RED节点的子节点都是BLACK RED节点的parent都是BLACK 从根节点到叶子节点的所有路径不能有2个连续的RED节点 从任一节点到叶子节点的所有路径都包含相同的BLACK节点 红黑树和4阶B树(2-3-4树)具有等价性 BLACK节点与它的RED字节点融合在一起，形成1个B树节点 红黑树的BLACK节点个树与4阶B树的节点总个树相等 添加过程总共3大类，12种情况 4种情况满足红黑情况的性质，不用修改。 父节点为黑色 有八种情况满足红黑树性质：父节点为红色（Double Red） 其中4种叔父(父节点的兄弟)节点是黑色 这4种情况分别是RR/LL/RL/LR RR/LL 1、父亲节点染成黑色BLACK,祖父节点染成RED 2、祖父节点进行单旋 3、RR(左旋)、LL(右旋) RL/LR 1、自己染成黑色BLACK,祖父节点染成红色 2、进行双旋操作 3、LR(父节点左旋，祖父节点右旋) 4、RL(父节点右旋，祖父节点左旋) 4种叔父(父节点的兄弟)节点是红色 这4种情况也分别是RR/LL/RL/LR RR 1、父节点和叔父节点染成黑色 2、祖父节点(染成红色)向上合并，当做新添加节点进行处理 3、向上合并时候有可能继续发生上益 ​ 删除过程 A—删除的是叶子节点且该叶子节点是红色的，无需修复。 B—删除的是叶子节点且叶子节点是黑色的，会破坏特征5，需要修复 C—删除的节点（P）有一个子节点(S)，通过置换的方式，然后进行删除。 S为红，P为黑，对应A情况 待补充（看算法导论为准） AVL树 VS 红黑树总结AVL树 平衡标准严格:每个左右子树的高度差不超过1 最大高度是1.44*log2(n+1)-1.328(100w节点，AVL树最大树高28) 搜索、添加、删除都是o(logn)复杂度，其中添加仅仅需要o(1)次调整、删除最多需要o(logn)次旋转调整 红黑树 平衡标准比较宽松:没有一条路径会大于其他路径2倍 最大高度是2*log2(n+1)(100万个节点，红黑树最大树高40) 搜索、添加、删除都是o(logn)复杂度，其中添加、删除都仅仅o(1)次旋转调整 选择 搜索的次数远远大于插入和删除,选择AVL树；搜索、插入、删除几乎差不多，选择红黑树 相对AVL树来说，红黑树牺牲了部分平衡以换取插入/删除操作时少量旋转操作，整体来说性能要优于AVL树 红黑树的平均统计性能优于AVL树,实际应用中更多选择使用红黑树","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://jameslin23.gitee.io/categories/数据结构与算法/"}],"tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://jameslin23.gitee.io/tags/数据结构与算法/"}]},{"title":"ZooKeeper的ZAB协议","slug":"ZooKeeper的ZAB协议","date":"2020-12-11T07:07:32.000Z","updated":"2020-12-11T09:21:32.328Z","comments":true,"path":"2020/12/11/ZooKeeper的ZAB协议/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/11/ZooKeeper的ZAB协议/","excerpt":"","text":"前言Zab（Zookeeper Atomic Broadcast）是为ZooKeeper协设计的崩溃恢复原子广播协议，它保证zookeeper集群数据的一致性和命令的全局有序性。 概念介绍在介绍zab协议之前首先要知道zookeeper相关的几个概念，才能更好的了解zab协议。 集群角色 Leader: 同一时间集群总有允许有一个Leader,提供对客户端的读写功能，负责将数据同步至各个节点。 Follower: 提供对客户端读功能,写请求则转发给Leader处理,当Leader崩溃失联之后，参与Leader选举 Observer:不参与Leader选举 服务状态 LOOKING：当节点认为群集中没有Leader，服务器会进入LOOKING状态，目的是为了查找或者选举Leader； FOLLOWING：follower角色； LEADING：leader角色； OBSERVING：observer角色； Zookeeper是通过自身的状态来区分自己所属的角色，来执行自己应该的任务。 ZAB状态Zookeeper还给ZAB定义的4中状态，反应Zookeeper从选举到对外提供服务的过程中的四个步骤。状态枚举定义： 123456public enum ZabState &#123; ELECTION, // 集群进入选举状态，此过程会选出一个节点作为leader角色； DISCOVERY,// 连接上leader，响应leader心跳，并且检测leader的角色是否更改，通过此步骤之后选举出的leader才能执行真正职务； SYNCHRONIZATION,// 整个集群都确认leader之后，将会把leader的数据同步到各个节点，保证整个集群的数据一致性； BROADCAST// 过渡到广播状态，集群开始对外提供服务。&#125; Zxid Zxid是Zab协议的一个事务编号,Zxid是一个64位数字,其中低32位是一个简单的单调递增计数器,针对客户每个一个事务请求,计数器+1；而高32位则代表Leader周期年代编号（epoch）。 选举选举时机 服务器初始化启动 服务器运行期间Leader故障 启动时选举假设一个 Zookeeper 集群中有5台服务器，id从1到5编号，并且它们都是最新启动的，没有历史数据 假设服务器依次启动，我们来分析一下选举过程： （1）服务器1启动 发起一次选举，服务器1投自己一票，此时服务器1票数一票，不够半数以上（3票），选举无法完成。 投票结果：服务器1为1票。 服务器1状态保持为LOOKING。 （2）服务器2启动 发起一次选举，服务器1和2分别投自己一票，此时服务器1发现服务器2的id比自己大，更改选票投给服务器2。 投票结果：服务器1为0票，服务器2为2票。 服务器1，2状态保持LOOKING （3）服务器3启动 发起一次选举，服务器1、2、3先投自己一票，然后因为服务器3的id最大，两者更改选票投给为服务器3； 投票结果：服务器1为0票，服务器2为0票，服务器3为3票。此时服务器3的票数已经超过半数（3票），服务器3当选Leader。 服务器1，2更改状态为FOLLOWING，服务器3更改状态为LEADING。 （4）服务器4启动 发起一次选举，此时服务器1，2，3已经不是LOOKING 状态，不会更改选票信息。交换选票信息结果：服务器3为3票，服务器4为1票。此时服务器4服从多数，更改选票信息为服务器3。 服务器4并更改状态为FOLLOWING。 （5）服务器5启动 与服务器4一样投票给3，此时服务器3一共5票，服务器5为0票。 服务器5并更改状态为FOLLOWING。 最终的结果： 服务器3是 Leader，状态为 LEADING；其余服务器是 Follower，状态为 FOLLOWING。 运行时期的Leader选举在Zookeeper运行期间 Leader 和 非 Leader 各司其职，当非Leader服务器宕机或者加入不会影响Leader，但是一旦Leader服务器挂了,那么整个Zookeeper集群将暂停对外服务,会触发新一轮的选举。 初始状态下服务器3当选为Leader，假设现在服务器3故障宕机了，此时每个服务器上zxid可能都不一样，server1为99，server2为102，server4为100，server5为101 （1）状态变更。Leader 故障后，余下的非 Observer 服务器都会将自己的服务器状态变更为LOOKING，然后开始进入Leader选举过程。 （2）每个Server会发出投票。 （3）接收来自各个服务器的投票，如果其他服务器的数据比自己的新会改投票。 （4）处理和统计投票，每一轮投票结束后都会统计投票，超过半数即可当选。 （5）改变服务器的状态，宣布当选。 传递集群在经过leader选举之后还会有连接leader和同步两个步骤，这里就不具体分析这两个步骤的流程了，主要介绍集群对外提供服务如何保证各个节点数据的一致性。 zab在广播状态中保证以下特征 可靠传递: 如果消息m由一台服务器传递，那么它最终将由所有服务器传递。 全局有序: 如果一个消息a在消息b之前被一台服务器交付，那么所有服务器都交付了a和b，并且a先于b。 全局有序: 如果一个消息a在消息b之前被一台服务器交付，那么所有服务器都交付了a和b，并且a先于b。 有序性是zab协议必须要保证的一个很重要的属性，因为zookeeper是以类似目录结构的数据结构存储数据的，必须要求命名的有序性。 比如一个命名a创建路径为/test，然后命名b创建路径为/test/123，如果不能保证有序性b命名在a之前，b命令会因为父节点不存在而创建失败。 ​ 如上图所示，整个写请求类似一个二阶段的提交。 当收到客户端的写请求的时候会经历以下几个步骤： Leader收到客户端的写请求，生成一个事务（Proposal），其中包含了zxid； Leader开始广播该事务，需要注意的是所有节点的通讯都是由一个FIFO的队列维护的； Follower接受到事务之后，将事务写入本地磁盘，写入成功之后返回Leader一个ACK； Leader收到过半的ACK之后，开始提交本事务，并广播事务提交信息 从节点开始提交本事务。 有以上流程可知，zookeeper通过二阶段提交来保证集群中数据的一致性，因为只需要收到过半的ACK就可以提交事务，所以zookeeper的数据并不是强一致性。 zab协议的有序性保证是通过几个方面来体现的，第一是，服务之前用TCP协议进行通讯，保证在网络传输中的有序性；第二，节点之前都维护了一个FIFO的队列，保证全局有序性；第三，通过全局递增的zxid保证因果有序性。 状态流转前面介绍了zookeeper服务状态有四种，ZAB状态也有四种。这里就简单介绍一个他们之间的状态流转，更能加深对zab协议在zookeeper工作流程中的作用。 服务在启动或者和leader失联之后服务状态转为LOOKING 如果leader不存在选举leader，如果存在直接连接leader，此时zab协议状态为ELECTION 如果有超过半数的投票选择同一台server，则leader选举结束，被选举为leader的server服务状态为LEADING，其他server服务状态为FOLLOWING/OBSERVING 所有server连接上leader，此时zab协议状态为DISCOVERY leader同步数据给learner，使各个从节点数据和leader保持一致，此时zab协议状态为SYNCHRONIZATION 同步超过一半的server之后，集群对外提供服务，此时zab状态为BROADCAST","categories":[{"name":"服务中心","slug":"服务中心","permalink":"https://jameslin23.gitee.io/categories/服务中心/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://jameslin23.gitee.io/tags/分布式/"}]},{"title":"ZooKeeper","slug":"ZooKeeper","date":"2020-12-11T02:12:20.000Z","updated":"2020-12-17T10:55:08.915Z","comments":true,"path":"2020/12/11/ZooKeeper/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/11/ZooKeeper/","excerpt":"","text":"Zookeeper概述 ZooKeeper是一个分布式服务框架，可以用ZooKeeper来做：统一配置管理、统一命名服务、分布式锁、集群管理。 使用分布式系统就无法避免对节点管理的问题(需要实时感知节点的状态、对节点进行统一管理等等)，而由于这些问题处理起来可能相对麻烦和提高了系统的复杂性，ZooKeeper作为一个能够通用解决这些问题的中间件就应运而生了 结构那为什么ZooKeeper可以干那么多事？来看看ZooKeeper究竟是何方神物，在Wiki中其实也有提到： ZooKeeper nodes store their data in a hierarchical name space, much like a file system or a tree data structure ZooKeeper的数据结构，跟Unix文件系统非常类似，可以看做是一颗树，每个节点叫做ZNode。每一个节点可以通过路径来标识，结构图如下： 那ZooKeeper这颗”树”有什么特点呢？？ZooKeeper的节点我们称之为Znode，Znode分为两种类型： 短暂/临时(Ephemeral)：当客户端和服务端断开连接后，所创建的Znode(节点)会自动删除 持久(Persistent)：当客户端和服务端断开连接后，所创建的Znode(节点)不会删除 ZooKeeper和Redis一样，也是C/S结构(分成客户端和服务端) 监听器在上面我们已经简单知道了ZooKeeper的数据结构了，ZooKeeper还配合了监听器才能够做那么多事的。 常见的监听场景有以下两项： 监听Znode节点的数据变化 监听子节点的增减变化 ​ 没错，通过监听+Znode节点(持久/短暂[临时])，ZooKeeper就可以玩出这么多花样了。 统一配置管理比如我们现在有3个系统A、B、C、他们有三份配置,分别是ASystem.yml、BSystem.yml、CSystem.yml,然后这分配又非常类似,很多的配置项几乎都一样 此时，如果我们要改变其中一份配置项的信息，很可能其他两份都要改。并且，改变了配置项的信息很可能就要重启系统 于是，我们希望把ASystem.yml、BSystem.yml、CSystem.yml相同的配置项抽取出来成一份公用的配置common.yml，并且即便common.yml改了，也不需要系统A、B、C重启。 做法：我们可以将common.yml这份配置放在ZooKeeper的Znode节点中，系统A、B、C监听着这个Znode节点有无变更，如果变更了，及时响应。 统一命名服务统一命名服务的理解其实跟域名一样，是我们为这某一部分的资源给它取一个名字，别人通过这个名字就可以拿到对应的资源。 比如说，现在我有一个域名www.java3y.com，但我这个域名下有多台机器： 192.168.1.1 192.168.1.2 192.168.1.3 192.168.1.4 分布锁我们可以使用ZooKeeper来实现分布式锁，那是怎么做的呢？？下面来看看： 系统A、B、C都去访问/locks节点 访问的时候会创建带顺序号的临时/短暂(EPHEMERAL_SEQUENTIAL)节点，比如，系统A创建了id_000000节点，系统B创建了id_000002节点，系统C创建了id_000001节点。 接着，拿到/locks节点下的所有子节点(id_000000,id_000001,id_000002)，判断自己创建的是不是最小的那个节点 如果是，则拿到锁。 释放锁：执行完操作后，把创建的节点给删掉 如果不是，则监听比自己要小1的节点变化 举个例子： 系统A拿到/locks节点下的所有子节点，经过比较，发现自己(id_000000)，是所有子节点最小的。所以得到锁 系统B拿到/locks节点下的所有子节点，经过比较，发现自己(id_000002)，不是所有子节点最小的。所以监听比自己小1的节点id_000001的状态 系统C拿到/locks节点下的所有子节点，经过比较，发现自己(id_000001)，不是所有子节点最小的。所以监听比自己小1的节点id_000000的状态 …… 等到系统A执行完操作以后，将自己创建的节点删除(id_000000)。通过监听，系统C发现id_000000节点已经删除了，发现自己已经是最小的节点了，于是顺利拿到锁 ….系统B如上 总结: 其实如果有客户端C、客户端D等N个客户端争抢一个zk分布式锁，原理都是类似的。 大家都是上来直接创建一个锁节点下的一个接一个的临时顺序节点 如果自己不是第一个节点，就对自己上一个节点加监听器 只要上一个节点释放锁，自己就排到前面去了，相当于是一个排队机制。 临时顺序节点的另外一个用意就是，如果某个客户端创建临时顺序节点之后，不小心自己宕机了也没关系，zk感知到那个客户端宕机，会自动删除对应的临时顺序节点，相当于自动释放锁，或者是自动取消自己的排队。 集群管理经过上面几个例子，我相信大家也很容易想到ZooKeeper是怎么”感知“节点的动态新增或者删除的了 还是以我们三个系统A、B、C为例，在ZooKeeper中创建临时节点即可： ​ 只要系统A挂了，那/groupMember/A这个节点就会删除，通过监听groupMember下的子节点，系统B和C就能够感知到系统A已经挂了。(新增也是同理) 除了能够感知节点的上下线变化，ZooKeeper还可以实现动态选举Master的功能。(如果集群是主从架构模式下) 原理也很简单，如果想要实现动态选举Master的功能，Znode节点的类型是带顺序号的临时节点(EPHEMERAL_SEQUENTIAL)就好了。 Zookeeper会每次选举最小编号的作为Master，如果Master挂了，自然对应的Znode节点就会删除。然后让新的最小编号作为Master，这样就可以实现动态选举的功能了","categories":[{"name":"服务中心","slug":"服务中心","permalink":"https://jameslin23.gitee.io/categories/服务中心/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://jameslin23.gitee.io/tags/分布式/"}]},{"title":"mysql之count用法","slug":"mysql之count用法","date":"2020-12-10T11:35:17.000Z","updated":"2020-12-11T02:12:41.323Z","comments":true,"path":"2020/12/10/mysql之count用法/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/10/mysql之count用法/","excerpt":"","text":"这个常用的COUNT函数，却暗藏着很多玄机，尤其是在面试的时候，一不小心就会被虐。不信的话请尝试回答下以下问题： 1、COUNT有几种用法？ 2、COUNT(字段名)和COUNT(*)的查询结果有什么不同？ 3、COUNT(1)和COUNT(*)之间有什么不同？ 4、COUNT(1)和COUNT(*)之间的效率哪个更高？ 5、为什么《阿里巴巴Java开发手册》建议使用COUNT(*) 6、MySQL的MyISAM引擎对COUNT(*)做了哪些优化？ 7、MySQL的InnoDB引擎对COUNT(*)做了哪些优化？ 8、上面提到的MySQL对COUNT(*)做的优化，有一个关键的前提是什么？ 9、SELECT COUNT(*) 的时候，加不加where条件有差别吗？ 10、COUNT(*)、COUNT(1)和COUNT(字段名)的执行过程是怎样的？ COUNT(列名)、COUNT(常量)和COUNT(*)之间的区别COUNT(常量) 和 COUNT(*)表示的是直接查询符合条件的数据库表的行数。而COUNT(列名)表示的是查询符合条件的列的值不为NULL的行数。 COUNT(*)的优化前面提到了COUNT(*)是SQL92定义的标准统计行数的语法，所以MySQL数据库对他进行过很多优化。那么，具体都做过哪些事情呢？ 这里的介绍要区分不同的执行引擎。MySQL中比较常用的执行引擎就是InnoDB和MyISAM。 MyISAM和InnoDB有很多区别，其中有一个关键的区别和我们接下来要介绍的COUNT(*)有关，那就是MyISAM不支持事务，MyISAM中的锁是表级锁；**而InnoDB支持事务，并且支持行级锁。** 因为MyISAM的锁是表级锁，所以同一张表上面的操作需要串行进行，所以，MyISAM做了一个简单的优化，那就是它可以把表的总行数单独记录下来，如果从一张表中使用COUNT(*)进行查询的时候，可以直接返回这个记录下来的数值就可以了，当然，前提是不能有where条件。 MyISAM之所以可以把表中的总行数记录下来供COUNT(*)查询使用，那是因为MyISAM数据库是表级锁，不会有并发的数据库行数修改，所以查询得到的行数是准确的。 但是，对于InnoDB来说，就不能做这种缓存操作了，因为InnoDB支持事务，其中大部分操作都是行级锁，所以可能表的行数可能会被并发修改，那么缓存记录下来的总行数就不准确了。 但是，InnoDB还是针对COUNT(*)语句做了些优化的。 在InnoDB中，使用COUNT(*)查询行数的时候，不可避免的要进行扫表了，那么，就可以在扫表过程中下功夫来优化效率了。 从MySQL 8.0.13开始，针对InnoDB的SELECT COUNT(*) FROM tbl_name语句，确实在扫表的过程中做了一些优化。前提是查询语句中不包含WHERE或GROUP BY等条件。 我们知道，COUNT(*)的目的只是为了统计总行数，所以，他根本不关心自己查到的具体值，所以，他如果能够在扫表的过程中，选择一个成本较低的索引进行的话，那就可以大大节省时间。 我们知道，InnoDB中索引分为聚簇索引（主键索引）和非聚簇索引（非主键索引），聚簇索引的叶子节点中保存的是整行记录，而非聚簇索引的叶子节点中保存的是该行记录的主键的值。 所以，相比之下，非聚簇索引要比聚簇索引小很多，所以MySQL会优先选择最小的非聚簇索引来扫表。**所以，当我们建表的时候，除了主键索引以外，创建一个非主键索引还是有必要的。** 至此，我们介绍完了MySQL数据库对于COUNT(*)的优化，这些优化的前提都是查询语句中不包含WHERE以及GROUP BY条件。 COUNT(*)和COUNT(1)官方文档 InnoDB handles SELECT COUNT(*) and SELECT COUNT(1) operations in the same way. There is no performance difference. 所以，对于COUNT(1)和COUNT(*)，MySQL的优化是完全一样的，根本不存在谁比谁快！ 那既然COUNT(*)和COUNT(1)一样，建议用哪个呢？ 建议使用COUNT(*)！因为这个是SQL92定义的标准统计行数的语法 《阿里巴巴Java开发手册》中强制要求不让使用 COUNT(列名)或 COUNT(常量)来替代 COUNT(*)","categories":[{"name":"数据库","slug":"数据库","permalink":"https://jameslin23.gitee.io/categories/数据库/"}],"tags":[{"name":"面试经典","slug":"面试经典","permalink":"https://jameslin23.gitee.io/tags/面试经典/"}]},{"title":"mysql事务","slug":"mysql事务","date":"2020-12-10T05:44:50.000Z","updated":"2021-01-07T03:54:25.612Z","comments":true,"path":"2020/12/10/mysql事务/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/10/mysql事务/","excerpt":"","text":"事务的四大特性 原子性: 事务最小工作单位，要么全部成功,要没全部失败。 一致性: 事务开始和结束后，数据库完整性不会被破坏。 隔离性: 不同事务之间互不影响，四种隔离级别为RU(读未提交)、RC(读已提交)、RR(可重复读)、SERIALIZABLE （串行化）。 持久性: 事务提交后,对数据的修改是永久性的，即便系统故障也不会丢失。 事务的隔离级别读未提交(Read UnCommitted/RU)一个事务可以读取到另外一个事务未提交的数据。这种隔离级别是最不安全的，因为未提交的事务存在回滚。 读已提交(Read Committed/RC)一个事务因为读取到另一个事务已提交的修改数据，导致在当前事务的不同时间读取同一条数据获取的结果不一致。 可重复读(Repeatable Read/RR)（默认）当前读取此条数据只可读一次,在当前事务中,不论读取多少次，数据仍然是第一次读取的数据,不会因为在第一次读取之后，其它事务再修改提交此数据而产生改变。 串行化 事务A和事务B，事务A在操作数据库时，事务B只能排队等待 这种隔离级别很少使用，吞吐量太低，用户体验差 这种级别可以避免“幻像读”，每一次读取的都是数据库中真实存在数据，事务A与事务B串行，而不并发 出现问题脏读：当前事务可以查看到别的事务未提交的数据（侧重点在于别的事务未提交）。 幻读：幻读的表象与不可重读的表象都让人”懵逼”，很容易搞混，但是如果非要细分的话，幻读的侧重点在于新增和删除。表示在同一事务中，使用相同的查询语句，第二次查询时，莫名的多出了一些之前不存在数据，或者莫名的不见了一些数据。 不可重读：不可重读的侧重点在于更新修改数据。表示在同一事务中，查询相同的数据范围时，同一个数据资源莫名的改变了。 不同级别拥有问题 脏读 不可重读 幻读 读未提交 √ √ √ 读提交 × √ √ 可重读 × × √ 串行化 × × × LBCCLBCC，基于锁的并发控制，Lock Based Concurrency Control。 使用锁的机制,在当前事务需要对数据修改时,将当前事务加上锁,同一个时间只允许一条事务修改当前数据,其他事务务必等待锁释放之后才可以操作。 MVCCMVCC，多版本的并发控制，Multi-Version Concurrency Control。 使用版本来控制并发情况下的数据问题，在B事务开始修改账户且事务未提交时，当A事务需要读取账户余额时，此时会读取到B事务修改操作之前的账户余额的副本数据，但是如果A事务需要修改账户余额数据就必须要等待B事务提交事务。 MVCC使得数据库读不会对数据加锁，普通的SELECT请求不会加锁，提高了数据库的并发处理能力。借助MVCC，数据库可以实现READ COMMITTED，REPEATABLE READ等隔离级别，用户可以查看当前数据的前一个或者前几个历史版本，保证了ACID中的I特性（隔离性)。 InnoDB的MVCC实现逻辑InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列来实现的。一个保存了行的事务ID(DB_TRX_ID),一个保存了行的回滚指针(DB_ROLL_PT)。每开始一个新的事务,都会自动递增产生一个新ID,事务开始时刻的会把事务ID放到当前事务影响的行事务ID中,当查询时需要用当前事务id和每行记录的事务id做比较。 MVCC只在REPEATABLE READ和READ COMMITIED两个隔离级别下工作。其他两个隔离级别都和 MVCC不兼容 ，因为READ UNCOMMITIED总是读取最新的数据行，而不是符合当前事务版本的数据行。而SERIALIZABLE则会对所有读取的行都加锁。 MVCC 在mysql 中的实现依赖的是 undo log(下面会介绍) 与 read view 。 ReadViewReadView中主要包含当前系统中还有哪些活跃的读写事务，把它们的事务id放到一个列表中，我们把这个列表命名为为m_ids。 对于查询时的版本链数据是否看见的判断逻辑： 如果被访问版本的 trx_id 属性值小于 m_ids 列表中最小的事务id，表明生成该版本的事务在生成 ReadView 前已经提交，所以该版本可以被当前事务访问。 如果被访问版本的 trx_id 属性值大于 m_ids 列表中最大的事务id，表明生成该版本的事务在生成 ReadView 后才生成，所以该版本不可以被当前事务访问。 如果被访问版本的 trx_id 属性值在 m_ids 列表中最大的事务id和最小事务id之间，那就需要判断一下 trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问。 举个例子： READ COMMITTED 隔离级别下的ReadView每次读取数据前都生成一个ReadView (m_ids列表) ​ 这里分析下上面的情况下的ReadView ​ 时间点 T5 情况下的 SELECT 语句： ​ 当前时间点的版本链： ​ 此时 SELECT 语句执行，当前数据的版本链如上，因为当前的事务777，和事务888 都未提交，所以此时的活跃事务的ReadView的列表情况 m_ids：[777, 888] ，因此查询语句会根据当前版本链中小于 m_ids 中的最大的版本数据，即查询到的是 Mbappe 时间点 T8 情况下的 SELECT 语句： 当前时间的版本链情况： 此时 SELECT 语句执行，当前数据的版本链如上，因为当前的事务777已经提交，和事务888 未提交，所以此时的活跃事务的ReadView的列表情况 m_ids：[888] ，因此查询语句会根据当前版本链中小于 m_ids 中的最大的版本数据，即查询到的是 Messi。 时间点 T11 情况下的 SELECT 语句： 当前时间点的版本链信息： ​ 此时 SELECT 语句执行，当前数据的版本链如上，因为当前的事务777和事务888 都已经提交，所以此时的活跃事务的ReadView的列表为空 ，因此查询语句会直接查询当前数据库最新数据，即查询到的是 Dybala。 总结： 使用READ COMMITTED隔离级别的事务在每次查询开始时都会生成一个独立的 ReadView。 REPEATABLE READ 隔离级别下的ReadView在事务开始后读取第一次读取数据时生成一个ReadView（m_ids列表） MVCC总结：所谓的MVCC（Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用 READ COMMITTD 、REPEATABLE READ 这两种隔离级别的事务在执行普通的 SEELCT 操作时访问记录的版本链的过程，这样子可以使不同事务的 读-写 、 写-读 操作并发执行，从而提升系统性能。 在 MySQL 中， READ COMMITTED 和 REPEATABLE READ 隔离级别的的一个非常大的区别就是它们生成 ReadView 的时机不同。在 READ COMMITTED 中每次查询都会生成一个实时的 ReadView，做到保证每次提交后的数据是处于当前的可见状态。而 REPEATABLE READ 中，在当前事务第一次查询时生成当前的 ReadView，并且当前的 ReadView 会一直沿用到当前事务提交，以此来保证可重复读（REPEATABLE READ）。 事务日志redo logredo log叫做重做日志，是用来实现事务的持久性。该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log）,前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都会存到该日志中。假设有个表叫做tb1(id,username) 现在要插入数据（3，ceshi） 123456start transaction;select balance from bank where name=&quot;zhangsan&quot;;// 生成 重做日志 balance=600update bank set balance = balance - 400; // 生成 重做日志 amount=400update finance set amount = amount + 400; 作用: mysql 为了提升性能不会把每次的修改都实时同步到磁盘，而是会先存到Boffer Pool(缓冲池)里头，把这个当作缓存来用。然后使用后台线程去做缓冲池和磁盘之间的同步。 那么问题来了，如果还没来的同步的时候宕机或断电了怎么办？还没来得及执行上面图中红色的操作。这样会导致丢部分已提交事务的修改信息！ 所以引入了redo log来记录已成功提交事务的修改信息，并且会把redo log持久化到磁盘，系统重启之后在读取redo log恢复最新数据。 总结：redo log是用来恢复数据的，用于保障，已提交事务的持久化特性（记录了已经提交的操作） undo log?undo log 叫做回滚日志，用于记录数据被修改前的信息。他正好跟前面所说的重做日志所记录的相反，重做日志记录数据被修改后的信息。undo log主要记录的是数据的逻辑变化，为了在发生错误时回滚之前的操作，需要将之前的操作都记录下来，然后在发生错误时才可以回滚。 还用上面那两张表 每次写入数据或者修改数据之前都会把修改前的信息记录到 undo log。 作用: undo log 记录事务修改之前版本的数据信息，因此假如由于系统错误或者rollback操作而回滚的话可以根据undo log的信息来进行回滚到没被修改前的状态。 总结:undo log是用来回滚数据的用于保障，未提交事务的原子性","categories":[{"name":"数据库","slug":"数据库","permalink":"https://jameslin23.gitee.io/categories/数据库/"}],"tags":[{"name":"事务","slug":"事务","permalink":"https://jameslin23.gitee.io/tags/事务/"}]},{"title":"Memcache","slug":"Memcache","date":"2020-12-09T12:50:10.000Z","updated":"2020-12-09T12:58:08.010Z","comments":true,"path":"2020/12/09/Memcache/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/09/Memcache/","excerpt":"","text":"memchache特点 MC处理请求时使用多线程异步IO方法，可以合理利用CPU多核的优势，性能非常优秀。 MC功能简单，使用内存存储数据 MC 对缓存的数据可以设置失效期，过期后的数据会被清除； 失效的策略采用延迟失效，就是当再次使用数据时检查是否失效； 当容量存满时，会对缓存中的数据进行剔除，剔除时除了会对过期 key 进行清理，还会按 LRU 策略对数据进行剔除。 缺陷 key不能超过250个字节 value不能超过1M字节 key的最大失效时间是30天 只支持K-V结构，不能供持久化和主从同步功能 没有原生的集群模式，需要依靠客户端来实现集群中分片写数据。","categories":[{"name":"Nosql","slug":"Nosql","permalink":"https://jameslin23.gitee.io/categories/Nosql/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://jameslin23.gitee.io/tags/缓存/"}]},{"title":"redis面试专题","slug":"redis面试专题","date":"2020-12-09T00:55:02.000Z","updated":"2020-12-10T05:45:26.452Z","comments":true,"path":"2020/12/09/redis面试专题/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/09/redis面试专题/","excerpt":"","text":"一、redis用了哪些数据结构？适用哪些场景二、redis是单线程，为什么不使用多线程？三、redis持久化机制？四、redis哨兵模式如何实现故障转移？五、穿透，击穿，雪崩如何解决六、谈一谈redis分布式锁?七、你了解最经典的KV、DB读写模式么？八、为什么是删除缓存，而不是更新缓存？九、Redis 和 Memcached 有啥区别，为啥选择用Redis作为你们的缓存中间件？十、假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？ 使用 keys 指令可以扫出指定模式的 key 列表。但是要注意 keys 指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 scan 指令，scan 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 keys 指令长。 十一、跳跃表是如何实现的？原理？本质是解决查找问题 因为是有序链表，无法使用二分查找，我们需要从头开始遍历查找，导致时间复杂度(n) 思想: 是一种特殊的数据结构，多层链表结构设计思想，不同节点有不同的高度，当查找的时候可以实现跳跃查找。 这样方便加快查询速度。 十二、Redis 的 SDS 和 C 中字符串相比有什么优势？SDS动态字符串 12345struct sdshdr&#123; int len; int free; char buf[];&#125; 计数方式不同 杜绝缓冲区溢出 减少修改字符串时带来的内存重分配次数 二进制安全","categories":[{"name":"Nosql","slug":"Nosql","permalink":"https://jameslin23.gitee.io/categories/Nosql/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://jameslin23.gitee.io/tags/缓存/"}]},{"title":"redis分布式锁","slug":"redis分布式锁","date":"2020-12-07T12:01:38.000Z","updated":"2020-12-09T02:23:36.865Z","comments":true,"path":"2020/12/07/redis分布式锁/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/07/redis分布式锁/","excerpt":"","text":"分布式锁什么是分布式锁?分布式锁就是控制分布式系统或不同系统之间共同访问共享资源的一种锁实现,如果不同的系统或同一个系统的不同主机之间共享了某个资源时，往往需要互斥来防止彼此干扰来保证一致性。 分布式锁需要具备哪些条件 互斥性:在任意一个时刻,只有一个客户端持有锁 无死锁:即便持有锁的客户端崩溃或者其他意外事件,锁仍然可以被获取。 容错:只要大部分redis节点都活着,客户端就可以获取锁和释放锁 分布式锁实现有哪些？ 数据库 Memcached（add命令） Redis（setnx命令） Zookeeper（临时节点） 分布式锁实现SET key value NX假设有两个客户端A和B，A获取到分布式的锁。A执行了一会，突然A所在的服务器断电了（或者其他什么的），也就是客户端A挂了。这时出现一个问题，这个锁一直存在，且不会被释放，其他客户端永远获取不到锁。如下示意图 SET lockKey value NX EX 30注: 要保证设置过期时间和设置锁具有原子性 此时又出现一个问题,过程如下 客户端A获取锁成功,过期时间30秒 客户端A在某个程序上阻塞了50秒 30秒时间到了，锁自动释放了 客户端B获取对应同一资源的锁 客户端A从阻塞恢复过来,释放掉了客户端B持有的锁 这时会有两个问题 过期时间如何保证大于业务执行时间? 如何保证锁不会被误删除? 先来解决如何保证锁不会被误删除这个问题。 这个问题可以通过设置value为当前客户端生成的一个随机字符串，且保证在足够长的一段时间内在所有客户端的所有获取锁的请求中都是唯一的。 lua脚本释放锁具备原子性123456789public void unlock() &#123; // 使用lua脚本进行原子删除操作 String checkAndDelScript = \"if redis.call('get', KEYS[1]) == ARGV[1] then \" + \"return redis.call('del', KEYS[1]) \" + \"else \" + \"return 0 \" + \"end\"; jedis.eval(checkAndDelScript, 1, lockKey, lockValue); &#125; Redisson实现分布式锁Redisson原理 加锁机制 线程去获取锁,获取成功:执行lua脚本,保存数据到redis数据库 线程去获取锁,获取失败:一直通过while循环尝试获取锁,获取成功后，执行lua脚本，保存数据到redis数据库 watch dog自动延期机制 它的作用就是 线程1 业务还没有执行完，锁时间就过了，线程1 还想持有锁的话，就会启动一个watch dog后台线程，不断的延长锁key的生存时间。 LUA脚本 主要是如果你的业务逻辑复杂的话，通过封装在lua脚本中发送给redis，而且redis是单线程的，这样就保证这段复杂业务逻辑执行的原子性。 可重入锁 Hash数据类型的key值包含了当前线程信息。 下面是redis存储的数据 这里表面数据类型是Hash类型,Hash类型相当于我们java的 &lt;key,&lt;key1,value&gt;&gt; 类型,这里key是指 ‘redisson’ 它的有效期还有9秒，我们再来看里们的key1值为078e44a3-5f95-4e24-b6aa-80684655a15a:45它的组成是: guid + 当前线程的ID。后面的value是就和可重入加锁有关。 举图说明 上面这图的意思就是可重入锁的机制，它最大的优点就是相同线程不需要在等待锁，而是可以直接进行相应操作。 Redis分布式锁缺陷Redis分布式锁会有个缺陷，就是在Redis哨兵模式下: 客户端1 对某个master节点写入了redisson锁，此时会异步复制给对应的 slave节点。但是这个过程中一旦发生 master节点宕机，主备切换，slave节点从变为了 master节点。 这时客户端2 来尝试加锁的时候，在新的master节点上也能加锁，此时就会导致多个客户端对同一个分布式锁完成了加锁。 这时系统在业务语义上一定会出现问题，导致各种脏数据的产生。 缺陷在哨兵模式或者主从模式下，如果 master实例宕机的时候，可能导致多个客户端同时完成加锁。 RLock接口Redisson分布式锁是基于RLock接口,RedissonLock实现RLock接口。 1public interface RLock extends Lock, RExpirable, RLockAsync 很明显RLock是继承Lock锁,所以他有Lock锁的所有特征,比如lock,unlock,trylock等特征，同时它很多新特性:强制锁释放,带有效期的锁。 RLock锁API12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public interface RLock &#123; //----------------------Lock接口方法----------------------- /** * 加锁 锁的有效期默认30秒 */ void lock(); /** * tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false . */ boolean tryLock(); /** * tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间， * 在时间期限之内如果还拿不到锁，就返回false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。 * * @param time 等待时间 * @param unit 时间单位 小时、分、秒、毫秒等 */ boolean tryLock(long time, TimeUnit unit) throws InterruptedException; /** * 解锁 */ void unlock(); /** * 中断锁 表示该锁可以被中断 假如A和B同时调这个方法，A获取锁，B为获取锁，那么B线程可以通过 * Thread.currentThread().interrupt(); 方法真正中断该线程 */ void lockInterruptibly(); //----------------------RLock接口方法----------------------- /** * 加锁 上面是默认30秒这里可以手动设置锁的有效时间 * * @param leaseTime 锁有效时间 * @param unit 时间单位 小时、分、秒、毫秒等 */ void lock(long leaseTime, TimeUnit unit); /** * 这里比上面多一个参数，多添加一个锁的有效时间 * * @param waitTime 等待时间 * @param leaseTime 锁有效时间 * @param unit 时间单位 小时、分、秒、毫秒等 */ boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException; /** * 检验该锁是否被线程使用，如果被使用返回True */ boolean isLocked(); /** * 检查当前线程是否获得此锁（这个和上面的区别就是该方法可以判断是否当前线程获得此锁，而不是此锁是否被线程占有） * 这个比上面那个实用 */ boolean isHeldByCurrentThread(); /** * 中断锁 和上面中断锁差不多，只是这里如果获得锁成功,添加锁的有效时间 * @param leaseTime 锁有效时间 * @param unit 时间单位 小时、分、秒、毫秒等 */ void lockInterruptibly(long leaseTime, TimeUnit unit); &#125; RedissonLock实现类1public class RedissonLock extends RedissonExpirable implements RLock void lock()方法12345678@Overridepublic void lock() &#123; try &#123; lockInterruptibly(); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); &#125;&#125; 发现lock锁里面进去其实用的是lockInterruptibly(中断锁,表示可以被中断),而且捕获异常后用Thread.currentThread().interupt()来真正中断当前线程,其实它们是搭配一起使用的 1234567891011121314151617181920212223242526272829303132333435/** * 1、带上默认值调另一个中断锁方法 */ @Override public void lockInterruptibly() throws InterruptedException &#123; lockInterruptibly(-1, null); &#125; /** * 2、另一个中断锁的方法 */ void lockInterruptibly(long leaseTime, TimeUnit unit) throws InterruptedException /** * 3、这里已经设置了锁的有效时间默认为30秒 （commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout()=30） */ RFuture&lt;Long&gt; ttlRemainingFuture = tryLockInnerAsync(commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG); /** * 4、最后通过lua脚本访问Redis,保证操作的原子性 */ &lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123; internalLockLeaseTime = unit.toMillis(leaseTime); return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command, \"if (redis.call('exists', KEYS[1]) == 0) then \" + \"redis.call('hset', KEYS[1], ARGV[2], 1); \" + \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + \"return nil; \" + \"end; \" + \"if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then \" + \"redis.call('hincrby', KEYS[1], ARGV[2], 1); \" + \"redis.call('pexpire', KEYS[1], ARGV[1]); \" + \"return nil; \" + \"end; \" + \"return redis.call('pttl', KEYS[1]);\", Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId)); &#125; tryLock(long waitTime,long leaseTime,TimeUnit unit)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Override public boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException &#123; long time = unit.toMillis(waitTime); long current = System.currentTimeMillis(); long threadId = Thread.currentThread().getId(); Long ttl = tryAcquire(leaseTime, unit, threadId); //1、 获取锁同时获取成功的情况下，和lock(...)方法是一样的 直接返回True，获取锁False再往下走 if (ttl == null) &#123; return true; &#125; //2、如果超过了尝试获取锁的等待时间,当然返回false 了。 time -= System.currentTimeMillis() - current; if (time &lt;= 0) &#123; acquireFailed(threadId); return false; &#125; // 3、订阅监听redis消息，并且创建RedissonLockEntry，其中RedissonLockEntry中比较关键的是一个 Semaphore属性对象,用来控制本地的锁请求的信号量同步，返回的是netty框架的Future实现。 final RFuture&lt;RedissonLockEntry&gt; subscribeFuture = subscribe(threadId); // 阻塞等待subscribe的future的结果对象，如果subscribe方法调用超过了time，说明已经超过了客户端设置的最大wait time，则直接返回false，取消订阅，不再继续申请锁了。 // 只有await返回true，才进入循环尝试获取锁 if (!await(subscribeFuture, time, TimeUnit.MILLISECONDS)) &#123; if (!subscribeFuture.cancel(false)) &#123; subscribeFuture.addListener(new FutureListener&lt;RedissonLockEntry&gt;() &#123; @Override public void operationComplete(Future&lt;RedissonLockEntry&gt; future) throws Exception &#123; if (subscribeFuture.isSuccess()) &#123; unsubscribe(subscribeFuture, threadId); &#125; &#125; &#125;); &#125; acquireFailed(threadId); return false; &#125; //4、如果没有超过尝试获取锁的等待时间，那么通过While一直获取锁。最终只会有两种结果 //1)、在等待时间内获取锁成功 返回true。2）等待时间结束了还没有获取到锁那么返回false。 while (true) &#123; long currentTime = System.currentTimeMillis(); ttl = tryAcquire(leaseTime, unit, threadId); // 获取锁成功 if (ttl == null) &#123; return true; &#125; // 获取锁失败 time -= System.currentTimeMillis() - currentTime; if (time &lt;= 0) &#123; acquireFailed(threadId); return false; &#125; &#125; &#125; tryLock一般用于特定满足需求的场合,但不建议作为一般需求的分布式锁，一般分布式锁建议用void lock(long leaseTime,TimeUnit unit)。因此性能上考虑，在高并发情况下后者效率是前者的好几倍。 unlock()123456789101112131415161718192021222324252627282930313233343536@Override public void unlock() &#123; // 1.通过 Lua 脚本执行 Redis 命令释放锁 Boolean opStatus = commandExecutor.evalWrite(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, \"if (redis.call('exists', KEYS[1]) == 0) then \" + \"redis.call('publish', KEYS[2], ARGV[1]); \" + \"return 1; \" + \"end;\" + \"if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then \" + \"return nil;\" + \"end; \" + \"local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); \" + \"if (counter &gt; 0) then \" + \"redis.call('pexpire', KEYS[1], ARGV[2]); \" + \"return 0; \" + \"else \" + \"redis.call('del', KEYS[1]); \" + \"redis.call('publish', KEYS[2], ARGV[1]); \" + \"return 1; \"+ \"end; \" + \"return nil;\", Arrays.&lt;Object&gt;asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(Thread.currentThread().getId())); // 2.非锁的持有者释放锁时抛出异常 if (opStatus == null) &#123; throw new IllegalMonitorStateException( \"attempt to unlock lock, not locked by current thread by node id: \" + id + \" thread-id: \" + Thread.currentThread().getId()); &#125; // 3.释放锁后取消刷新锁失效时间的调度任务 if (opStatus) &#123; cancelExpirationRenewal(); &#125; &#125; 使用EVAL命令执行Lua脚本来释放锁: key 不存在,说明锁已经释放,直接执行public命令发布释放锁消息并返回1 key存在,但field在 Hash 中不存在，说明自己不是锁持有者，无权释放锁，返回 nil。 因为锁可重入,所以释放锁时不能把所有已获取的锁全部释放掉,一次只能释放一把锁,因此执行hincrby对锁的值减1。 释放一把锁后，如果还有剩余的锁,则刷新锁的失效时间并返回0；如果刚才释放的已经是最后一把锁，则执行 del 命令删除锁的 key，并发布锁释放消息，返回 1。 注意这里有个实际开发过程中，容易出现很容易出现上面第二步异常，非锁的持有者释放锁时抛出异常。比如下面这种情况 12345678910//设置锁1秒过去 redissonLock.lock(\"redisson\", 1); /** * 业务逻辑需要咨询2秒 */ redissonLock.release(\"redisson\"); /** * 线程1 进来获得锁后，线程一切正常并没有宕机，但它的业务逻辑需要执行2秒，这就会有个问题，在 线程1 执行1秒后，这个锁就自动过期了， * 那么这个时候 线程2 进来了。在线程1去解锁就会抛上面这个异常（因为解锁和当前锁已经不是同一线程了） */","categories":[{"name":"Nosql","slug":"Nosql","permalink":"https://jameslin23.gitee.io/categories/Nosql/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://jameslin23.gitee.io/tags/缓存/"}]},{"title":"redis缓存故障","slug":"redis缓存故障","date":"2020-12-07T06:25:23.000Z","updated":"2020-12-07T12:03:56.269Z","comments":true,"path":"2020/12/07/redis缓存故障/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/07/redis缓存故障/","excerpt":"","text":"缓存穿透缓存穿透的概念,用户想查询一个数据，发现Redis没有，也就是缓存没有命中，于是向持久层数据库查询。发现也没有，于是本次查询失败。当用户很多时候，缓存都没有命中，于是都去请求了持久层数据库。这个给持久层数据库造成很多的压力。 解决方法: 1、缓存空对象 当存储层不命中时,即使返回空对象也将其缓存起来,设置一个过期时间，之后再访问这个数据将会从缓存中获取，保护了后端数据源 但是这种方法会存在两个问题： 1、缓存区可能存在大量空值的键 2、可能会存在缓存层和存储层会有一段时间空窗不一致，对保持一致性的业务会有影响 2、布隆过滤器 在查询缓存之间先在到布隆过滤器查询，没有则返回，有再走redis，DB查询操作 布隆过滤器原理 本质上布隆过滤器是一个数据结构,比较巧妙的概率型数据结构,特点高效的插入和查询。 根据查询结果可以用来告诉你某样东西一定不存在或者可能存在。这句话是算法的核心。 相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的，同时布隆过滤器还有一个缺陷就是数据只能插入不能删除。 数据如何存入布隆过滤器 布隆过滤器是由一个很长的bit数组和一系列哈希函数组成的 数组的每个元素都只占1bit空间,并且每个元素只能0或者1 布隆过滤器还拥有k个哈希函数,当一个元素加入布隆过滤器时,会使用k个函数对其进行k次计算，得到k个哈希值，并且根据得到哈希值,在维数据对应下标的值置位1。 判断某个数是否在布隆过滤器中，就对该元素进行k次哈希计算，得到的值在位数组中判断每个元素是否都为1，如果每个元素都为1，就说明这个值在布隆过滤器中。 布隆过滤器为什么会有误判 当插入元素越来越多时,当一个不在布隆过滤器中的元素,经过同样规则哈希计算后，得到的值在位数据组中查询，有可能这些位置被其它元素先置为1了。 所以布隆过滤器存在误判的情况。 但如果布隆过滤器判断某个元素不在布隆过滤器中，那么这个值就一定不在。 使用场景 网页爬虫对URL的去重 垃圾邮件过滤 解决数据库缓存击穿 秒杀系统 缓存击穿这里需要注意和缓存穿透的区别。缓存穿透，是指一个key非常热点,在不停的扛着大并发,大并发集中对这个点进行访问，当这个key在失效的瞬间,持续的大并发就穿破缓存,直接请求数据库，就像一个屏幕凿开一个洞。 当某个key在过期的瞬间,有大量的请求并发访问,这类数据一般是热点数据,由于缓存过期，会同时访问数据库来查询最新的数据，并回写缓存，会导致数据库压力过大。 解决方法： 1、设置热点数据永不过期 2、加互斥锁 分布式锁:使用分布式锁,保证了对每个Key只有一个线程去查询后端服务,其它线程没有获得分布式锁的权限，因此只需要等待即可。 缓存雪崩缓存雪崩,是指在某一个时间段,缓存集中过期失效（或者redis宕机）。 比如马上就双12零点,很快就会有一波抢购，这波抢购商品比较集中的放在redis，假设缓存一个小时，那么到凌晨一点钟，这批缓存就都过期了，而对这批商品的访问查询,都落在数据库上，对于数据库而言，都会产生周期性的压力波峰。于是所有的请求都会到达存储层，存储层的调用量会暴增，造成存储层也回掉的情况 解决方案： 1、redis高可用 这个思想的含义是，既然 redis 有可能挂掉，那我多增设几台 redis，这样一台挂掉之后其他的还可以继续工作，其实就是搭建的集群。 2、限流降级 这个解决方案的思想是，在缓存失效后，通过加锁或者队列来控制数据库写缓存的线程数量。比如对某个 key 只允许一个线程查询数据和写缓存，其他线程等待。 3、数据预热 数据预热的含义是在正式部署之前，把可能的数据线预先访问一遍，这样部分可能大量访问的数据就会加载到缓存。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀","categories":[{"name":"Nosql","slug":"Nosql","permalink":"https://jameslin23.gitee.io/categories/Nosql/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://jameslin23.gitee.io/tags/缓存/"}]},{"title":"redis哨兵模式","slug":"redis哨兵模式","date":"2020-12-05T06:55:30.000Z","updated":"2020-12-09T13:03:05.731Z","comments":true,"path":"2020/12/05/redis哨兵模式/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/05/redis哨兵模式/","excerpt":"","text":"哨兵模式Sentinel(哨兵)是redis的高可用性解决方案:由一个或者多个Sentinel实例组成的Sentinel系统可以监视任意多个主服务器以及这些主服务器属下所有从服务器，并在被监视的主服务器进入下线状态时,自动将下线主服务器属下的某个从服务器升级为新的服务器，然后由新的主服务器代替已下线的主服务器继续处理请求命令,他主要功能如下: 监控(Monitoring)：Sentinel会不断地检查你的主服务器和从服务器是否运作正常。 通知(Notification)：当被监控的某个 Redis 服务器出现问题时， Sentinel可以通过API向管理员或者其他应用程序发送通知。 故障迁移：当主服务器不能正常工作时，Sentinel会自动进行故障迁移，也就是主从切换。 统一的配置管理：连接者询问sentinel取得主从的地址。 哨兵原理Sentinel 使用核心算法是Raft算法,主要用途就是用于分布式系统,系统容错以及Leader选举,每个Sentinel都需要定期的执行以下任务: 主观下线(一个Sentinel判断) 在默认情况下,Sentinel会以每秒一次的频率像所有与它创建了命令连接的实例(包括主服务器,从服务器,其它Sentinel在内)发送PING命令回复来判断实例是否在线。 实例对PING命令的回复可以分为以下两种情况： 有效回复:实例返回+PONG,-LOADING、-MASTERDOWN三种回复其中一种。 无效回复:有效回复之外的其它三种回复或者在指定时限内没有任何回复。 客观下线 当Sentinel将一个主服务器判断为主观下线之后,为了确认这个主服务器是否真的下线了,它会向同样监视这个主服务器的其他Sentinel进行询问,看他们是否也认为主服务器已经进入下线状态,当Sentinel从其他Sentinel那里接收到足够数量的已经判断下线之后,Sentinel就会将服务器判断为客观下线,并对主服务器执行故障转移。 如何从主机选取主机 故障转移操作的第一步 要做的就是在已下线主服务器属下的所有从服务器中，挑选出一个状态良好、数据完整的从服务器，然后向这个从服务器发送 slaveof no one 命令，将这个从服务器转换为主服务器。但是这个从服务器是怎么样被挑选出来的呢？ 在失效主服务器属下的从服务器当中， 那些被标记为主观下线、已断线、或者最后一次回复 PING 命令的时间大于五秒钟的从服务器都会被 淘汰。 在失效主服务器属下的从服务器当中， 那些与失效主服务器连接断开的时长超过 down-after 选项指定的时长十倍的从服务器都会被 淘汰。 在 经历了以上两轮淘汰之后 剩下来的从服务器中， 我们选出 复制偏移量（replication offset）最大 的那个 从服务器 作为新的主服务器；如果复制偏移量不可用，或者从服务器的复制偏移量相同，那么 带有最小运行 ID 的那个从服务器成为新的主服务器。 部署配置文件详解 哨兵的配置主要就是修改sentinel.conf配置文件中的参数，在Redis安装目录即可看到此配置文件，各参数详解如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 哨兵sentinel实例运行的端口，默认26379 port 26379 # 哨兵sentinel的工作目录 dir ./ # 是否开启保护模式，默认开启。 protected-mode no # 是否设置为后台启动。 daemonize yes # 哨兵sentinel的日志文件 logfile:./sentinel.log # 哨兵sentinel监控的redis主节点的 ## ip：主机ip地址 ## port：哨兵端口号 ## master-name：可以自己命名的主节点名字（只能由字母A-z、数字0-9 、这三个字符&quot;.-_&quot;组成。） ## quorum：当这些quorum个数sentinel哨兵认为master主节点失联 那么这时 客观上认为主节点失联了 # sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt; sentinel monitor mymaster 127.0.0.1 6379 2 # 当在Redis实例中开启了requirepass，所有连接Redis实例的客户端都要提供密码。 # sentinel auth-pass &lt;master-name&gt; &lt;password&gt; sentinel auth-pass mymaster 123456 # 指定主节点应答哨兵sentinel的最大时间间隔，超过这个时间，哨兵主观上认为主节点下线，默认30秒 # sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt; sentinel down-after-milliseconds mymaster 30000 # 指定了在发生failover主备切换时，最多可以有多少个slave同时对新的master进行同步。这个数字越小，完成failover所需的时间就越长；反之，但是如果这个数字越大，就意味着越多的slave因为replication而不可用。可以通过将这个值设为1，来保证每次只有一个slave，处于不能处理命令请求的状态。 # sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt; sentinel parallel-syncs mymaster 1 # 故障转移的超时时间failover-timeout，默认三分钟，可以用在以下这些方面： ## 1. 同一个sentinel对同一个master两次failover之间的间隔时间。 ## 2. 当一个slave从一个错误的master那里同步数据时开始，直到slave被纠正为从正确的master那里同步数据时结束。 ## 3. 当想要取消一个正在进行的failover时所需要的时间。 ## 4.当进行failover时，配置所有slaves指向新的master所需的最大时间。不过，即使过了这个超时，slaves依然会被正确配置为指向master，但是就不按parallel-syncs所配置的规则来同步数据了 # sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt; sentinel failover-timeout mymaster 180000 # 当sentinel有任何警告级别的事件发生时（比如说redis实例的主观失效和客观失效等等），将会去调用这个脚本。一个脚本的最大执行时间为60s，如果超过这个时间，脚本将会被一个SIGKILL信号终止，之后重新执行。 # 对于脚本的运行结果有以下规则： ## 1. 若脚本执行后返回1，那么该脚本稍后将会被再次执行，重复次数目前默认为10。 ## 2. 若脚本执行后返回2，或者比2更高的一个返回值，脚本将不会重复执行。 ## 3. 如果脚本在执行过程中由于收到系统中断信号被终止了，则同返回值为1时的行为相同。 # sentinel notification-script &lt;master-name&gt; &lt;script-path&gt; sentinel notification-script mymaster /var/redis/notify.sh # 这个脚本应该是通用的，能被多次调用，不是针对性的。 # sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt; sentinel client-reconfig-script mymaster /var/redis/reconfig.sh 对应配置修改 123456789101112131415161718# 端口默认为26379。 port:26379 # 关闭保护模式，可以外部访问。 protected-mode:no # 设置为后台启动。 daemonize yes # 日志文件。 logfile &quot;/data/redis/redis-5.0.7/logs/sentinel.log&quot;# 指定主机IP地址和端口，并且指定当有2台哨兵认为主机挂了，则对主机进行容灾切换。 sentinel monitor mymaster 192.168.10.8 6379 2 # 当在Redis实例中开启了requirepass，这里就需要提供密码。 sentinel auth-pass mymaster 123456 # 这里设置了主机多少秒无响应，则认为挂了。 sentinel down-after-milliseconds mymaster 3000 # 主备切换时，最多有多少个slave同时对新的master进行同步，这里设置为默认的1。 snetinel parallel-syncs mymaster 1 # 故障转移的超时时间，这里设置为三分钟。 sentinel failover-timeout mymaster 180000 启动三个哨兵： cd /data/redis/redis-5.0.7/bin redis-sentinel ../conf/sentinel.conf 查看状态 redis-cli -p 26379 info sentinel","categories":[{"name":"Nosql","slug":"Nosql","permalink":"https://jameslin23.gitee.io/categories/Nosql/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://jameslin23.gitee.io/tags/缓存/"}]},{"title":"redis主从复制","slug":"redis主从复制","date":"2020-12-05T02:24:07.000Z","updated":"2020-12-07T03:02:06.269Z","comments":true,"path":"2020/12/05/redis主从复制/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/05/redis主从复制/","excerpt":"","text":"概念主从复制,是指将一台Redis服务器的数据,复制到其它的Redis服务器。前称为主节点(master),后者称为从节点(slave);数据的复制是当向的。只能由主节点到从节点。Master负责写，Slave以读为主。 主从复制的作用主要包括: 数据冗余: 主从复制实现了数据的热备份，是持久化之外的一种数据冗余方法 故障恢复: 当节点出现问题时,可以由从节点提供服务器,实现快速故障恢复 负载均衡: 在主从复制的基础上,配合读写分离,可以由节点提供些服务,由从节点提供读服务(即写redis数据时应用连接主节点，读Redis数据时应用连接从节点),分担服务器负载；尤其是在写少读多的场景，通过多个节点分担读负载,可以大大提高Redis服务的并发量 缺点 当主节点宕机时,需要自己手动恢复，当恢复不及时会造成线上故障 旧版复制原理Redis的复制功能分为同步(sync) 和命令传播(command propagete)两个状态: 同步操作用于将从服务器的数据库状态更新至主服务器当前所处的数据库状态 命令传播操作则用于主服务器的数据库状态被修改,导致主从服务器的数据库状态出现不一致时，让主从服务器状态重新回到一致状态。 同步操作从服务对主服务器的同步操作需要通过向主服务器发送SYNC命令来完成,以下是SYNC命令的执行步骤: 1) 从服务器向主服务器发送SYNC命令 2) 收到SYNC命令的主服务器执行BGSAVE命令,在后台生成一个RDB文件,并使用一个缓冲区记录从现在开始执行的所有写命令。 3) 当主服务器BGSAVE执行完毕，主服务器会将从BGSAVE生成RDB文件发送给从服务器，从服务器接收并载入这个RDB文件,将自己的数据库更新至主服务器执行BGSAVE命令时的数据库状态。 4) 主服务器将记录在缓冲区里面的所有命令发送给从服务器，从服务器执行这些写命令，将自己的数据库状态更新至主服务器数据库当前所处的状态。 同步过程 命令传播在同步操作执行完毕之后,主从服务器两者的数据库将达到一致状态，但这种一致并不是一成不变的，每当主服务器执行客户端发送的写命令时，主服务器的数据库就有可能会被修改，并导致主从服务器状态不再一致。 举个例子 假设一个主服务器和一个从服务器刚刚完成同步操作，他们的数据库都保存了相同的5个键k1至k5,如果这时候，客户端向主服务器发送命令DEL K3,那么主服务器在执行完成这个DEL K3之后，主从服务器状态出现不一致。 为了让主从服务器再次回到一致状态，主服务器需要对服务器执行命令传播操作，主服务器会将自己执行命令操作发送给从服务器，让主从服务器再次回到一致。 旧版复制缺陷在redis中,从服务器对主服务器复制可以分以下2种情况 初次复制： 从服务器以前没有复制过任何主服务器，或者从服务器当前要复制的主服务器和上次复制的主服务器不同。 断线后重新复制： 处于命令传播阶段的主从服务器因为网络原因中断复制，但从服务器通过自动重连重新连上主服务器，并继续复制服务器。 但对于旧版初次复制，能够很好的完成任务，但对于断线后复制来说，旧版本复制让主从服务器重新回到一致状态，效率很低。 断开期间，主从增加3个命令（现实实际不止），从服务器发送SYNC,却从K1-K5生成RDB，实际K1,K2是没必要，如果命令多，这部分造成很大资源浪费，效率低下。Redis2.8版本开始，使用PSYNC命令代替SYNC命令来执行复制时的同步同步操作。 新版复制原理PSYNC命令PSYNC命令具有完整同步和部分重同步 其中完整重同步用于处理初次复制情况:完整同步的执行步骤和SYNC命令的执行步骤基本一样，他们都是通过主服务器创建并发送RDB文件,以及向从服务器发送保存的缓冲区里面的写命令进行同步。 而部分同步则用于处理断线后重复情况:当从服务器在断线后重新连接主服务器时，如果条件允许，主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器,从服务器只要接收并执行这些写命令,就可以将数据库更新至主服务器当前所处状态。 部分同步的实现部分同步功能由以下部分构成: 主服务器的复制偏移量和从服务器的复制偏移量 主服务器的复制积压缓冲区 服务器的运行ID 复制偏移量执行复制双方——主服务器和从服务器会分别维护一个复制偏移量 主服务器每次向从服务器传播N个字节的数据，就将自己的复制偏移量的值加上N 从服务器每次收到主服务器传播来N个字节的数据时，就将自己复制偏移量的值加上N 通过对比主从服务器的复制偏移量,程序可以很容易地知道主从服务器是否处于一致状态: 如果主从服务器处于一致状态，那么主从服务器两者的偏移量总是相同 相反,如果主从服务器两者的偏移量并不相同,那么说明状态不一致。 复制积压缓冲区复制积压缓冲区是由主从服务器维护的一个固定长度先进先出队列,默认大小为1MB 当主服务器进行命令传播时,他不仅会将命令发送给所有从服务器,还会将写命令入队列到复制积压缓冲区里面。 因此,主服务器的复制积压缓冲区里面会保存着一份最近传播的写命令,并且复制积压缓冲区会为队列中每个字节记录相应的复制偏移量 过程 当服务器断线之后,它立即重新连接主服务器,并向主服务器发送PSYNC命令,报告自己的复制偏移量10086。 当服务器收到从服务器发来PSYNC命令以及偏移量10086之后的数据是否在于复制积压缓冲区里面,结果发现这些数据依然存在， 于是主服务器向从服务器发送+CONTINUE回复，表示数据同步以部分同步模式。 接着主服务器会将复制积压缓冲区10086偏移之后所有数据都发给从服务器 从服务器只要接收这33字节缺失数据,就可以回到主服务器一致状态。 服务器运行ID除了复制偏移量和复制积压缓冲区之外,实现部分同步还需要用到服务器运行状态ID 每个redis服务器,不论主服务器还是从服务器,都会有自己的运行ID 运行ID在服务器启动时自动生成,由40个随机的16进制字符组成 当从服务器对主服务器进行初次复制,主服务器会将自己的运行ID传给从服务器,而从服务器则会将这个运行ID保存起来。 当从服务器断线并且重新连上一个主服务器时，从服务器将像当前连接主服务器发送之前保存的运行ID 如果从服务器保存的运行ID和当前连接的主服务器运行ID相同，主服务器可以尝试执行部分同步。 相反，ID不相同，则对从服务器执行完全同步。 Redis安装单机版安装 下载安装包 wget http://download.redis.io/releases/redis-5.0.7.tar.gz 解压 tar -xvf redis-5.0.7.tar.gz 编译 (1) cd redis-5.0.7/ (2) make (3) cd src/ (4) make instal 整理配置文件和启动文件 (1) mkdir conf (2) mkdir bin (3) 将redis.conf 和sentinel.conf 放入conf (4) 进入src目录,将mkreleasehdr.sh、redis-benchmark、redis-check-aof、redis-check-rdb、redis-cli、redis-server、redis-sentinel文件复制到 bin 文件夹 (5) cp mkreleasehdr.sh redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-server redis-sentinel ../bin/ 启动 ./redis-server ../conf/redis.conf 主从配置首先看一下redis.conf 配置文件中的各个参数，详解如下 123456789101112131415161718192021222324252627282930313233343536373839404142# redis进程是否以守护进程的方式运行，yes为是，no为否(不以守护进程的方式运行会占用一个终端)。 daemonize no # 指定redis进程的PID文件存放位置 pidfile /var/run/redis.pid # redis进程的端口号 port 6379 #是否开启保护模式，默认开启。要是配置里没有指定bind和密码。开启该参数后，redis只会本地进行访问，拒绝外部访问。要是开启了密码和bind，可以开启。否则最好关闭设置为no。 protected-mode yes # 绑定的主机地址 bind 127.0.0.1 # 客户端闲置多长时间后关闭连接，默认此参数为0即关闭此功能 timeout 300 # redis日志级别，可用的级别有debug.verbose.notice.warning loglevel verbose # log文件输出位置，如果进程以守护进程的方式运行，此处又将输出文件设置为stdout的话，就会将日志信息输出到/dev/null里面去了 logfile stdout # 设置数据库的数量，默认为0可以使用select &lt;dbid&gt;命令在连接上指定数据库id databases 16 # 指定在多少时间内刷新次数达到多少的时候会将数据同步到数据文件 save &lt;seconds&gt; &lt;changes&gt; # 指定存储至本地数据库时是否压缩文件，默认为yes即启用存储 rdbcompression yes # 指定本地数据库文件名 dbfilename dump.db # 指定本地数据问就按存放位置 dir ./ # 指定当本机为slave服务时，设置master服务的IP地址及端口，在redis启动的时候他会自动跟master进行数据同步 replicaof &lt;masterip&gt; &lt;masterport&gt; # 当master设置了密码保护时，slave服务连接master的密码 masterauth &lt;master-password&gt; # 设置redis连接密码，如果配置了连接密码，客户端在连接redis是需要通过AUTH&lt;password&gt;命令提供密码，默认关闭 requirepass footbared # 设置同一时间最大客户连接数，默认无限制。redis可以同时连接的客户端数为redis程序可以打开的最大文件描述符，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回 max number of clients reached 错误信息 maxclients 128 # 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key。当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区 maxmemory&lt;bytes&gt; # 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no。 appendonly no # 指定跟新日志文件名默认为appendonly.aof appendfilename appendonly.aof # 指定更新日志的条件，有三个可选参数 - no：表示等操作系统进行数据缓存同步到磁盘(快)，always：表示每次更新操作后手动调用fsync()将数据写到磁盘(慢，安全)， everysec：表示每秒同步一次(折衷，默认值)； appendfsync everysec 主机配置(192.168.10.8) 1234567891011121314# Redis 默认只允许本机访问，把 bind 修改为 0.0.0.0 表示允许所有远程访问。如果想指定限制访问，可设置对应的 ip。bind 0.0.0.0 # 端口port 6379 # 关闭保护模式，可以外部访问。protected-mode：no # 后台启动daemonize yes# 日志文件logfile ./redis.log # 设置 redis 连接密码。requirepass 123456# slave 服务连接 master 的密码。。masterauth 123456 从机配置(192.168.10.10) 12345678910111213141516# Redis 默认只允许本机访问，把 bind 修改为 0.0.0.0 表示允许所有远程访问。如果想指定限制访问，可设置对应的 ip。bind 0.0.0.0 # 端口port 6379 # 关闭保护模式，可以外部访问。protected-mode：no # 后台启动daemonize yes# 日志文件logfile ./redis.log # 设置 redis 连接密码。requirepass 123456# slave 服务连接 master 的密码。。masterauth 123456 # 配置主机地址replicaof 192.168.10.8 6379 从机配置:(192.168.10.3) 12345678910111213141516# Redis 默认只允许本机访问，把 bind 修改为 0.0.0.0 表示允许所有远程访问。如果想指定限制访问，可设置对应的 ip。bind 0.0.0.0 # 端口port 6379 # 关闭保护模式，可以外部访问。protected-mode：no # 后台启动daemonize yes# 日志文件logfile ./redis.log # 设置 redis 连接密码。requirepass 123456# slave 服务连接 master 的密码。。masterauth 123456 # 配置主机地址 replicaof 192.168.10.8 6379 小总结 Redis2.8之前的复制功能不能高效地处理断线后重复复制情况,但Redis2.8新添的部分功能重同步功能可以解决这个问题 部分重同步通过复制偏移量、复制积压缓冲区、服务器运行ID三个部分来实现 在复制操作刚开始时候，从服务器会成为主服务器客户端，并通过向主服务器发送命令请求执行复制步骤,而在复制操作后期。主从复制会互相成为对方的客户端。 主服务器通过从服务器传播命令来更新服务器状态，保存主从一致,而从服务器则通过向主服务器发送命令来进行心跳检测,以及命令丢失检测。 单机版和主从配置部署","categories":[{"name":"Nosql","slug":"Nosql","permalink":"https://jameslin23.gitee.io/categories/Nosql/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://jameslin23.gitee.io/tags/缓存/"}]},{"title":"RocketMQ分布式事务","slug":"RocketMQ分布式事务","date":"2020-12-04T11:37:59.000Z","updated":"2020-12-05T02:26:33.310Z","comments":true,"path":"2020/12/04/RocketMQ分布式事务/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/04/RocketMQ分布式事务/","excerpt":"","text":"RocketMQ事务机制举个分布式事务场景例子: 假设A给B转100块，同时他们不是在同一个服务器上 目标: 就是 A 减100块钱，B 加100块钱。 实际可能情况 1）就是A账户减100 （成功），B账户加100 （成功） 2）就是A账户减100（失败），B账户加100 （失败） 3）就是A账户减100（成功），B账户加100 （失败） 4）就是A账户减100 （失败），B账户加100 （成功） 这里 第1和第2 种情况是能够保证事务的一致性的，但是 第3和第4 是无法保证事务的一致性的 RocketMQ实现分布式事务原理RocketMQ虽然之前也支持分布式事务，但并没有开源，等到RocketMQ 4.3才正式开源。 基础概念最终一致性 RocketMQ是一种最终一致性的分布式事务，就是说它保证的是消息最终一致性，而不是像2PC、3PC、TCC那样强一致分布式事务，至于为什么说它是最终一致性事务下面会详细说明。 Half Message(半消息) 是指暂不能被Consumer消费的消息。Producer 已经把消息成功发送到了 Broker 端，但此消息被标记为暂不能投递状态，处于该种状态下的消息称为半消息。需要 Producer 对消息的二次确认后，Consumer才能去消费它。 消息回查 由于网络闪段，生产者应用重启等原因。导致 Producer 端一直没有对 Half Message(半消息) 进行 二次确认。这是Brock服务器会定时扫描长期处于半消息的消息，会 主动询问 Producer端 该消息的最终状态(Commit或者Rollback),该消息即为 消息回查 分布式事务交互流程 我们来说明下上面这张图 1、A服务先发送个Half Message给Brock端，消息中携带 B服务 即将要+100元的信息。 2、当A服务知道Half Message发送成功后，那么开始第3步执行本地事务。 3、执行本地事务(会有三种情况1、执行成功。2、执行失败。3、网络等原因导致没有响应) 4.1)、如果本地事务成功，那么Product像Brock服务器发送Commit,这样B服务就可以消费该message。 4.2)、如果本地事务失败，那么Product像Brock服务器发送Rollback,那么就会直接删除上面这条半消息。 4.3)、如果因为网络等原因迟迟没有返回失败还是成功，那么会执行RocketMQ的回调接口,来进行事务的回查。 为什么要先发送Half Message(半消息)? 1）可以先确认 Brock服务器是否正常 ，如果半消息都发送失败了 那说明Brock挂了。 2）可以通过半消息来回查事务，如果半消息发送成功后一直没有被二次确认，那么就会回查事务状态。 什么情况会回查 1）执行本地事务的时候，由于突然网络等原因一直没有返回执行事务的结果(commit或者rollback)导致最终返回UNKNOW，那么就会回查。 2) 本地事务执行成功后，返回Commit进行消息二次确认的时候的服务挂了，在重启服务那么这个时候在brock端 它还是个Half Message(半消息)，这也会回查。 通过上面这幅图，我们可以看出，在上面举例事务不一致的两种情况中，永远不会发生 A账户减100 （失败），B账户加100 （成功） A账户减100 （成功），B账户加100 （失败）有可能发生 如果B最终执行失败，几乎可以断定就是代码有问题所以才引起的异常，因为消费端RocketMQ有重试机制，如果不是代码问题一般重试几次就能成功。 如果是代码的原因引起多次重试失败后，也没有关系，将该异常记录下来，由人工处理，人工兜底处理后，就可以让事务达到最终的一致性。","categories":[{"name":"消息队列","slug":"消息队列","permalink":"https://jameslin23.gitee.io/categories/消息队列/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://jameslin23.gitee.io/tags/MQ/"}]},{"title":"RocketMQ拉取策略","slug":"RocketMQ拉取策略","date":"2020-12-04T11:28:57.000Z","updated":"2020-12-04T11:37:34.408Z","comments":true,"path":"2020/12/04/RocketMQ拉取策略/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/04/RocketMQ拉取策略/","excerpt":"","text":"消费者拉取策略（Master-Slave）ConsumeQueue文件也是基于os cache的 ConsumeQueue会被大量的消费者发送的请求高并发读取，所以ComsumeQueue文件读取操作非常频繁，而且同时会极大影响到消费者进行拉取的性能和消费吞吐量 对于Broker机器的磁盘上的大量的comsumeQueue文件，在写入的时候也都是优先进os cache中，ConsumeQueue文件主要存放消息CommitLog消息offest,所以每个文件很小,30万条消息的offset就只有5.72MB，他们整体数据量小,几乎可以完全被os缓存在内存cache里面。 实际上在消费者拉取消息的时候，第一步大量的频繁读取ConsumeQueue文件,几乎可以说是跟读内存里的数据的性能是一样的，通过这个可以保证数据消费的高性能以及高吞吐量。 读取CommitLog基于cache+磁盘一起读的 当你拉取消息时候，可以轻松从os cache里读取少量的ConsumeQueue文件offest,这个性能极高，但是当去CommitLog文件读取完整消息数据时候，会有两种可能 第一种 如果你读取的是那种刚刚写入CommitLog的数据，那么大概率他们还停留在os cache中，此时你可以顺利的直接从os cache里面读取CommitLog中的数据，这个是内存读取，性能很高。 第二种 你也许读取的是比较早之前写入CommitLog的数据，那些数据早就被刷入磁盘了，已经不在os cache里了，那么此时你就只能从磁盘上的文件里读取了，这个性能是比较差一些的。 什么时候会从os cache读？什么时候会从磁盘读？ 其实这个问题很简单了，如果你的消费者机器一直快速的在拉取和消费处理，紧紧的跟上了生产者写入broker的消息速率，那么你每次拉取几乎都是在拉取最近人家刚写入CommitLog的数据，那几乎都在os cache里。 但是如果broker的负载很高，导致你拉取消息的速度很慢，或者是你自己的消费者机器拉取到一批消息之后处理的时候性能很低，处理的速度很慢，这都会导致你跟不上生产者写入的速率。 比如人家都写入10万条数据了，结果你才拉取了2万条数据，此时有5万条最新的数据是在os cache里，有3万条你还没拉取的数据是在磁盘里，那么当后续你再拉取的时候，必然很大概率是从磁盘里读取早就刷入磁盘的3万条数据。 Master Broker什么时候会让你从Slave Broker拉取数据？ 假设此时你的broker里已经写入了10万条数据，但是你仅仅拉取了2万条数据， 下次你拉取的时候，是从第2万零1条数据开始继续往后拉取的，是不是？ 也就是说，此时你有8万条数据是没有拉取的！ 然后broker自己是知道机器上当前的整体物理内存有多大的，而且他也知道自己可用的最大空间占里面的比例，他是知道自己的消息最多可以在内存里放多少的！比如他心知肚明，他最多也就在内存里放5万条消息而已！ 因为他知道，他最多只能利用10GB的os cache去放消息，这么多内存最多也就放5万左右的消息。 然后这个时候你过来拉取消息，他发现你还有8万条消息没有拉取，这个8万条消息他发现是大于10GB内存最多存放的5万条消息的，那么此时就说明，肯定有3万条消息目前是在磁盘上的，不在os cache内存里！ 所以他经过上述判断，会发现此时你很大概率会从磁盘里加载3万条消息出来！他会认为，出现这种情况，很可能是因为自己作为master broker负载太高了，导致没法及时的把消息给你，所以你落后的进度比较多。 这个时候，他就会告诉你，我这次给你从磁盘里读取3万条消息，但是下次你还是从slave broker去拉取吧！ 基于mmap内存映射实现磁盘文件的高性能读写传统IO拷贝 读跟写的过程都发生2次拷贝 mmap技术 mmap内存映射，把物理上磁盘文件的一些地址和用户进程私有空间的一些虚拟内存进行一个映射 内存映射，简而言之就是将用户空间的一段内存区域映射到内核空间，映射成功后，用户对这段内存区域的修改可以直接反映到内核空间，同样，内核空间对这段区域的修改也直接反映用户空间。那么对于内核空间&lt;—-&gt;用户空间两者之间需要大量数据传输等操作的话效率是非常高的。 基于JDK NIO包下的MappedByteBuffer的map()函数，先将一个磁盘文件(比如一个CommitLog文件或者一个ComsumeQueue文件)映射到内存中 mmap技术在进行文件映射的时候，一般有大小限制，在1G~2GB之间 所以RocketMQ才能让CommitLog单个文件在1GB,ConsumeQueue在5.72MB，不会太大 基于mmap技术+pagecache技术实现高性能的文件读写写过程 比如写入消息到CommitLog文件，你先把一个CommitLog文件通过MappedByteBuffer的map()函数映射其它地址到你的虚拟内存地址,接着就可以对这个MappedByteBuffer执行写入操作了，写入时候他会直接进入PageCache中，然后过一段时间之后,由os的线程异步刷入磁盘中 只有一次数据拷贝 读过程 先判断读取的数据是否在PageCache里，如果在就直接从PageCache读取，如果不在，就会从磁盘文件加载到PageCache中去。而PageCache技术在加载数据时候，还会将你加载数据块的临近的其它数据块也一起加载到PageCache里 预映射机制 + 文件预热机制(1)内存预映射机制：Broker会针对磁盘上的各种CommitLog、ConsumeQueue文件预先分配好MappedFile，也就是提前对一些可能接下来要读写的磁盘文件，提前使用MappedByteBuffer执行map()函数完成映射，这样后续读写文件的时候，就可以直接执行了。 (2)文件预热：在提前对一些文件完成映射之后，因为映射不会直接将数据加载到内存里来，那么后续在读取尤其是CommitLog、ConsumeQueue的时候，其实有可能会频繁的从磁盘里加载数据到内存中去。","categories":[{"name":"消息队列","slug":"消息队列","permalink":"https://jameslin23.gitee.io/categories/消息队列/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://jameslin23.gitee.io/tags/MQ/"}]},{"title":"RocketMQ集群模式","slug":"RocketMQ集群模式","date":"2020-12-04T10:52:53.000Z","updated":"2020-12-07T01:26:47.749Z","comments":true,"path":"2020/12/04/RocketMQ集群模式/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/04/RocketMQ集群模式/","excerpt":"","text":"Master-Slave主从模式 生产者发数据只会发到Master上，然后slave 从Master pull数据同步下来，跟master保存一份一模一样的数据。 消费者在系统获取消息时候会先发送请求到Master Broker上去,请求获取一批消息，此时Master Broker是会返回一批消息给消费者系统的。然后Master Broker在返回消息给消费者系统的时候， 会根据当时Master Broker的负载情况和Slave Broker的同步情况，向消费者系统建议下一次拉取消息的时候是从Master Broker拉取还是从Slave Broker拉取。 在RocketMQ 4.5版本之前，都是用Slave Broker同步数据，尽量保证数据不丢失，但是一旦Master故障了，Slave是没法自动切换成Master的，在这种情况下，如果Master Broker宕机了，这时就得手动做一些运维操作，把Slave Broker重新修改一些配置，重启机器给调整为Master Broker，这是有点麻烦的，而且会导致中间一段时间不可用。Master-Slave模式不是彻底的高可用模式，他没法实现自动把Slave切换为Master 基于DLedger高可用自动切换什么是DLedger DLedger有一个CommitLog机制，你把数据交给他，他会写入CommitLog磁盘文件里去，这些他做的第一件事。如下图可见，基于DLedger技术来实现Broker高可用框架，实际就是用DLedger先替换原来Broker自己来管理的CommitLog，由DLedger来管理CommitLog DLedger基于Raft协议选举Leader Broker 简单来说,三台Broker机器启动时，他们都会投票自己作为Leader,然后把这个投票发送给其它Broker。 举个例子,Broker01是投票给自己的，Broker02是投票给自己的，Broker03是投票给自己的，他们都把自己的投票发送给了别人。 第一轮选举中，Broker01会收到别人的投票，他发现自己是投票给自己，但是Broker02投票给Broker02自己，Broker03投票给Broker03自己，似乎每个人都很自私，都在投票给自己，所以第一轮选举是失败的 每个人会进入一个随机时间的休眠，比如说Broker01休眠3秒，Broker02休眠5秒，Broker03休眠4秒。 Broker01必然是先苏醒过来的，他苏醒过来之后，直接会继续尝试投票给自己，并且发送自己的选票给别人。接着Broker03休眠4秒后苏醒过来，他发现Broker01已经发送来了一个选票是投给Broker01自己的，此时他自己因为没投票，所以会尊重别人的选择，就直接把票投给Broker01了，同时把自己的投票发送给别人。接着Broker02苏醒了，他收到了Broker01投票给Broker01自己，收到了Broker03也投票给了Broker01，那么他此时自己是没投票的，直接就会尊重别人的选择，直接就投票给Broker01，并且把自己的投票发送给别人 此时所有人都会收到三张投票，都是投给Broker01的，那么Broker01就会当选为Leader。 Raft协议中选举leader算法的简单描述，简单来说，他确保有人可以成为Leader的核心机制就是一轮选举不出来Leader的话，就让大家随机休眠一下，先苏醒过来的人会投票给自己，其他人苏醒过后发现自己收到选票了，就会直接投票给那个人。 DLedger基于Raft协议进行副本同步数据同步会分为两个阶段，一个是uncommitted阶段，一个是commited阶段 首先Leader Broker上的DLedger收到一个条数据之后，会标记为uncommitted状态，然后通过自己的DLedgerServer组件把这个 uncommitted数据发送给Follower Broker的DLedgerServer。 接着Follower Broker的DLedgerServer收到uncommitted消息之后，必须返回一个ack给Leader Broker的DLedgerServer,然后如果Leader Broker收到超过半数的Follower Broker返回的ack之后，就会将消息标记为committed状态。 然后Leader Broker上的DLedgerServer就会发送commited消息给Follower Broker机器的DLedgerServer,让他们也把消息标记commited状态 这个就是基于Raft协议实现的两阶段完成的数据同步机制。 如何使用心跳维护leader地位当选节点之后，首选要维护自己的leader地位，他要告诉集群其它节点，我是集群中leader，你们要成为我的follower，负责同步我的数据，并且保证只要我还活着，你们就不要妄想重新进行选举 每隔几秒钟leader节点会向所有follower节点发送心跳请求； follower收到心跳请求之后，更新本地倒计时时间，同时给leader节点一个确认回复 leader节点收到过半数follower节点回复，则说明自己还是leader 如果没有收到过半数follower节点回复，则会变更为candidate状态，重新触发选举；同样的，如果follower节点一直没有收到leader节点的心跳请求,follower节点也会变更为candidate状态，触发leader选举。 实践部署下载MQ，要求版本4.5以上 https://github.com/apache/rocketmq/releases 这里下载需要的RocketMQ版本 unzip rocketmq-all-4.7.0-bin-release.zip 修改配置文件服务器说明：(生产中应该将 NameServer 部署到其他服务器中，在这为了方便，与Broker部署在一起) 服务器 ip 安装的服务 服务器1-主 192.168.10.8 DLedger，Broker，NameServer 服务器2-从 192.168.10.10 DLedger，Broker，NameServer 服务器3-从 192.168.10.3 DLedger，Broker，NameServer 服务器1配置-Master 123456789101112131415161718192021# ## 集群名brokerClusterName = RaftCluster## broker组名，同一个RaftClusterGroup内，brokerName名要一样brokerName=RaftNode00## 监听的端口listenPort=30911# 你设置的NameServer地址和端口namesrvAddr=192.168.10.8:9876;192.168.10.10:9876;192.168.10.3:9876# 数据存储路径storePathRootDir=/tmp/rmqstore/node1storePathCommitLog=/tmp/rmqstore/node1/commitlog# 是否启动 DLedgerenableDLegerCommitLog=true# DLedger Raft Group的名字，建议和 brokerName 保持一致dLegerGroup=RaftNode00# DLedger Group 内各节点的端口信息，同一个 Group 内的各个节点配置必须要保证一致dLegerPeers=n1-192.168.10.8:40911;n2-192.168.10.10:40912;n3-192.168.10.3:40913#节点 id, 必须属于 dLegerPeers 中的一个；同 Group 内各个节点要唯一dLegerSelfId=n1# 发送线程个数，建议配置成 Cpu 核数sendMessageThreadPoolNums=16 服务器2配置-Slave 123456789101112brokerClusterName = RaftClusterbrokerName=RaftNode00listenPort=30922namesrvAddr=192.168.10.8:9876;192.168.10.3:9876;192.168.10.10:9876storePathRootDir=/tmp/rmqstore/node2storePathCommitLog=/tmp/rmqstore/node2/commitlogenableDLegerCommitLog=truedLegerGroup=RaftNode00dLegerPeers=n1-192.168.10.8:40911;n2-192.168.10.10:40912;n3-192.168.10.3:40913## must be uniquedLegerSelfId=n2sendMessageThreadPoolNums=16 服务器3配置-Slave 123456789101112brokerClusterName = RaftClusterbrokerName=RaftNode00listenPort=30933namesrvAddr=192.168.10.8:9876;192.168.10.3:9876;192.168.10.10:9876storePathRootDir=/tmp/rmqstore/node03storePathCommitLog=/tmp/rmqstore/node03/commitlogenableDLegerCommitLog=truedLegerGroup=RaftNode00dLegerPeers=n1-192.168.10.8:40911;n2-192.168.10.10:40912;n3-192.168.10.3:40913## must be uniquedLegerSelfId=n3sendMessageThreadPoolNums=16 启动集群 在服务器1 执行 先启动mqnamesrv服务 nohup sh mqnamesrv &gt;/dev/null 2&gt;log &amp; 再启动broker服务 nohup sh mqbroker -c ../conf/dledger/broker-node1.conf &gt;/dev/null 2&gt;log &amp; 在服务器2 执行 先启动mqnamesrv服务 nohup sh mqnamesrv &gt;/dev/null 2&gt;log &amp; 再启动broker服务 nohup sh mqbroker -c ../conf/dledger/broker-node2.conf &gt;/dev/null 2&gt;log &amp; 在服务器3 执行 先启动mqnamesrv服务 nohup sh mqnamesrv &gt;/dev/null 2&gt;log &amp; 再启动broker服务 nohup sh mqbroker -c ../conf/dledger/broker-node3.conf &gt;/dev/null 2&gt;log &amp; 内存不足，修改runbroker.sh，runserver.sh 参数 12JAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms8g -Xmx8g -Xmn4g\"JAVA_OPT=\"$&#123;JAVA_OPT&#125; -XX:MaxDirectMemorySize=1g 连接超时，查看防火墙状态 查看防火墙服务状态 systemctl status firewalld 将防火墙关闭 systemctl stop firewalld 查看集群状态 sh mqadmin clusterList -n 127.0.0.1:9876 使用控制台查看 测试生产者-消费者 测试集群高可用，关闭192.168.10.8节点，集群重新竞选master 发送消息 重启192.168.10.8节点,变成slave 配置参数说明 参数名 默认值 说明 listenPort 10911 接受客户端连接的监听端口 namesrvAddr null nameServer 地址 brokerIP1 网卡的 InetAddress 当前 broker 监听的 IP brokerIP2 跟 brokerIP1 一样 存在主从 broker 时，如果在 broker 主节点上配置了 brokerIP2 属性，broker 从节点会连接主节点配置的 brokerIP2 进行同步 brokerName null broker 的名称 brokerClusterName DefaultCluster 本 broker 所属的 Cluser 名称 brokerId 0 broker id, 0 表示 master, 其他的正整数表示 slave storePathCommitLog $HOME/store/commitlog/ 存储 commit log 的路径 storePathConsumerQueue $HOME/store/consumequeue/ 存储 consume queue 的路径 mappedFileSizeCommitLog 1024 * 1024 * 1024(1G) commit log 的映射文件大小 deleteWhen 04 在每天的什么时间删除已经超过文件保留时间的 commit log fileReservedTime 72 以小时计算的文件保留时间 brokerRole ASYNC_MASTER SYNC_MASTER/ASYNC_MASTER/SLAVE flushDiskType ASYNC_FLUSH SYNC_FLUSH/ASYNC_FLUSH SYNC_FLUSH 模式下的 broker 保证在收到确认生产者之前将消息刷盘。ASYNC_FLUSH 模式下的 broker 则利用刷盘一组消息的模式，可以取得更好的性能。 enableDLegerCommitLog 是否启动 DLedger true dLegerGroup DLedger Raft Group的名字，建议和 brokerName 保持一致 RaftNode00 dLegerPeers DLedger Group 内各节点的端口信息，同一个 Group 内的各个节点配置必须要保证一致 n0-127.0.0.1:40911;n1-127.0.0.1:40912;n2-127.0.0.1:40913 dLegerSelfId 节点 id, 必须属于 dLegerPeers 中的一个；同 Group 内各个节点要唯一 n0 sendMessageThreadPoolNums 发送线程个数，建议配置成 Cpu 核数 16","categories":[{"name":"消息队列","slug":"消息队列","permalink":"https://jameslin23.gitee.io/categories/消息队列/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://jameslin23.gitee.io/tags/MQ/"}]},{"title":"RocketMQ单机模式","slug":"RocketMQ单机模式","date":"2020-12-04T10:20:49.000Z","updated":"2020-12-04T10:50:36.052Z","comments":true,"path":"2020/12/04/RocketMQ单机模式/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/04/RocketMQ单机模式/","excerpt":"","text":"按照步骤官网下载http://rocketmq.apache.org/ rocketmq-all-4.6.1-bin-release.zip unzip rocketmq-all-4.6.1-bin-release.zip 修改配置文件在MQ目录下 conf/2m-noslave 创建新的配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#broker 集群名称brokerClusterName = cluster-bus#broker 名称brokerName = broker-4#broker idbrokerId = 0#指定nameserver 的地址端口namesrvAddr=192.168.2.4:9876#数据清除时间deleteWhen=04#文件保存时间fileReservedTime=48#磁盘阀值diskMaxUsedSpaceRatio=95#broker 角色brokerRole=ASYNC_MASTER#刷盘方式flushDiskType=ASYNC_FLUSH#CommitLog 存储路径storePathCommitLog=/data/mq/store/commitlog#数据存储根路径storePathRootDir=/data/mq/store#storePathConsumerQueue 消息队列存储路径#storePathConsumerQueue=/home/apps/data/rocketmq/store/consumerqueue/#storePathIndex 消息索引存储队列#storePathIndex=/home/apps/data/rocketmq/store/index/ #单次从内存最大消费字节数#maxTransferBytesOnMessageInMemory=2621440#单次从内存最大消费信息条数 maxTransferCountOnMessageInMemory=20000#单次从磁盘获取信息的最大条数maxTransferCountOnMessageInDisk=1000#单次从磁盘获取信息的最大字节数maxTransferBytesOnMessageInDisk=6553500#生产者最大发送线程池sendThreadPoolQueueCapacity=100000#消费者最大拉取线程池pullThreadPoolQueueCapacity=1000000#客户管理端线程池clientManagerThreadPoolQueueCapacity=10000000#消费管理端线程池consumerManagerThreadPoolQueueCapacity=10000000#发送等待时间waitTimeMillsInSendQueue=10000#发送线程sendMessageThreadPoolNums=4#刷入内存等待时间osPageCacheBusyTimeOutMills=3000 修改启动参数如果服务器的内存足够，无需修改 MQ根目录bin目录，对runbroker.sh，runserver.sh启动文件 runbroker.sh 12JAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms8g -Xmx8g -Xmn4g\"JAVA_OPT=\"$&#123;JAVA_OPT&#125; -XX:MaxDirectMemorySize=1g\" runserver.sh 123JAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms2g -Xmx2g -Xmn1g -XX:PermSize=512m -XX:MaxPermSize=512m\"# 默认是磁盘90%,当磁盘空间达到90%,MQ就没办法处理数据,此设置可以提高98%JAVA_OPT=\"$&#123;JAVA_OPT&#125; -Drocketmq.broker.diskSpaceWarningLevelRatio=0.98\" 启动MQ 先启动mqnamesrv服务 nohup sh mqnamesrv &gt;/dev/null 2&gt;log &amp; 再启动broker服务 nohup sh mqbroker -c ../conf/2m-noslave/broker-57.properties &gt;/dev/null 2&gt;log &amp; 查看进程 jps -l","categories":[{"name":"消息队列","slug":"消息队列","permalink":"https://jameslin23.gitee.io/categories/消息队列/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://jameslin23.gitee.io/tags/MQ/"}]},{"title":"redis","slug":"redis","date":"2020-12-04T02:34:34.000Z","updated":"2020-12-09T12:00:55.431Z","comments":true,"path":"2020/12/04/redis/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/04/redis/","excerpt":"","text":"redis基础知识 Key-Value数据库，NOSQL 存储，查询高效(Redis读的速度是110000次/秒,写的速度80000次/秒) 单线程，基于内存操作，CPU不是redis性能瓶颈，瓶颈是机器带宽和内存 存储数据结构String类型 这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存 String的实际应用比较广泛 缓存功能:**String字符串是最常用的数据类型，不仅仅是Redis，各个语言都是最基本类型，因此，利用Redis作为缓存，配合其它数据库作为存储层，利用Redis**支持高并发的特点，可以大大加快系统的读写速度、以及降低后端数据库的压力。 计数器:许多系统都会使用Redis作为系统的实时计数器，可以快速实现计数和查询的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。 共享用户Session：用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存Cookie，但是可以利用Redis将用户的Session集中管理，在这种模式只需要保证Redis的高可用，每次用户Session的更新和获取都可以快速完成。大大提高效率。 List列表 比如可以通过 List 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。 消息队列：Redis的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过Lpush命令从左边插入数据，多个数据消费者，可以使用BRpop命令阻塞的“抢”列表尾部的数据。 文章列表或者数据分页展示的应用。 比如，我们常用的博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用Redis的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。 Set集合 Set 是无序集合，会自动去重的那种 可以基于 Set 玩儿交集、并集、差集的操作，比如交集吧，我们可以把两个人的好友列表整一个交集，看看俩人的共同好友是谁 Hash类型 key-value Zset有序集合 Sorted set 是排序的 Set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。 有序集合的使用场景与集合类似，但是set集合不是自动有序的，而Sorted set可以利用分数进行成员间的排序，而且是插入时就排序好。所以当你需要一个有序且不重复的集合列表时，就可以选择Sorted set数据结构作为选择方案。 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。 用Sorted Sets来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。 微博热搜榜，就是有个后面的热度值，前面就是名称 Geospatial地理位置 代补充 Hyperloglog基数统计 通常是用来统计一个集合中不重复的元素个数 如果统计 PV 那非常好办，给每个网页一个独立的 Redis 计数器就可以了，这个计数器的 key 后缀加上当天的日期。这样来一个请求，incrby 一次，最终就可以统计出所有的 PV 数据。 但是 UV 不一样，它要去重，同一个用户一天之内的多次访问请求只能计数一次。 这就要求每一个网页请求都需要带上用户的 ID，无论是登陆用户还是未登陆用户都需要一个唯一 ID 来标识 你也许已经想到了一个简单的方案，那就是为每一个页面一个独立的 set 集合来存储所有当天访问过此页面的用户 ID。 当一个请求过来时，我们使用 sadd 将用户 ID 塞进去就可以了。 通过 scard 可以取出这个集合的大小，这个数字就是这个页面的 UV 数据。没错，这是一个非常简单的方案。 但是，如果你的页面访问量非常大，比如一个爆款页面几千万的 UV，你需要一个很大的 set 集合来统计，这就非常浪费空间。 如果这样的页面很多，那所需要的存储空间是惊人的。为这样一个去重功能就耗费这样多的存储空间，值得么？其实老板需要的数据又不需要太精确，105w 和 106w 这两个数字对于老板们来说并没有多大区别，So，有没有更好的解决方案呢？ HyperLogLog 提供了两个指令 pfadd 和 pfcount，根据字面意义很好理解，一个是增加计数，一个是获取计数。 pfadd 用法和 set 集合的 sadd 是一样的，来一个用户 ID，就将用户 ID 塞进去就是，pfcount 和 scard 用法是一样的，直接获取计数值。 12345678910111213141516171819202122232425262728127.0.0.1:6379&gt; pfadd codehole user1(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 1127.0.0.1:6379&gt; pfadd codehole user2(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 2127.0.0.1:6379&gt; pfadd codehole user3(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 3127.0.0.1:6379&gt; pfadd codehole user4(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 4127.0.0.1:6379&gt; pfadd codehole user5(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 5127.0.0.1:6379&gt; pfadd codehole user6(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 6127.0.0.1:6379&gt; pfadd codehole user7 user8 user9 user10(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 10 Hyperloglog原理—–&gt; https://mp.weixin.qq.com/s/9dtGe3d_mbbxW5FpVPDNow BitMap位图场景 位存储,都是操作二进制进行记录,0和1 Redis提供了SETBIT、GETBIT、BITCOUNT、BITOP四个命令用于处理二进制位数组。 BitMap原理 BitMap的基本原理就是用一个bit来标记某个元素对应的value,而key即是该元素。由于采用一个bit来存储一个数据，因此可以大大的节省空间。 我们通过一个具体例子来说明BitMap的原理。假设我们要对0-31内的3个元素(10,17,28)排序。我们就可以采用BitMap方法(假设这些元素没有重复) 如下图,要表示32个数，我们只需要32个bit(4Bytes)，首先我们开辟4Byte的空间,将这些空间的所有bit位都设置为0 然后，我们要添加(10, 17,28) 这三个数到 BitMap 中，需要的操作就是在相应的位置上将0置为1即可。如下图，比如现在要插入 10 这个元素，只需要将蓝色的那一位变为1即可。 将这些数据插入后，假设我们想对数据进行排序或者检索数据是否存在，就可以依次遍历这个数据结构，碰到位为 1 的情况，就当这个数据存在。 字符串映射 BitMap 也可以用来表述字符串类型的数据，但是需要有一层Hash映射，如下图，通过一层映射关系，可以表述字符串是否存在。 当然这种方式会有数据碰撞的问题，但可以通过 Bloom Filter 做一些优化。 使用场景一：统计活跃用户 使用时间作为cacheKey，然后用户ID为offset(当用户很大时，需要优化)，如果当日活跃过就设置为1 使用场景二：户在线状态 只需要一个key，然后用户ID为offset(当用户很大时，需要优化)，如果在线就设置为1，不在线就设置为0 使用场景三 : 用户签到 用户ID作为key，签到的天数offest redis持久化SAVE 保存是阻塞主进程，客户端无法连接redis，等SAVE完成后，主进程才开始工作，客户端可以连接 BGSAVE 是fork一个save的子进程，在执行save过程中，不影响主进程，客户端可以正常链接redis，等子进程fork执行save完成后，通知主进程，子进程关闭。很明显BGSAVE RDB 快照方式，允许你每隔一段时间对内存数据做一次快照然后存储到硬盘中 RDB可以通过在配置文件中配置时间或者改动键的个数来定义快照条件，编辑配置文件redis.conf 1234# 默认配置save 900 1 #15分钟之内至少有一个键被更改则进行快照save 300 10 #5分钟之内至少有10个键被更改则进行快照 save 60 10000 #1分钟之内至少有1000个键被更改则进行快照 RDB持久化到磁盘文件默认路径是当前安装目录，文件名为dump.rdb，你可以通过配置文件dir和dbfilename来指定文件目录和文件名称，rdb文件还可以进行压缩,你可以通过配置rdbcompression参数进行压缩 执行流程 （1）redis根据配置自己尝试去生成rdb快照文件 （2）fork一个子进程出来 （3）子进程尝试将数据dump到临时的rdb快照文件中 （4）完成rdb快照文件的生成之后，就替换之前的旧的快照文件 存在问题 当还没进行sava，触发存储快照时，服务器宕机，会丢失上次保存快照-到宕机时这段时间的数据。 AOF 记录客户端对服务器的每一个写操作命令,并将这些写操作以Redis协议追加保存到.aof文件,在redis服务器重启时,在redis服务器重启时，会加载并运行aof文件命令，已达到恢复数据的目的。 开启AOF持久化方式 Redis默认不开启AOF持久化方式，我们可以在配置文件中开启并进行更加详细的配置，如下面的redis.conf文件： 1234567891011121314# 开启aof机制appendonly yes# aof文件名appendfilename &quot;appendonly.aof&quot;# 写入策略,always表示每个写操作都保存到aof文件中,也可以是everysec或noappendfsync always# 默认不重写aof文件no-appendfsync-on-rewrite no# 保存目录dir ~/redis/ 执行方式 always: Redis的每条写命令都写入到系统缓冲区，然后每条写命令都使用fsync“写入”硬盘。 客户端的每一个写操作都保存到aof文件当，这种策略很安全，但是每个写请注都有IO操作，所以也很慢。 everysec: 过程与always相同，只是fsync的频率为1秒钟一次。这个是Redis默认配置，如果系统宕机，会丢失一秒左右的数据 appendfsync的默认写入策略，每秒写入一次aof文件，因此，最多可能会丢失1s的数据。 no: 由操作系统决定什么时候从系统缓冲区刷新到硬盘。 Redis服务器不负责写入aof，而是交由操作系统来处理什么时候写入aof文件。更快，但也是最不安全的选择，不推荐使用。 AOF文件重写 AOF将客户端的每一个写操作都追加到aof文件末尾，比如对一个key多次执行incr命令，这时候，aof保存每一次命令到aof文件中，aof文件会变得非常大。 12345incr num 1incr num 2incr num 3...incr num 100000 aof文件太大，加载aof文件恢复数据时，就会非常慢，为了解决这个问题，Redis支持aof文件重写，通过重写aof，可以生成一个恢复当前数据的最少命令集，比如上面的例子中那么多条命令，可以重写为: 1set num 100000 注意：通过在redis.conf配置文件中的选项no-appendfsync-on-rewrite可以设置是否开启重写，这种方式会在每次fsync时都重写，影响服务器性以，因此默认值为no，不推荐使用。 AOF文件损坏 在写入aof日志文件时，如果redis服务器宕机,则aof日志文件会出格式错误,在重启redis服务器时,redis服务器会拒绝载入这个aof文件，可以通过以下步骤修复aof并恢复数据 使用redis-check-aof命令修复aof文件，该命令格式如下 12&gt; redis-check-aof -fix file.aof&gt; AOF的优点 AOF只是追加日志文件，因此对服务器性能影响较小，速度比RDB要快，消耗的内存较小 AOF的缺点 AOF方式生成的日志文件太大，即使通过AFO重写，文件体积仍然很大。 恢复数据的速度比RDB RDB VS AOF RDB AOF 启动优先级 低 高 体积 小 大 恢复速度 快 慢 数据安全性 丢数据 根据策略 小总结 简单概述redis基础，8大数据结构，及bitmap原理，运用场景 redis两大持久化机制,RDB原理，AOF原理及各种优缺点","categories":[{"name":"Nosql","slug":"Nosql","permalink":"https://jameslin23.gitee.io/categories/Nosql/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://jameslin23.gitee.io/tags/缓存/"}]},{"title":"Nginx","slug":"ngnix","date":"2020-12-01T06:55:34.000Z","updated":"2020-12-24T01:38:01.072Z","comments":true,"path":"2020/12/01/ngnix/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/01/ngnix/","excerpt":"","text":"Nginx的按照准备工作 打开官网http://nginx.org/下载nginx nginx-1.19.5.tar.gz 安装 openssl 、zlib 、 gcc 依赖 yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel 联网下载 pcre 压缩文件依赖 1、wget http://downloads.sourceforge.net/project/pcre/pcre/8.37/pcre-8.37.tar.gz 2、tar –xvf pcre-8.37.tar.gz 3、./configure 4、install &amp;&amp; make install 安装 nginx 1、tar -xvf nginx-1.19.5.tar.gz 2、./configure 3、install &amp;&amp; make instal 启动nginx 先关闭防火墙，测试可以全部关掉，生产按照端口开发 停止firewall systemctl stop firewalld.service 禁止firewall开机启动 systemctl disable firewalld.service 查看防火墙状态 firewall-cmd –state 进入/usr/local/nginx/sbin/nginx 启动命令 ./nginx 可配置环境变量 vim /etc/profile PATH=$PATH:/usr/local/webserver/nginx/sbinexport PATH 生效 source /etc/profile ngnix常用命令 1、查看版本号 nginx -v 2、启动 nginx 3、停止 nginx -s stop 4、重新加载 nginx -s reload 反向代理配置反向代理-1 反向代理-2 根据不同请求路径对应不同服务器 负载均衡负载均衡算法轮询(默认) 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。 weight权重 weight 代表权,重默认为 1,权重越高被分配的客户端越多 ip_hash 每个请求按方位ip的hash结果分配，这样每个访客固定一个后端服务器,可以解决session的问题 fair 按照后端服务器的响应时间来分配请求，响应时间短的优先分配 HTTP 负载均衡 TCP 负载均衡 nginx-1.17.9使用增加了stream 模块用于一般的TCP 代理和负载均衡，ngx_stream_core_module 这个模块在1.90版本后将被启用。但是并不会默认安装 到nginx源文件目录 ./configure –with-stream make &amp; make install 修改 配置文件 12345678910111213stream &#123; upstream kevin &#123; server 192.168.10.10:8080; #这里配置成要访问的地址 server 192.168.10.20:8081; &#125; server &#123; listen 8081; #需要监听的端口 proxy_timeout 20s; proxy_pass kevin; &#125; # 多个模块可增加多个sever+upstream&#125; TCP负载算法轮询（默认）least-connected 对应每个请求,nginx plus选择当前连接数最少的server来处理 12345upstream kevin &#123; least_conn; server 192.168.10.10:8080; #这里配置成要访问的地址 server 192.168.10.20:8081;&#125; ip_hash 客户机的IP地址用作散列键，用于确定应该为客户机的请求选择服务器组中的哪个服务器 123456upstream myapp1 &#123; ip_hash; server srv1.example.com; server srv2.example.com; server srv3.example.com;&#125; hash普通的hash算法：nginx plus选择这个server是通过user_defined 关键字，就是IP地址：$remote_addr; 1234567upstream kevin &#123; hash $remote_addr consistent; server 192.168.10.10:8080 weight=5; #这里配置成要访问的地址 server 192.168.10.20:8081 max_fails=2 fail_timeout=30s; server 192.168.10.30:8081 max_conns=3; #需要代理的端口，在这里我代理一一个kevin模块的接口8081&#125; 静态分离待编辑 nginx限流nginx提供两种限流的方式 控制速率 控制并发连接数 控制速率原理 采用漏桶算法实现控制速率限流 漏桶(Leaky Bucket) 算法思路很简单，水(请求)先进入到漏桶里，漏桶以一定的速度出水(接口有响应速率),当水流入速度过大会直接溢出（访问频率超过接口响应速率），然后就拒绝请求，可以看出漏桶算法能强行限制数据的传输速率。 配置1 12345678910111213141516171819202122232425262728293031323334353637383940user root root;worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #cache lua_shared_dict dis_cache 128m; #限流设置 limit_req_zone $binary_remote_addr zone=contentRateLimit:10m rate=2r/s; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name localhost; location /update_content &#123; content_by_lua_file /root/lua/update_content.lua; &#125; location /read_content &#123; #使用限流配置 limit_req zone=contentRateLimit; content_by_lua_file /root/lua/read_content.lua; &#125; &#125;&#125; 配置参数说明 binary_remote_addr: 是一种key,表示基于remote_add(客户端)来做限流，binary_ 目的压缩内存占用量。 zone: 定义共享内存区来存储访问信息，contentRateLimit:10m 表示一个大小为10m,名字为contentRateLimit的内存区域。1M能存储16000 IP地址访问信息，10M可以存储16万IP地址访问 rate: 用于设置最大访问速率,rate=10r/s 表示每秒最多处理10请求。nginx实际上以毫秒为颗粒度来跟踪请求信息。因此10r/s实际上是限制每100毫秒处理一个请求。这意味着自上一个请求处理完，若后续100毫秒内又有请求到达，将拒接该请求。我们这里设置为2，方便测试。 测试 访问http://192.168.10.132/read_content?id=1，连续刷新就会报错 配置2 上面例子限制2r/s，如果有时正常流量突然增大，超过的请求将被拒接，无法处理突发流量，可以结合burst参数使用来解决该问题 1234567891011server &#123; listen 80; server_name localhost; location /update_content &#123; content_by_lua_file /root/lua/update_content.lua; &#125; location /read_content &#123; limit_req zone=contentRateLimit burst=4; content_by_lua_file /root/lua/read_content.lua; &#125;&#125; burst译为突发、爆发，表示在超过设定的处理速率后能额外处理的请求，当rate=10r/s时，将1s拆分10份，既每100ms可以处理1个请求。此处burst=4,若同时有4个请求达到,nginx会处理第一个请求。剩余3个请求将放入队列，然后每隔100ms从队列中获取一个请求进行处理。若请求大于4，将拒接处理多余的请求，直接返回503. 不过，单独使用 burst 参数并不实用。假设 burst=50 ，rate依然为10r/s，排队中的50个请求虽然每100ms会处理一个，但第50个请求却需要等待 50 * 100ms即 5s，这么长的处理时间自然难以接受。 因此，burst往往结合nodelay 一起使用 1limit_req zone=contentRateLimit burst=4 nodelay; 平均每秒允许不超过2个请求，突发不超过4个请求，并且处理突发4个请求的时候，没有延迟，等到完成之后，按照正常的速率处理。 控制并发连接数配置限制固定连接数 ngx_http_limit_conn_module 提供了限制连接数的能力。主要是利用limit_conn_zone和limit_conn两个指令。 12345678910111213141516171819202122232425262728293031323334353637383940http &#123; include mime.types; default_type application/octet-stream; #cache lua_shared_dict dis_cache 128m; #限流设置 limit_req_zone $binary_remote_addr zone=contentRateLimit:10m rate=2r/s; #根据IP地址来限制，存储内存大小10M limit_conn_zone $binary_remote_addr zone=addr:1m; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name localhost; #所有以brand开始的请求，访问本地changgou-service-goods微服务 location /brand &#123; limit_conn addr 2; proxy_pass http://192.168.211.1:18081; &#125; location /update_content &#123; content_by_lua_file /root/lua/update_content.lua; &#125; location /read_content &#123; limit_req zone=contentRateLimit burst=4 nodelay; content_by_lua_file /root/lua/read_content.lua; &#125; &#125;&#125; limit_conn_zone $binary_remote_addr zone=addr:10m; 表示限制根据用户的IP地址来显示，设置存储地址为的内存大小10M limit_conn addr 2; 表示 同一个地址只允许连接2次。 限制每个客户端IP与服务器的连接数，同时限制与虚拟服务器的连接总数 12345678910111213limit_conn_zone $binary_remote_addr zone=perip:10m;limit_conn_zone $server_name zone=perserver:10m; server &#123; listen 80; server_name localhost; charset utf-8; location / &#123; limit_conn perip 10;#单个客户端ip与服务器的连接数． limit_conn perserver 100; ＃限制与服务器的总连接数 root html; index index.html index.htm; &#125;&#125; Keepalived高可用 安装keepalived一种是用yum安装，一种是下载安装包，这里使用yum yum install keepalived –y 安装之后在/etc/keepalived,有个keepalived.conf 12345678910111213141516171819202122232425262728293031323334353637! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.10.8 smtp_connect_timeout 30 router_id LVS_DEVEL &#125;vrrp_script monitor_nginx &#123; script \"/usr/local/src/nginx_check.sh\" interval 2 #（检测脚本执行的间隔） weight 2 # 检测失败（脚本返回非0）则优先级 -2 fall 2 # 检测连续 2 次失败才算确定是真失败。会用weight减少优先级（1-255之间） &#125;vrrp_instance VI_1 &#123; state MASTER # 备份服务器上将 MASTER 改为 BACKUP interface ens33 # 网卡 virtual_router_id 51 # 主、备机的 virtual_router_id 必须相同 priority 100 # 主、备机取不同的优先级，主机值较大，备份机值较小 advert_int 1authentication &#123; auth_type PASS auth_pass 1111&#125; virtual_ipaddress &#123; 192.168.10.33 # VRRP H 虚拟地址 &#125; track_script &#123; monitor_nginx &#125;&#125; 检测脚本 123456789#!/bin/bashA=`ps -C nginx --no-header | wc -l`if [ $A -eq 0 ];then /usr/local/webserver/nginx/sbin/nginx #尝试重新启动nginx sleep 1 #睡眠1秒 if [ `ps -C nginx --no-header | wc -l` -eq 0 ];then killall keepalived #启动失败，将keepalived服务杀死。将vip漂移到其它备份节点 fifi 启动keepalived systemctl start keepalived.service 查看状态 systemctl status keepalived.service 关闭keeaplived systemctl stop keepalived.service 强关进程 pkill keepalived 问题总结1、/etc/keepalived/chk_nginx.sh exited due to signal 15 vrrp_script interval的值要修改成小于chk_nginx.sh中sleep的值 chk_nginx.sh sleep的值不宜过大最好不要超过3，否则也会出现exited due to signal 15问题，偶尔会出time out问题","categories":[{"name":"负载均衡","slug":"负载均衡","permalink":"https://jameslin23.gitee.io/categories/负载均衡/"}],"tags":[{"name":"负载均衡","slug":"负载均衡","permalink":"https://jameslin23.gitee.io/tags/负载均衡/"}]},{"title":"RocketMQ","slug":"RocketMQ","date":"2020-12-01T00:30:33.000Z","updated":"2020-12-04T11:56:08.848Z","comments":true,"path":"2020/12/01/RocketMQ/","link":"","permalink":"https://jameslin23.gitee.io/2020/12/01/RocketMQ/","excerpt":"","text":"MQ有哪些作用?异步化提高系统性能系统解耦高并发削峰MQ技术选型 RocketMQ核心原理NameServer 是整个消息队列中的状态服务器，集群的各个组件通过它来了解全局的信息。每个broker都会注册到所有的NameServer上，Broker和NameServer采用心跳机制,Broker会每隔30s给所有NameServer发送心跳,告诉每个nameServer自己还活着，然后NameServer会每隔10s运行一个任务，去检测一下各个Broker的最近一次心跳时间，如果某个Broker超过120s都没发心跳了，就认为这个Broker已经挂掉了。 发送消息。通过nameServer去获取路由信息，就知道集群有哪些Broker等消息消费消息，也会到NameServer获取路由信息，去找到对应的Broker获取消息 Broker真正存储数据的地方。 CommitLog 消息内容原文的存储文件，同Kafka一样，消息是变长的，顺序写入 生成规则: 每个文件的默认1G =1024 * 1024 * 1024，commitlog的文件名fileName，名字长度为20位，左边补零，剩余为起始偏移量；比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1 073 741 824Byte；当这个文件满了，第二个文件名字为00000000001073741824，起始偏移量为1073741824, 消息存储的时候会顺序写入文件，当文件满了则写入下一个文件 ConsumeQueue ConsumeQueue中并不需要存储消息的内容，而存储的是消息在CommitLog中的offset。也就是说，ConsumeQueue其实是CommitLog的一个索引文件。 $HOME/store/consumequeue/{topic}/{queueId}/{fileName} ConsumeQueue是定长的结构，每1条记录固定的20个字节。很显然，Consumer消费消息的时候，要读2次：先读ConsumeQueue得到offset，再读CommitLog得到消息内容 ConsumeQueue的作用 通过broker保存的offset可以在ConsumeQueue中获取消息，从而快速的定位到commitLog的消息位置 过滤tag是也是通过遍历ConsumeQueue来实现的（先比较hash(tag)符合条件的再到consumer比较tag原文） 并且ConsumeQueue还能保存于操作系统的PageCache进行缓存提升检索性能 当你的Broker收到一条消息写入了CommitLog之后，其实他同时会将这条消息在CommitLog中的物理位置，也就是一个文件偏移量，就是一个offset，写入到这条消息所属的MessageQueue对应的ConsumeQueue文件中去。 异步刷盘和同步刷盘Broker是基于OS操作系统的PageCache和顺序写两个机制，来提升写入CommitLog文件的性能的 异步刷盘 首先Broker是以顺序的方式将消息写入CommitLog磁盘文件的，也就是每次写入就是在文件末尾追加一条数据就可以了，对文件进行顺序写的性能要比对文件随机写的性能提升很多 数据写入CommitLog文件的时候，其实不是直接写入底层的物理磁盘文件的，而是先进入OS的PageCache内存缓存中，然后后续由OS的后台线程选一个时间，异步化的将OS PageCache内存缓冲中的数据刷入底层的磁盘文件 所以在这样的优化之下，采用磁盘文件顺序写+OS PageCache写入+OS异步刷盘的策略，基本上可以让消息写入CommitLog的性能跟你直接写入内存里是差不多的，所以正是如此，才可以让Broker高吞吐的处理每秒大量的消息写入。 存在问题 在上述的异步刷盘模式下，生产者把消息发送给Broker，Broker将消息写入OS PageCache中，就直接返回ACK给生产者了。 生产者认为消息写入成功了，但是实际上那条消息此时是在Broker机器上的os cache中的，如果此时Broker直接宕机，可能会有数据丢失的风险。 同步刷盘 生产者发送一条消息出去，broker收到了消息，必须直接强制把这个消息刷入底层的物理磁盘文件中，然后才会返回ack给producer，此时你才知道消息写入成功了 优缺点 吞吐量低，但是消息不容易丢失。 Producerrocketmq支持三种发送消息的方式，分别是同步发送（sync），异步发送（async）和直接发送（oneway） 同步发送（Sync） 这种只有在消息完全发送完成之后才返回结果，此方法需要同步等待发送结果的时间为代价 这种方式具有内部重试机制,即在主动声明本次发送失败之前，内部实现将重试一定的次数，默认为2次（DefaultMQProducer＃setRetryTimesWhenSendFailed（））发送结果存在同一个消息可能被多次发送给broker,这里需要应用开发者在自己消费端处理。 123456789101112131415161718192021222324public class SyncProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); for (int i = 0; i &lt; 100; i++) &#123; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"TopicTest\" /* Topic */, \"TagA\" /* Tag */, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); // 发送消息到一个Broker SendResult sendResult = producer.send(msg); // 通过sendResult返回消息是否成功送达 System.out.printf(\"%s%n\", sendResult); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125; 异步发送（async） 异步消息通常在对响应时间敏感的业务场景，即发送端不能容忍长时间等待Broker的响应,异步模式也在内部实现了重试机制，默认次数为2次(setRetryTimesWhenSendAsyncFailed() 12345678910111213141516171819202122232425262728293031323334public class AsyncProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); producer.setRetryTimesWhenSendAsyncFailed(0); for (int i = 0; i &lt; 100; i++) &#123; final int index = i; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"TopicTest\", \"TagA\", \"OrderID188\", \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET)); // SendCallback接收异步返回结果的回调 producer.send(msg, new SendCallback() &#123; @Override public void onSuccess(SendResult sendResult) &#123; System.out.printf(\"%-10d OK %s %n\", index, sendResult.getMsgId()); &#125; @Override public void onException(Throwable e) &#123; System.out.printf(\"%-10d Exception %s %n\", index, e); e.printStackTrace(); &#125; &#125;); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125; 直接发送(sendOneway) 这种方式主要用在不特别关心发送结果的场景，例如日志发送。 1234567891011121314151617181920212223public class OnewayProducer &#123; public static void main(String[] args) throws Exception&#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); for (int i = 0; i &lt; 100; i++) &#123; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"TopicTest\" /* Topic */, \"TagA\" /* Tag */, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); // 发送单向消息，没有任何返回结果 producer.sendOneway(msg); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125; 顺序消息发送 消息有序指的是可以按照消息的发送顺序来消费(FIFO)。RocketMQ可以严格的保证消息有序，可以分为分区有序或者全局有序。 顺序消费的原理解析，在默认的情况下消息发送会采取Round Robin轮询方式把消息发送到不同的queue(分区队列)；而消费消息的时候从多个queue上拉取消息，这种情况发送和消费是不能保证顺序。 要保证发送与消费有序，那同一类型的消息-发送到同一个队列当中，同一个队列只能一个线程去处理，即同一个消费者。 面用订单进行分区有序的示例。一个订单的顺序流程是：创建、付款、推送、完成。订单号相同的消息会被先后发送到同一个队列中，消费时，同一个OrderId获取到的肯定是同一个队列。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import org.apache.rocketmq.client.producer.DefaultMQProducer;import org.apache.rocketmq.client.producer.MessageQueueSelector;import org.apache.rocketmq.client.producer.SendResult;import org.apache.rocketmq.common.message.Message;import org.apache.rocketmq.common.message.MessageQueue; import java.text.SimpleDateFormat;import java.util.ArrayList;import java.util.Date;import java.util.List; /*** Producer，发送顺序消息*/public class Producer &#123; public static void main(String[] args) throws Exception &#123; DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); producer.setNamesrvAddr(\"127.0.0.1:9876\"); producer.start(); String[] tags = new String[]&#123;\"TagA\", \"TagC\", \"TagD\"&#125;; // 订单列表 List&lt;OrderStep&gt; orderList = new Producer().buildOrders(); Date date = new Date(); SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); String dateStr = sdf.format(date); for (int i = 0; i &lt; 10; i++) &#123; // 加个时间前缀 String body = dateStr + \" Hello RocketMQ \" + orderList.get(i); Message msg = new Message(\"TopicTest\", tags[i % tags.length], \"KEY\" + i, body.getBytes()); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Long id = (Long) arg; //根据订单id选择发送queue long index = id % mqs.size(); return mqs.get((int) index); &#125; &#125;, orderList.get(i).getOrderId());//订单id System.out.println(String.format(\"SendResult status:%s, queueId:%d, body:%s\", sendResult.getSendStatus(), sendResult.getMessageQueue().getQueueId(), body)); &#125; producer.shutdown(); &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091 /** * 订单的步骤 */ private static class OrderStep &#123; private long orderId; private String desc; public long getOrderId() &#123; return orderId; &#125; public void setOrderId(long orderId) &#123; this.orderId = orderId; &#125; public String getDesc() &#123; return desc; &#125; public void setDesc(String desc) &#123; this.desc = desc; &#125; @Override public String toString() &#123; return \"OrderStep&#123;\" + \"orderId=\" + orderId + \", desc='\" + desc + '\\'' + '&#125;'; &#125; &#125; /** * 生成模拟订单数据 */ private List&lt;OrderStep&gt; buildOrders() &#123; List&lt;OrderStep&gt; orderList = new ArrayList&lt;OrderStep&gt;(); OrderStep orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"创建\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc(\"创建\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"付款\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc(\"创建\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc(\"付款\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc(\"付款\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc(\"完成\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"推送\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc(\"完成\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"完成\"); orderList.add(orderDemo); return orderList; &#125;&#125; 发送延迟消息 现在RocketMq并不支持任意时间的延时，需要设置几个固定的延时等级，从1s到2h分别对应着等级1到18 private String messageDelayLevel = “1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”; 123456789101112131415161718192021import org.apache.rocketmq.client.producer.DefaultMQProducer;import org.apache.rocketmq.common.message.Message; public class ScheduledMessageProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化一个生产者来产生延时消息 DefaultMQProducer producer = new DefaultMQProducer(\"ExampleProducerGroup\"); // 启动生产者 producer.start(); int totalMessagesToSend = 100; for (int i = 0; i &lt; totalMessagesToSend; i++) &#123; Message message = new Message(\"TestTopic\", (\"Hello scheduled message \" + i).getBytes()); // 设置延时等级3,这个消息将在10s之后发送(现在只支持固定的几个时间,详看delayTimeLevel) message.setDelayTimeLevel(3); // 发送消息 producer.send(message); &#125; // 关闭生产者 producer.shutdown(); &#125;&#125; 发送批量消息 批量发送消息能显著提高传递小消息的性能。限制是这些批量消息应该有相同的topic，相同的waitStoreMsgOK，而且不能是延时消息。此外，这一批消息的总大小不应超过4MB。 1234567891011String topic = \"BatchTest\";List&lt;Message&gt; messages = new ArrayList&lt;&gt;();messages.add(new Message(topic, \"TagA\", \"OrderID001\", \"Hello world 0\".getBytes()));messages.add(new Message(topic, \"TagA\", \"OrderID002\", \"Hello world 1\".getBytes()));messages.add(new Message(topic, \"TagA\", \"OrderID003\", \"Hello world 2\".getBytes()));try &#123; producer.send(messages);&#125; catch (Exception e) &#123; e.printStackTrace(); //处理error&#125; 生产者常用设置参数123456789101112131415// 初始化 设置相关参数 defaultMQProducer = new DefaultMQProducer(producerGroupName); // 设置nameSever地址 defaultMQProducer.setNamesrvAddr(namesrvAddr); // 实例名 defaultMQProducer.setInstanceName(instanceName); // 异步发送失败重发次数，默认2次 defaultMQProducer.setRetryTimesWhenSendAsyncFailed(10); // 同步发送失败重发次数，默认2次 defaultMQProducer.setRetryTimesWhenSendFailed(10); // 消息没有存储成功是否发送到另外一个broker defaultMQProducer.setRetryAnotherBrokerWhenNotStoreOK(true); // 发送超时时间 defaultMQProducer.setSendMsgTimeout(5000); defaultMQProducer.start(); ConsumerPush模式 由于消息中间件主动地将消息推送给消费者，可以尽可能实时地将消息发送给消费者进行消费。但是消费者的处理消息的能力较弱时，比如(消费者端业务系统处理一条流程比较复杂，导致消费比较耗时)，而MQ不断地向消费者Push消息，消费者端缓冲区可能会溢出，导致异常。 Push模式实际上在内部还是使用的Pull方式实现的，通过Pull不断地轮询Broker获取消息，当不存在新消息时，Broker端会挂起Pull请求，直到有新消息产生才取消挂起，返回新消息。 需要返回消费状态，MQ内部维护Offset Pull模式 由消费者客户端主动向消息中间件（MQ消息服务器代理）拉取消息；采用Pull方式，如何设置Pull消息的频率需要重点去考虑，举个例子来说，可能1分钟内连续来了1000条消息，然后2小时内没有新消息产生（概括起来说就是“消息延迟与忙等待”）。如果每次Pull的时间间隔比较久，会增加消息的延迟，即消息到达消费者的时间加长，MQ中消息的堆积量变大；若每次Pull的时间间隔较短，但是在一段时间内MQ中并没有任何消息可以消费，那么会产生很多无效的Pull请求的RPC开销，影响MQ整体的网络性能； 消息消费的偏移量需要Consumer端自己去维护 集群模式&amp;广播模式 集群模式：一条消息，在同一个消费者组中，只有一个消费实例消费。 广播模式: 一条消息，在同一个消费者组中,全部消费实例都会消费。 消费者与队列关系消费者==队列数 一个消费负责一个队列 消费者&gt;队列数 一个消费者负责一个队列，剩余消费者空闲 消费者&lt;队列数 队列数均摊所有消费者 消费重复问题Redis 给消息分配一个全局id,只要消费过该消息，将&lt;id,message&gt;以K-V形式写入redis。消费者开始消费之前，先去redis中查询有没有消费记录即可 常用的命令 查看所有topic sh mqadmin topicList -n localhost:9876 查看clustername sh mqadmin clusterList -n localhost:9876 查看所有消费组 sh mqadmin consumerProgress -n localhost:9876 查看消费组的发送、接收、阻塞情况 sh mqadmin consumerProgress -g groupname -n localhost:9876 删除topic sh mqadmin deleteTopic -n localhost:9876 -c cluster-bus -t topicname 删除group sh mqadmin deleteSubGroup -c topicname -g groupname -n localhost:9876 新增增或修改topic sh mqadmin updateTopic -c cluster-bus -n localhost:9876 -o true -p 6 -w 50 -r 50 -t topicName 新增或修改消费组 sh mqadmin updateSubGroup -n localhost:9876 -c cluster-bus -g groupname 查看topic配置属性 sh mqadmin topicRoute -n localhost:9876 -t topicname 根据消息Key查询消息 sh mqadmin queryMsgByKey -n localhost:9876 -t topicname -k key 重置消费位点 sh mqadmin resetOffsetByTime -n localhost:9876 -g groupname -t topicname -s now","categories":[{"name":"消息队列","slug":"消息队列","permalink":"https://jameslin23.gitee.io/categories/消息队列/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://jameslin23.gitee.io/tags/MQ/"}]},{"title":"零散java知识补漏","slug":"java基础","date":"2020-11-28T06:45:45.000Z","updated":"2020-12-26T02:44:32.598Z","comments":true,"path":"2020/11/28/java基础/","link":"","permalink":"https://jameslin23.gitee.io/2020/11/28/java基础/","excerpt":"","text":"修饰符 private : 在同一类可见，使用对象：变量、方法。注意不能修饰类(外部类) default: 在同一包内见，不使用任何修饰符，使用对象: 类、接口、变量、方法。 protected: 对同一包内的类和所有子类可见，使用对象：变量,方法。注意：不能修饰类(外部类) public: 对所有类可见，使用对象: 类、接口、方法 修饰符 当前类 同包 子类 其它包 private √ × × × default √ √ × × protected √ √ √ × public √ √ √ √ final作用 被final修饰的类不可以继承 被final修饰的方法不可被重写 被final修饰的常量是不可能变的 被final修饰的对象，对象的引用时不变的 final、finally、finalize区别 final可以修饰类、变量、方法，修饰类表示该类不能被继承、修饰方法表示该方法不能被重写、修饰变量表示该变量是一个常量不能被重新赋值 finally一般作用在try-catch代码块中，在处理异常的时候，通常我们将一定要执行的代码方法finally代码块中，表示不管是否出现异常，该代码块都会执行，一般用来存放一些关闭资源的代码。 finalize是一个方法，属于Object类的一个方法，而Object类是所有类的父类，该方法一般由垃圾回收器来调用，当我们调用System.gc() 方法的时候，由垃圾回收器调用finalize()，回收垃圾，一个对象是否可回收的最后判断。 this关键字用法 this是自身的一个对象，代表对象本身，可以理解为:指向对象本身的一个指针 this的用法在Java中大体可以分3种 普通的直接引用,this相当于是指向当前对象本身 形参与成员名字重名,用来this来区分 1234public Person(String name, int age) &#123; this.name = name; this.age = age;&#125; 引用本类的构造函数 123456789101112131415class Person&#123; private String name; private int age; public Person() &#123; &#125; public Person(String name) &#123; this.name = name; &#125; public Person(String name, int age) &#123; this(name); this.age = age; &#125;&#125; super关键字的用法 super可以理解为是指向自己超（父）类对象的一个指针，而这个超类指的是离自己最近的一个父类。 super也有三种用法： 普通的直接引用 与this类似，super相当于是指向当前对象的父类的引用，这样就可以用super.xxx来引用父类的成员。 子类中的成员变量或方法与父类中的成员变量或方法同名时，用super进行区分 12345678910111213141516171819202122232425262728293031class Person&#123; protected String name; public Person(String name) &#123; this.name = name; &#125; &#125; class Student extends Person&#123; private String name; public Student(String name, String name1) &#123; super(name); this.name = name1; &#125; public void getInfo()&#123; System.out.println(this.name); //Child System.out.println(super.name); //Father &#125; &#125;public class Test &#123; public static void main(String[] args) &#123; Student s1 = new Student(\"Father\",\"Child\"); s1.getInfo(); &#125;&#125; 引用父类构造函数 this与super的区别 super:它引用当前对象的直接父类中的成员（用来访问直接父类中被隐藏的父类中成员数据或函数，基类与派生类中有相同成员定义时如：super.变量名 super.成员函数据名（实参） this：它代表当前对象名（在程序中易产生二义性之处，应使用this来指明当前对象；如果函数的形参与类中的成员数据同名，这时需用this来指明成员变量名） super()和this()类似,区别是，super()在子类中调用父类的构造方法，this()在本类内调用本类的其它构造方法。 super()和this()均需放在构造方法内第一行 尽管可以用this调用一个构造器，但却不能调用两个 this()和super()都指的是对象，所以，均不可以在static环境中使用。包括：static变量,static方法，static语句块。 static 存在的主要意义及特点 static的主要意义是在于创建独立于具体对象的域变量或者方法。 以致于即使没有创建对象，也能使用属性和调用方法 ！ 1、在该类被第一次加载的时候，就会去加载被static修饰的部分，而且只在类第一次使用时加载并进行初始化，注意这是第一次用就要初始化，后面根据需要是可以再次赋值的。 2、static变量值在类加载的时候分配空间，以后创建类对象的时候不会重新分配。赋值的话，是可以任意赋值的！ 3、被static修饰的变量或者方法是优先于对象存在的，也就是说当一个类加载完毕之后，即便没有创建对象，也可以去访问。 多态 所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出来的方法调用在编程时并不确定，而在程序运行期间才确定，即一个引用变量到底会指向哪个类的实例对象，该引用变量发出来调用到底是哪个类中实现的方法，必须由程序运行期间才能决定。因为在程序运行时才能确定具体的类，这样就不用修改源代码,就可以让引用变量绑定到各个不同实现类上，从而导致该引用调用的具体方法随之改变，即不修改程序代码就可以改变程序运行时所绑定的具体代码，让程序可以选择多个运行状态，这就是多态性。 多态实现 Java实现多态有三个必要条件：继承、重写、向上转型。 继承: 在多态中必须存在有继承关系的子类和父类 重写：子类对父类中某些方法进行重新定义，在调用这些方法时就会调用子类的方法。 向上转型: 在多态中需要将子类的引用赋给父类对象，只有这样该引用才能够具备技能调用父类的方法和子类的方法。 在多态中需要将子类的引用赋给父类对象，只有这样该引用才能够具备技能调用父类的方法和子类的方法。 类与接口抽象类与接口对比 抽象类是用来捕捉子类的通用特性。接口是抽象方法的集合 从设计层面来说,抽象类是对类的抽象,是一种模板设计,接口是行为的抽象，是一种行为规范。 相同点 接口和抽象类不能实例化 都位于继承的顶端,用于被其它实现或继承 都包含抽象方法,其子类都必须覆写这些抽象方法 不同点 参数 抽象类 接口 声明 抽象类使用abstract关键字 接口使用interface关键字声明 实现 子类使用extends关键字来继承抽象类,如果子类不是抽象类的话,他需要提供抽象类中所声明的方法来实现 子类使用implements关键类来实现接口，它需要提供接口中所有声明的方法来实现 构造器 抽象类可以有构造器 接口不能有构造器 访问修饰符 抽象类中的方法可以是任意访问修饰符 接口方法默认修饰符是public，并且不允许定义为private或者protected 多继承 一个类最多只能继承一个抽象类 一个类可以实现多个接口 字段声明 抽象类的字段声明可以是任意的 接口的字段默认都是 static 和 final 的 接口和抽象类各有优缺点，在接口和抽象类的选择上，必须遵守这样一个原则： 行为模型应该总是通过接口而不是抽象类定义，所以通常是优先选用接口，尽量少用抽象类。 选择抽象类的时候通常是如下情况：需要定义子类的行为，又要为子类提供通用的功能。 error和exception区别error: 程序无法处理系统错误,编译器不做检查 Error表示系统致命的错误,程序没法处理，一般与JVM相关的问题，如系统崩溃，内存溢出，方法调用栈溢出等。 如经常遇到的StackOverflowError、OutOfMemoryError 这种类型错误，编译器不做检查，都是系统运行过程中发生的 Exception: 程序可以处理的异常,捕获后可以处理 Exception异常是程序能够捕获的，也可以异常处理。 hashCode()方法作用 返回对象的哈希代码值（就是散列码），用来支持哈希表，例如：HashMap 实现了hashCode一定要实现equals，因为底层HashMap就是通过这2个方法判断重复对象的 String、StringBuffer、StingBuilder的区别 可变性 String类使用final关键字修饰字符数组来保存字符串,所以String对象是不可变的。 StringBuilder与StringBuffer都继承AbstractStringBuilder,在类中没有使用final关键字修饰，所以这两种对象都是可变的 12345678abstract class AbstractStringBuilder implements Appendable, CharSequence &#123; char[] value; int count; AbstractStringBuilder() &#123; &#125; AbstractStringBuilder(int capacity) &#123; value = new char[capacity]; &#125; 安全性 String是不可变的，所以是线程安全的 StringBuffer使用synchironized修饰，线程安全的 StringBuilder线程不安全的。 性能 StringBuffer源码 1234567@Override public synchronized String toString() &#123; if (toStringCache == null) &#123; toStringCache = Arrays.copyOfRange(value, 0, count); &#125; return new String(toStringCache, true); &#125; ​ StringBuilder源码 12345@Override public String toString() &#123; // Create a copy, don't share the array return new String(value, 0, count); &#125; StringBuffer的缓存有数据时，就直接在缓存区，而StringBuiler每次都是直接copy，这样StringBuffer相对StingBuiler做了一个性能上的优化，所以只有当数量足够大，StringBuffer的缓存区填补不了加锁的影响的性能时，StringBuiler才能性能上展示出它的优势。","categories":[{"name":"java基础","slug":"java基础","permalink":"https://jameslin23.gitee.io/categories/java基础/"}],"tags":[{"name":"java","slug":"java","permalink":"https://jameslin23.gitee.io/tags/java/"}]},{"title":"枚举","slug":"枚举","date":"2020-11-28T06:25:58.000Z","updated":"2020-11-28T06:45:41.687Z","comments":true,"path":"2020/11/28/枚举/","link":"","permalink":"https://jameslin23.gitee.io/2020/11/28/枚举/","excerpt":"","text":"什么是枚举 Enum类型实质是一种特殊的class，它不可以继承其他类，也不可以被其他类继承，但可以实现接口。 用途可以用来管理错误码12345678910111213141516171819202122232425262728public enum ErrorCodeEn &#123; OK(0, \"成功\"), ERROR_A(100, \"错误A\"), ERROR_B(200, \"错误B\"); ErrorCodeEn(int number, String description) &#123; this.code = number; this.description = description; &#125; private int code; private String description; public int getCode() &#123; return code; &#125; public String getDescription() &#123; return description; &#125; /** * 下面是测试 * @param args */ public static void main(String args[]) &#123; // 静态方法 for (ErrorCodeEn s : ErrorCodeEn.values()) &#123; System.out.println(\"code: \" + s.getCode() + \", description: \" + s.getDescription()); &#125; &#125;&#125; 枚举类的构造函数默认是私有的。通过构造函数自定义枚举实例的内容，实例之间用逗号隔开，最后一个末尾加分号。用枚举类型的get方法获取枚举实例的属性。（实例就是用枚举类型创建的对象） 实现单例模式123456789101112131415161718public enum Singleton &#123; INSTANCE; public void doSomething() &#123; System.out.println(\"doSomething\"); &#125; &#125;public class Main &#123; public static void main(String[] args) &#123; Singleton.INSTANCE.doSomething(); &#125; &#125;","categories":[{"name":"java基础","slug":"java基础","permalink":"https://jameslin23.gitee.io/categories/java基础/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"https://jameslin23.gitee.io/tags/java基础/"}]},{"title":"java设计模式","slug":"java设计模式","date":"2020-11-27T09:21:43.000Z","updated":"2020-11-28T09:09:45.708Z","comments":true,"path":"2020/11/27/java设计模式/","link":"","permalink":"https://jameslin23.gitee.io/2020/11/27/java设计模式/","excerpt":"","text":"一、单例模式 手写单例步骤 1、私有构造函数,外部不可new对象 2、实例化对象 3、提供外部访问接口 单例模式类型1. 饿汉式123456789public class Hungry &#123; private Hungry()&#123;&#125; // 类初始化new对象 private final static Hungry HUNGRY = new Hungry(); public static Hungry getInstance()&#123; return HUNGRY; &#125;&#125; 2.懒汉式 基本写法(线程不安全) 1234567891011// 线程不安全public class LazyDemo1 &#123; private LazyDemo1()&#123; &#125; private static LazyDemo1 lazyDemo1; public static LazyDemo1 getInstance()&#123; if (lazyDemo1==null)&#123; lazyDemo1 = new LazyDemo1(); &#125; return lazyDemo1; &#125;&#125; 使用Synchronized同步（效率低） 123456789101112public class LazyDemo2 &#123; private static LazyDemo2 lazyDemo2; private LazyDemo2()&#123; &#125; public static synchronized LazyDemo2 getInstance()&#123; if (lazyDemo2==null)&#123; lazyDemo2 = new LazyDemo2(); &#125; return lazyDemo2; &#125;&#125; 双重检测 123456789101112131415// 会被反射和反序列化攻击破坏public class LazyDemo3 &#123; private static volatile LazyDemo3 lazyDemo3; private LazyDemo3()&#123;&#125; public static LazyDemo3 getInstance()&#123; if (lazyDemo3==null)&#123; synchronized (LazyDemo3.class)&#123; if (lazyDemo3==null)&#123; lazyDemo3 = new LazyDemo3(); &#125; &#125; &#125; return lazyDemo3; &#125;&#125; 静态内部类 123456789101112// 静态内部类方式在 Singleton 类被装载时并不会立即实例化，而是在需要实例化时，调用 getInstance 方法，才会装载 SingletonInstance 类，从而完成 Singleton 的实例化// 类的静态属性只会在第一次加载类的时候初始化，所以在这里，JVM 帮助我们保证了线程的安全性，在类进行初始化时，别的线程是无法进入的public class LazyDemo4 &#123; private static LazyDemo4 lazyDemo4; private LazyDemo4()&#123;&#125; private static class SingletonInstance&#123; private static final LazyDemo4 INSTANCE = new LazyDemo4(); &#125; public static LazyDemo4 getInstance()&#123; return SingletonInstance.INSTANCE; &#125;&#125; 枚举 12345678910111213// 被《Effective Java》称为最佳的单例实现模式，因为最简单，而且不会被反射和反序列化攻击破坏。enum EnumDemo &#123; INSTANCE; public void doSomething() &#123; System.out.println(\"doSomething\"); &#125; public static void main(String[] args) &#123; EnumDemo.INSTANCE.doSomething(); &#125;&#125;","categories":[{"name":"java基础","slug":"java基础","permalink":"https://jameslin23.gitee.io/categories/java基础/"}],"tags":[{"name":"java设计模式","slug":"java设计模式","permalink":"https://jameslin23.gitee.io/tags/java设计模式/"}]},{"title":"hashmap源码底层分析","slug":"hashmap","date":"2020-11-27T00:15:09.000Z","updated":"2020-12-26T13:21:25.364Z","comments":true,"path":"2020/11/27/hashmap/","link":"","permalink":"https://jameslin23.gitee.io/2020/11/27/hashmap/","excerpt":"","text":"前期知识铺垫什么是哈希表 哈希表又叫散列表，他是一种基于快速存取的角度设计，也是一种典型的”空间换时间”的做法，数据结构可以理解为线性表,但是其中的元素不是紧密排列的,可能存在空隙。 哈希表是根据关键码值而直接进行访问的数据结构,通过把关键码值映射到表中一个位置来访问记录，以加快查找速度，这个映射函数就做散列函数。比如我们存储75个元素，但我们可能为这75个元素申请100元素空间，为了“快速存取“的目的。我们基于一种结果尽可能随机分布的固定函数h为每个元素存储位置,这样就可以避免遍历性质的线性搜索 一、HashMap核心分析(JDK1.7版)1.1 什么是hashmap? hashmap是java集合类,以key-value键值对形式存储,在jdk1.7版本采用数组+链表 1.2 hashmap核心成员1234static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 默认容量16static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 最大容量static final float DEFAULT_LOAD_FACTOR = 0.75f; // 默认负载因子0.75ransient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE; // Entry数组，核心 Entry数组（hashmap静态内部类）123456789101112static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; int hash; Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; // value值 next = n; // 指向下一个entry,形成链表 key = k; // key值 hash = h; // hash值 &#125; &#125; 1.3 hashmap put操作底层分析123456789101112131415161718192021222324252627282930313233343536373839404142434445public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); // 懒加载,第一次需要进行初始化 &#125; if (key == null) // 如果key为null ,直接put值进去 return putForNullKey(value); int hash = hash(key); // 获取hash值 int i = indexFor(hash, table.length); //计算下标 // 遍历链表 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; // 如果has值和key都一致，进行覆盖，并把原来数据返回 if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // 如果找不到就新增一个entry addEntry(hash, key, value, i); return null; &#125; // 获取hash值 final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; // 容量2的倍数-1的目的，就是取hashcode 后面几位，使得下标可以更加均匀分布，避免hash冲突 static int indexFor(int h, int length) &#123; // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\"; return h &amp; (length-1); &#125; 增加Entry对象(核心)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 void addEntry(int hash, K key, V value, int bucketIndex) &#123; // 当entry长度大等于负载因子*容量大小 并且当前数组不为Null时候进行扩容 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex); &#125;// 扩容 void resize(int newCapacity) &#123; // new一个新的数组 Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; // 赋值操作 transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); &#125; void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; // 遍历旧的数组 for (Entry&lt;K,V&gt; e : table) &#123; // 遍历链表 while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; // 从initHashSeedAsNeeded基本不会进入这个地方进行重取hash if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; // 获取下标获取还是原来hash值 int i = indexFor(e.hash, newCapacity); // 头插法插入链表,在线程不安全情况下会导致形成循环链表，下面会仔细分析 e.next = newTable[i]; // 头插法关键--当前元素e的下一个元素 指向新数组的头部 newTable[i] = e; // 把当前元素加入新数组 e = next; &#125; &#125; &#125; void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; // 获取当前数组i的元素 table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e);//new的entry对象，next指向头元素 size++; &#125; 头插法过程 此时e是”我”,e.next是“你” 第一步：e.next = newTable[i] e.next等于newTable[i]，新数组还没插入数据，此时为null，即e.next=null 第二步: newTable[i] = e ,把当前元素插入数组中 e = next; 执行下一个元素 此时e是”你”,e.next是“他” 第一步：e.next = newTable[i] e.next = “我” newTable[i] = e 依次类推 头插法的在多线程情况下，会导致循环链表。当get()操作，没有找到对应key的时候，就会死循环遍历该链表 12345678910111213141516final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; 总结 put过程中，hashmap会先判断数据是否需要初始化，然后判断key值是否为空，但key不为空时候，通过hash算法，得到hash值跟数组容量-1”与”运算得到下标，定位到数组中的位置,如果是链表，即遍历链表，判断hash,key是否一致，如果有相同的值，既覆盖并返回久的值，否则增加entry对象，在增加entry对象之前，根据当前数据容量size&gt;=数组容量*负载因子并且当前数据 位置不为空的时候，进行扩容，采用new新的数组，采用头插法插入链表中，会造成循环链表，在get操作时候，如果没有找到对应key值，会造成死循环。所以在多线程环境下， 请使用ConcurrentHashMap。 问题hashamp如果减少hash碰撞? hashmap在设计数组下标的时候，数组容量都是2的m次方，然后采用hash值和数组容量-1进行与运算。由于2的m次方减1，在二进制最低进制位都是1111的形式，与运算出来都是唯一性比较强的，比较散列分布的值。所以可以减少hash碰撞。 二、HashMap核心分析(JDK1.8版) hashmap在jdk1.8使用数组+链表/红黑树，来解决当链表过长，查找时间复杂度为o(n)的问题，并且使用尾插法。 Put操作底层分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 判断数组是否初始化 if ((tab = table) == null || (n = tab.length) == 0) // 初始化和扩容代码集成一起 n = (tab = resize()).length; // 当前数组位置为空 if ((p = tab[i = (n - 1) &amp; hash]) == null) // 首节点，next为空 tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 判断是不是当前节点位置值是不是一致 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 是把p赋值给e // 如果p节点是树 else if (p instanceof TreeNode) // 添加插入二叉树 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 遍历链表 for (int binCount = 0; ; ++binCount) &#123; // e = p.next if ((e = p.next) == null) &#123; // 插入链表尾部 p.next = newNode(hash, key, value, null); // 判断该节点是8， if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 转换成二叉树 treeifyBin(tab, hash); break; &#125; // 找到对应位置 if (e.hash == hash &amp;&amp; // k=e.key ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; // 下一个元素 p = e; &#125; &#125; // 说明找到值了 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); // 返回旧的值 return oldValue; &#125; &#125; ++modCount; // 扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; 总结 jdk1.8 当链表长度大于等8的时候，链表就会转换成二叉树，插入链表的时候是插入链表尾部。 三、 ConcurrentHashMap(JDK1.7版) 底层一个Segments数组，存储一个Segments对象，一个Segments中储存一个Entry数组，存储的每个Entry对象又是一个链表头结点。 Segment数组的意义就是将一个大的table分割成多个小的table来进行加锁，也就是上面的提到的锁分离技术，而每一个Segment元素存储的是HashEntry数组+链表，这个和HashMap的数据存储结构一样 Put操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/**从上Segment的继承体系可以看出，Segment实现了ReentrantLock,也就带有锁的功能**/static class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123;&#125; public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; if (value == null) throw new NullPointerException(); int hash = hash(key); // 通过hash值计算出下标 int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject // nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) // in ensureSegment // 获取segment s = ensureSegment(j); // 调用put return s.put(key, hash, value, false); &#125; final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; // 获取锁 HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; // 插入操作 try &#123; HashEntry&lt;K,V&gt;[] tab = table; int index = (tab.length - 1) &amp; hash; HashEntry&lt;K,V&gt; first = entryAt(tab, index); for (HashEntry&lt;K,V&gt; e = first;;) &#123; if (e != null) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; e.value = value; ++modCount; &#125; break; &#125; e = e.next; &#125; else &#123; if (node != null) node.setNext(first); else node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue; &#125; 总结 使用segment数组，解决多线程并发安全问题，但每次先要定位segment位置，效率会低一点，jdk1.8做出优化。 四、ConcurrentHashMap(JDK1.8版) JDK1.8，使用CAS+Synchronized 提高并发效率 Put操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990 final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); // 得到 hash 值 int binCount = 0; // 用于记录相应链表的长度 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) // 如果数组\"空\"，进行数组初始化 tab = initTable(); // 找该 hash 值对应的数组下标，得到第一个节点 f else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; // 用一次 CAS 操作将新new出来的 Node节点放入数组i下标位置 // 如果 CAS 失败，那就是有并发操作，进到下一个循环 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED) // 进入扩容，采用cas tab = helpTransfer(tab, f); else &#123; V oldVal = null; // 锁住整个节点 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null; &#125;final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; int rs = resizeStamp(tab.length); while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; // cas if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table; &#125; 总结 计算hash，算出数据的下标，判断首节点为Null,采用cas尝试插入,其次判断是否需要扩容，扩容采用cas，其他则使用synchronized锁住整个节点，避免多线程竞争。 ConcurrentHashMap机制提高了并发效率。多线程环境下是最优选择。","categories":[{"name":"java基础","slug":"java基础","permalink":"https://jameslin23.gitee.io/categories/java基础/"}],"tags":[{"name":"java集合","slug":"java集合","permalink":"https://jameslin23.gitee.io/tags/java集合/"}]},{"title":"多线程与高并发","slug":"多线程与高并发","date":"2020-11-26T08:55:29.000Z","updated":"2020-11-26T09:32:04.471Z","comments":true,"path":"2020/11/26/多线程与高并发/","link":"","permalink":"https://jameslin23.gitee.io/2020/11/26/多线程与高并发/","excerpt":"","text":"一、并发基础1.1 并发三大特性 原子性 指一个操作是不可中断的，要么全部执行成功，要么全部失败 有序性 程序执行顺序按照代码的先后顺序执行 可见性 指多个线程访问同一个变量时，一个线程修改了这个变量的值,其它线程能够立马看到修改的值 1.2 线程基础1. 线程的实现3种实现方式 继承Thread 实现Runable接口 实现callable接口，有返回值 2.线程5种状态 新建、就绪、运行、阻塞、死亡 3.线程之间通讯 object对象wait()，notifyAll() Codition对象await(),signalAll() 3.线程中断 调用interrupt()方法+return 调用interrupt()方法+抛异常throw new InterruptedException() Interrupt方法就是把中断状态由false变成true 1.3 Volatile关键字 Volatile是java一个关键字，该关键字修饰的字段，被某线程修改时，对其它线程可见。它保证了线程可见性和禁止指令重排序 底层实现 在java内存模型当中，线程是不能直接操作主内存共享变量，而是拷贝一份到自己工作内存当中。对于声明volatile变量进行写操作时，会马上写入主内存，并导致其它线程工作内存的值无效，当其它线程需要访问该变量时，就需要从主内存获取最新的值。此时就保证了线程可见。 JVM底层操作：JVM会向处理器发送一个Lock前缀指令，Lock前缀会引起处理器缓存回写到主内存，并使其它处理器的缓存无效 禁止重排序 为了程序性能、处理器、编译器都会对程序进行重排序处理，多线程模式下会导致线程不安全 volatile是否能保证原子性? Volatile无法保证原子性，当某一个线程读取变量时，还没写入主内存就被阻塞，无法导致其它线程工作内存变量无效。使得原子性无法得到保证。i++ 并非原子性操作，自增后再赋值。","categories":[{"name":"并发编程","slug":"并发编程","permalink":"https://jameslin23.gitee.io/categories/并发编程/"}],"tags":[{"name":"多线程与高并发","slug":"多线程与高并发","permalink":"https://jameslin23.gitee.io/tags/多线程与高并发/"}]},{"title":"网络框架-Netty","slug":"netty-1","date":"2020-11-26T08:27:08.000Z","updated":"2020-11-26T09:21:32.587Z","comments":true,"path":"2020/11/26/netty-1/","link":"","permalink":"https://jameslin23.gitee.io/2020/11/26/netty-1/","excerpt":"","text":"一、netty的简介 什么是Netty Netty是一个利用java的高级网络的能力,隐藏其背后的复杂性而提供一个易于使用的API的客户端/服务器框架。 Netty构成部分Channel Channel是NIO基本结构,他代表一个用于连接到实体如硬件设备、文件、网络套接字或程序组件,能够执行一个或者多个不同的I/O操作的开发连接。把Channel想象成一个可以”打开”或者”关闭”,”连接”或”断开”和作为传入和传出数据的运输。 Callback (回调) callback (回调)是一个简单的方法,提供给另一种方法作为引用,这样后者就可以在某个合适的 时间调用前者。这种技术被广泛使用在各种编程的情况下,最常见的方法之一通知给其他人操 作已完成。 Future Future 提供了另外一种通知应用操作已经完成的方式。这个对象作为一个异步操作结果的占 位符,它将在将来的某个时候完成并提供结果。 Event和Handler Netty使用不同的事件来通知我们更改的状态和操作的状态。这使我们能够根据发送的事件触发适当的行为。这些行为可能包括: 日志 数据转换 流控制 应用程序逻辑 由于Netty是一个网络框架,事件很清晰的跟入站或或出站数据流相关。因为一些事件可能触发传入的数据或状态的变化包括： 活动或者非活动连接 数据的读取 用户事件 错误 出站事件是由于在未来操作将触发一个动作。这些包括: 打开或关闭一个连接到远程 写或冲刷数据到socket","categories":[{"name":"网络编程","slug":"网络编程","permalink":"https://jameslin23.gitee.io/categories/网络编程/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://jameslin23.gitee.io/tags/Netty/"}]}],"categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://jameslin23.gitee.io/categories/数据结构与算法/"},{"name":"并发编程","slug":"并发编程","permalink":"https://jameslin23.gitee.io/categories/并发编程/"},{"name":"JVM","slug":"JVM","permalink":"https://jameslin23.gitee.io/categories/JVM/"},{"name":"java基础","slug":"java基础","permalink":"https://jameslin23.gitee.io/categories/java基础/"},{"name":"面试专题","slug":"面试专题","permalink":"https://jameslin23.gitee.io/categories/面试专题/"},{"name":"springCloud","slug":"springCloud","permalink":"https://jameslin23.gitee.io/categories/springCloud/"},{"name":"web服务器","slug":"web服务器","permalink":"https://jameslin23.gitee.io/categories/web服务器/"},{"name":"docker","slug":"docker","permalink":"https://jameslin23.gitee.io/categories/docker/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://jameslin23.gitee.io/categories/计算机网络/"},{"name":"服务中心","slug":"服务中心","permalink":"https://jameslin23.gitee.io/categories/服务中心/"},{"name":"数据库","slug":"数据库","permalink":"https://jameslin23.gitee.io/categories/数据库/"},{"name":"Nosql","slug":"Nosql","permalink":"https://jameslin23.gitee.io/categories/Nosql/"},{"name":"消息队列","slug":"消息队列","permalink":"https://jameslin23.gitee.io/categories/消息队列/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://jameslin23.gitee.io/categories/负载均衡/"},{"name":"网络编程","slug":"网络编程","permalink":"https://jameslin23.gitee.io/categories/网络编程/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"https://jameslin23.gitee.io/tags/排序算法/"},{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"https://jameslin23.gitee.io/tags/ThreadLocal/"},{"name":"垃圾回收器","slug":"垃圾回收器","permalink":"https://jameslin23.gitee.io/tags/垃圾回收器/"},{"name":"垃圾回收算法","slug":"垃圾回收算法","permalink":"https://jameslin23.gitee.io/tags/垃圾回收算法/"},{"name":"Synchronized","slug":"Synchronized","permalink":"https://jameslin23.gitee.io/tags/Synchronized/"},{"name":"AQS","slug":"AQS","permalink":"https://jameslin23.gitee.io/tags/AQS/"},{"name":"java集合","slug":"java集合","permalink":"https://jameslin23.gitee.io/tags/java集合/"},{"name":"java","slug":"java","permalink":"https://jameslin23.gitee.io/tags/java/"},{"name":"服务网关","slug":"服务网关","permalink":"https://jameslin23.gitee.io/tags/服务网关/"},{"name":"服务降级","slug":"服务降级","permalink":"https://jameslin23.gitee.io/tags/服务降级/"},{"name":"服务调用","slug":"服务调用","permalink":"https://jameslin23.gitee.io/tags/服务调用/"},{"name":"缓存","slug":"缓存","permalink":"https://jameslin23.gitee.io/tags/缓存/"},{"name":"运维与虚拟化技术","slug":"运维与虚拟化技术","permalink":"https://jameslin23.gitee.io/tags/运维与虚拟化技术/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://jameslin23.gitee.io/tags/计算机网络/"},{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://jameslin23.gitee.io/tags/数据结构与算法/"},{"name":"分布式","slug":"分布式","permalink":"https://jameslin23.gitee.io/tags/分布式/"},{"name":"面试经典","slug":"面试经典","permalink":"https://jameslin23.gitee.io/tags/面试经典/"},{"name":"事务","slug":"事务","permalink":"https://jameslin23.gitee.io/tags/事务/"},{"name":"MQ","slug":"MQ","permalink":"https://jameslin23.gitee.io/tags/MQ/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://jameslin23.gitee.io/tags/负载均衡/"},{"name":"java基础","slug":"java基础","permalink":"https://jameslin23.gitee.io/tags/java基础/"},{"name":"java设计模式","slug":"java设计模式","permalink":"https://jameslin23.gitee.io/tags/java设计模式/"},{"name":"多线程与高并发","slug":"多线程与高并发","permalink":"https://jameslin23.gitee.io/tags/多线程与高并发/"},{"name":"Netty","slug":"Netty","permalink":"https://jameslin23.gitee.io/tags/Netty/"}]}